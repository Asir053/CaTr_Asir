{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CaTr_Asir.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89a3644b62ad4ad0a5fda0b591bb857f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26f78530e6494f6daa6f08d8fb7cfc11",
              "IPY_MODEL_d7c46e4d2101406b945e20bfcf42714f",
              "IPY_MODEL_4cc5b0d3fb0c41d79fb7c91b57bec7b7"
            ],
            "layout": "IPY_MODEL_57509072f16943b0b1a3059a4ae89884"
          }
        },
        "26f78530e6494f6daa6f08d8fb7cfc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab2d44d35c64e31bf5a01237857d026",
            "placeholder": "​",
            "style": "IPY_MODEL_7db2c2b7bd964e0b8a8a60a3974c26af",
            "value": "100%"
          }
        },
        "d7c46e4d2101406b945e20bfcf42714f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318e9f8a241e4f479ddf4d93af81a294",
            "max": 178793939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdb1eaa8919c48db88f6196525aa11cc",
            "value": 178793939
          }
        },
        "4cc5b0d3fb0c41d79fb7c91b57bec7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9762e04a9f664f04bf7cb2b4fa62cd86",
            "placeholder": "​",
            "style": "IPY_MODEL_ad97c7e0f4b843c0a40120e69b5666da",
            "value": " 171M/171M [00:02&lt;00:00, 79.9MB/s]"
          }
        },
        "57509072f16943b0b1a3059a4ae89884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab2d44d35c64e31bf5a01237857d026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db2c2b7bd964e0b8a8a60a3974c26af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "318e9f8a241e4f479ddf4d93af81a294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb1eaa8919c48db88f6196525aa11cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9762e04a9f664f04bf7cb2b4fa62cd86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad97c7e0f4b843c0a40120e69b5666da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8adc431bcdb4dbcbf4b032603165797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a89fb3ca91264d24a4d82fb1ff09f480",
              "IPY_MODEL_0408eb448c974cc284fee81c6cc4f5c7",
              "IPY_MODEL_38415f9fae394b3ea7358a2286a687ad"
            ],
            "layout": "IPY_MODEL_1515a1447b3942f0992d3317468fcb62"
          }
        },
        "a89fb3ca91264d24a4d82fb1ff09f480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0477395df304ab59c230e920a43d330",
            "placeholder": "​",
            "style": "IPY_MODEL_d86ef8a95adf41c0863d20f369ad81be",
            "value": "100%"
          }
        },
        "0408eb448c974cc284fee81c6cc4f5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71ce32838d3d469ea65e315694177c2a",
            "max": 337711781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dda19f5e2ee416daddc06e86e4afd2d",
            "value": 337711781
          }
        },
        "38415f9fae394b3ea7358a2286a687ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1d9310efdf4333ab2f9367ebd0d4a3",
            "placeholder": "​",
            "style": "IPY_MODEL_5c8080c34bb34a689ae548b488af29aa",
            "value": " 322M/322M [00:21&lt;00:00, 8.82MB/s]"
          }
        },
        "1515a1447b3942f0992d3317468fcb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0477395df304ab59c230e920a43d330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86ef8a95adf41c0863d20f369ad81be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ce32838d3d469ea65e315694177c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dda19f5e2ee416daddc06e86e4afd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad1d9310efdf4333ab2f9367ebd0d4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8080c34bb34a689ae548b488af29aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLg-77AZzbQ6",
        "outputId": "4d952e06-0a84-4709-9ec1-68e3d1208dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/gdrive/MyDrive/CaTr'"
      ],
      "metadata": {
        "id": "nqgTJDfQzntJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/gdrive/MyDrive/CaTr' && git clone 'https://github.com/saahiluppal/catr.git'"
      ],
      "metadata": {
        "id": "OuubhXA4z9J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/gdrive/MyDrive/CaTr/catr' && git pull 'https://github.com/saahiluppal/catr.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nwgegU20Fs-",
        "outputId": "e246474a-0f90-4513-8b3d-82904e9e06b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/saahiluppal/catr\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.hub.load('saahiluppal/catr', 'v3', pretrained=True) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "89a3644b62ad4ad0a5fda0b591bb857f",
            "26f78530e6494f6daa6f08d8fb7cfc11",
            "d7c46e4d2101406b945e20bfcf42714f",
            "4cc5b0d3fb0c41d79fb7c91b57bec7b7",
            "57509072f16943b0b1a3059a4ae89884",
            "6ab2d44d35c64e31bf5a01237857d026",
            "7db2c2b7bd964e0b8a8a60a3974c26af",
            "318e9f8a241e4f479ddf4d93af81a294",
            "fdb1eaa8919c48db88f6196525aa11cc",
            "9762e04a9f664f04bf7cb2b4fa62cd86",
            "ad97c7e0f4b843c0a40120e69b5666da",
            "b8adc431bcdb4dbcbf4b032603165797",
            "a89fb3ca91264d24a4d82fb1ff09f480",
            "0408eb448c974cc284fee81c6cc4f5c7",
            "38415f9fae394b3ea7358a2286a687ad",
            "1515a1447b3942f0992d3317468fcb62",
            "d0477395df304ab59c230e920a43d330",
            "d86ef8a95adf41c0863d20f369ad81be",
            "71ce32838d3d469ea65e315694177c2a",
            "5dda19f5e2ee416daddc06e86e4afd2d",
            "ad1d9310efdf4333ab2f9367ebd0d4a3",
            "5c8080c34bb34a689ae548b488af29aa"
          ]
        },
        "id": "_J4Wxtuv2u2C",
        "outputId": "1d4ce78d-36ed-4d8d-a019-28031f7d7418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/saahiluppal/catr/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/171M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89a3644b62ad4ad0a5fda0b591bb857f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/saahiluppal/catr/releases/download/0.2/weight493084032.pth\" to /root/.cache/torch/hub/checkpoints/weight493084032.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/322M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8adc431bcdb4dbcbf4b032603165797"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r '/content/gdrive/MyDrive/CaTr/catr/requirements.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofKHrBBI3RiP",
        "outputId": "50a50d83-4a78-40c5-8f3f-795f45070f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 1)) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (0.13.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 3)) (1.21.6)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 5)) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 4)) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 4)) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 4)) (4.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 4)) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/gdrive/MyDrive/CaTr/catr/requirements.txt (line 2)) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir 'trainingImages'"
      ],
      "metadata": {
        "id": "yx_pdmbrBL2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/trainingImages' && jar xvf '/content/gdrive/MyDrive/BLtraining.zip' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPkTc13XBOfm",
        "outputId": "c74fcb6b-7a4f-4a78-ef52-4cdcf239e510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " inflated: BLtraining/309.png\n",
            " inflated: BLtraining/3090.png\n",
            " inflated: BLtraining/3091.png\n",
            " inflated: BLtraining/3092.png\n",
            " inflated: BLtraining/3093.png\n",
            " inflated: BLtraining/3094.png\n",
            " inflated: BLtraining/3095.png\n",
            " inflated: BLtraining/3096.png\n",
            " inflated: BLtraining/3097.png\n",
            " inflated: BLtraining/3098.png\n",
            " inflated: BLtraining/3099.png\n",
            " inflated: BLtraining/31.png\n",
            " inflated: BLtraining/310.png\n",
            " inflated: BLtraining/3100.png\n",
            " inflated: BLtraining/3101.png\n",
            " inflated: BLtraining/3102.png\n",
            " inflated: BLtraining/3103.png\n",
            " inflated: BLtraining/3104.png\n",
            " inflated: BLtraining/3105.png\n",
            " inflated: BLtraining/3106.png\n",
            " inflated: BLtraining/3107.png\n",
            " inflated: BLtraining/3108.png\n",
            " inflated: BLtraining/3109.png\n",
            " inflated: BLtraining/311.png\n",
            " inflated: BLtraining/3110.png\n",
            " inflated: BLtraining/3111.png\n",
            " inflated: BLtraining/3112.png\n",
            " inflated: BLtraining/3113.png\n",
            " inflated: BLtraining/3114.png\n",
            " inflated: BLtraining/3115.png\n",
            " inflated: BLtraining/3116.png\n",
            " inflated: BLtraining/3117.png\n",
            " inflated: BLtraining/3118.png\n",
            " inflated: BLtraining/3119.png\n",
            " inflated: BLtraining/312.png\n",
            " inflated: BLtraining/3120.png\n",
            " inflated: BLtraining/3121.png\n",
            " inflated: BLtraining/3122.png\n",
            " inflated: BLtraining/3123.png\n",
            " inflated: BLtraining/3124.png\n",
            " inflated: BLtraining/3125.png\n",
            " inflated: BLtraining/3126.png\n",
            " inflated: BLtraining/3127.png\n",
            " inflated: BLtraining/3128.png\n",
            " inflated: BLtraining/3129.png\n",
            " inflated: BLtraining/313.png\n",
            " inflated: BLtraining/3130.png\n",
            " inflated: BLtraining/3131.png\n",
            " inflated: BLtraining/3132.png\n",
            " inflated: BLtraining/3133.png\n",
            " inflated: BLtraining/3134.png\n",
            " inflated: BLtraining/3135.png\n",
            " inflated: BLtraining/3136.png\n",
            " inflated: BLtraining/3137.png\n",
            " inflated: BLtraining/3138.png\n",
            " inflated: BLtraining/3139.png\n",
            " inflated: BLtraining/314.png\n",
            " inflated: BLtraining/3140.png\n",
            " inflated: BLtraining/3141.png\n",
            " inflated: BLtraining/3142.png\n",
            " inflated: BLtraining/3143.png\n",
            " inflated: BLtraining/3144.png\n",
            " inflated: BLtraining/3145.png\n",
            " inflated: BLtraining/3146.png\n",
            " inflated: BLtraining/3147.png\n",
            " inflated: BLtraining/3148.png\n",
            " inflated: BLtraining/3149.png\n",
            " inflated: BLtraining/315.png\n",
            " inflated: BLtraining/3150.png\n",
            " inflated: BLtraining/3151.png\n",
            " inflated: BLtraining/3152.png\n",
            " inflated: BLtraining/3153.png\n",
            " inflated: BLtraining/3154.png\n",
            " inflated: BLtraining/3155.png\n",
            " inflated: BLtraining/3156.png\n",
            " inflated: BLtraining/3157.png\n",
            " inflated: BLtraining/3158.png\n",
            " inflated: BLtraining/3159.png\n",
            " inflated: BLtraining/316.png\n",
            " inflated: BLtraining/3160.png\n",
            " inflated: BLtraining/3161.png\n",
            " inflated: BLtraining/3162.png\n",
            " inflated: BLtraining/3163.png\n",
            " inflated: BLtraining/3164.png\n",
            " inflated: BLtraining/3165.png\n",
            " inflated: BLtraining/3166.png\n",
            " inflated: BLtraining/3167.png\n",
            " inflated: BLtraining/3168.png\n",
            " inflated: BLtraining/3169.png\n",
            " inflated: BLtraining/317.png\n",
            " inflated: BLtraining/3170.png\n",
            " inflated: BLtraining/3171.png\n",
            " inflated: BLtraining/3172.png\n",
            " inflated: BLtraining/3173.png\n",
            " inflated: BLtraining/3174.png\n",
            " inflated: BLtraining/3175.png\n",
            " inflated: BLtraining/3176.png\n",
            " inflated: BLtraining/3177.png\n",
            " inflated: BLtraining/3178.png\n",
            " inflated: BLtraining/3179.png\n",
            " inflated: BLtraining/318.png\n",
            " inflated: BLtraining/3180.png\n",
            " inflated: BLtraining/3181.png\n",
            " inflated: BLtraining/3182.png\n",
            " inflated: BLtraining/3183.png\n",
            " inflated: BLtraining/3184.png\n",
            " inflated: BLtraining/3185.png\n",
            " inflated: BLtraining/3186.png\n",
            " inflated: BLtraining/3187.png\n",
            " inflated: BLtraining/3188.png\n",
            " inflated: BLtraining/3189.png\n",
            " inflated: BLtraining/319.png\n",
            " inflated: BLtraining/3190.png\n",
            " inflated: BLtraining/3191.png\n",
            " inflated: BLtraining/3192.png\n",
            " inflated: BLtraining/3193.png\n",
            " inflated: BLtraining/3194.png\n",
            " inflated: BLtraining/3195.png\n",
            " inflated: BLtraining/3196.png\n",
            " inflated: BLtraining/3197.png\n",
            " inflated: BLtraining/3198.png\n",
            " inflated: BLtraining/3199.png\n",
            " inflated: BLtraining/32.png\n",
            " inflated: BLtraining/320.png\n",
            " inflated: BLtraining/3200.png\n",
            " inflated: BLtraining/3201.png\n",
            " inflated: BLtraining/3202.png\n",
            " inflated: BLtraining/3203.png\n",
            " inflated: BLtraining/3204.png\n",
            " inflated: BLtraining/3205.png\n",
            " inflated: BLtraining/3206.png\n",
            " inflated: BLtraining/3207.png\n",
            " inflated: BLtraining/3208.png\n",
            " inflated: BLtraining/3209.png\n",
            " inflated: BLtraining/321.png\n",
            " inflated: BLtraining/3210.png\n",
            " inflated: BLtraining/3211.png\n",
            " inflated: BLtraining/3212.png\n",
            " inflated: BLtraining/3213.png\n",
            " inflated: BLtraining/3214.png\n",
            " inflated: BLtraining/3215.png\n",
            " inflated: BLtraining/3216.png\n",
            " inflated: BLtraining/3217.png\n",
            " inflated: BLtraining/3218.png\n",
            " inflated: BLtraining/3219.png\n",
            " inflated: BLtraining/322.png\n",
            " inflated: BLtraining/3220.png\n",
            " inflated: BLtraining/3221.png\n",
            " inflated: BLtraining/3222.png\n",
            " inflated: BLtraining/3223.png\n",
            " inflated: BLtraining/3224.png\n",
            " inflated: BLtraining/3225.png\n",
            " inflated: BLtraining/3226.png\n",
            " inflated: BLtraining/3227.png\n",
            " inflated: BLtraining/3228.png\n",
            " inflated: BLtraining/3229.png\n",
            " inflated: BLtraining/323.png\n",
            " inflated: BLtraining/3230.png\n",
            " inflated: BLtraining/3231.png\n",
            " inflated: BLtraining/3232.png\n",
            " inflated: BLtraining/3233.png\n",
            " inflated: BLtraining/3234.png\n",
            " inflated: BLtraining/3235.png\n",
            " inflated: BLtraining/3236.png\n",
            " inflated: BLtraining/3237.png\n",
            " inflated: BLtraining/3238.png\n",
            " inflated: BLtraining/3239.png\n",
            " inflated: BLtraining/324.png\n",
            " inflated: BLtraining/3240.png\n",
            " inflated: BLtraining/3241.png\n",
            " inflated: BLtraining/3242.png\n",
            " inflated: BLtraining/3243.png\n",
            " inflated: BLtraining/3244.png\n",
            " inflated: BLtraining/3245.png\n",
            " inflated: BLtraining/3246.png\n",
            " inflated: BLtraining/3247.png\n",
            " inflated: BLtraining/3248.png\n",
            " inflated: BLtraining/3249.png\n",
            " inflated: BLtraining/325.png\n",
            " inflated: BLtraining/3250.png\n",
            " inflated: BLtraining/3251.png\n",
            " inflated: BLtraining/3252.png\n",
            " inflated: BLtraining/3253.png\n",
            " inflated: BLtraining/3254.png\n",
            " inflated: BLtraining/3255.png\n",
            " inflated: BLtraining/3256.png\n",
            " inflated: BLtraining/3257.png\n",
            " inflated: BLtraining/3258.png\n",
            " inflated: BLtraining/3259.png\n",
            " inflated: BLtraining/326.png\n",
            " inflated: BLtraining/3260.png\n",
            " inflated: BLtraining/3261.png\n",
            " inflated: BLtraining/3262.png\n",
            " inflated: BLtraining/3263.png\n",
            " inflated: BLtraining/3264.png\n",
            " inflated: BLtraining/3265.png\n",
            " inflated: BLtraining/3266.png\n",
            " inflated: BLtraining/3267.png\n",
            " inflated: BLtraining/3268.png\n",
            " inflated: BLtraining/3269.png\n",
            " inflated: BLtraining/327.png\n",
            " inflated: BLtraining/3270.png\n",
            " inflated: BLtraining/3271.png\n",
            " inflated: BLtraining/3272.png\n",
            " inflated: BLtraining/3273.png\n",
            " inflated: BLtraining/3274.png\n",
            " inflated: BLtraining/3275.png\n",
            " inflated: BLtraining/3276.png\n",
            " inflated: BLtraining/3277.png\n",
            " inflated: BLtraining/3278.png\n",
            " inflated: BLtraining/3279.png\n",
            " inflated: BLtraining/328.png\n",
            " inflated: BLtraining/3280.png\n",
            " inflated: BLtraining/3281.png\n",
            " inflated: BLtraining/3282.png\n",
            " inflated: BLtraining/3283.png\n",
            " inflated: BLtraining/3284.png\n",
            " inflated: BLtraining/3285.png\n",
            " inflated: BLtraining/3286.png\n",
            " inflated: BLtraining/3287.png\n",
            " inflated: BLtraining/3288.png\n",
            " inflated: BLtraining/3289.png\n",
            " inflated: BLtraining/329.png\n",
            " inflated: BLtraining/3290.png\n",
            " inflated: BLtraining/3291.png\n",
            " inflated: BLtraining/3292.png\n",
            " inflated: BLtraining/3293.png\n",
            " inflated: BLtraining/3294.png\n",
            " inflated: BLtraining/3295.png\n",
            " inflated: BLtraining/3296.png\n",
            " inflated: BLtraining/3297.png\n",
            " inflated: BLtraining/3298.png\n",
            " inflated: BLtraining/3299.png\n",
            " inflated: BLtraining/33.png\n",
            " inflated: BLtraining/330.png\n",
            " inflated: BLtraining/3300.png\n",
            " inflated: BLtraining/3301.png\n",
            " inflated: BLtraining/3302.png\n",
            " inflated: BLtraining/3303.png\n",
            " inflated: BLtraining/3304.png\n",
            " inflated: BLtraining/3305.png\n",
            " inflated: BLtraining/3306.png\n",
            " inflated: BLtraining/3307.png\n",
            " inflated: BLtraining/3308.png\n",
            " inflated: BLtraining/3309.png\n",
            " inflated: BLtraining/331.png\n",
            " inflated: BLtraining/3310.png\n",
            " inflated: BLtraining/3311.png\n",
            " inflated: BLtraining/3312.png\n",
            " inflated: BLtraining/3313.png\n",
            " inflated: BLtraining/3314.png\n",
            " inflated: BLtraining/3315.png\n",
            " inflated: BLtraining/3316.png\n",
            " inflated: BLtraining/3317.png\n",
            " inflated: BLtraining/3318.png\n",
            " inflated: BLtraining/3319.png\n",
            " inflated: BLtraining/332.png\n",
            " inflated: BLtraining/3320.png\n",
            " inflated: BLtraining/3321.png\n",
            " inflated: BLtraining/3322.png\n",
            " inflated: BLtraining/3323.png\n",
            " inflated: BLtraining/3324.png\n",
            " inflated: BLtraining/3325.png\n",
            " inflated: BLtraining/3326.png\n",
            " inflated: BLtraining/3327.png\n",
            " inflated: BLtraining/3328.png\n",
            " inflated: BLtraining/3329.png\n",
            " inflated: BLtraining/333.png\n",
            " inflated: BLtraining/3330.png\n",
            " inflated: BLtraining/3331.png\n",
            " inflated: BLtraining/3332.png\n",
            " inflated: BLtraining/3333.png\n",
            " inflated: BLtraining/3334.png\n",
            " inflated: BLtraining/3335.png\n",
            " inflated: BLtraining/3336.png\n",
            " inflated: BLtraining/3337.png\n",
            " inflated: BLtraining/3338.png\n",
            " inflated: BLtraining/3339.png\n",
            " inflated: BLtraining/334.png\n",
            " inflated: BLtraining/3340.png\n",
            " inflated: BLtraining/3341.png\n",
            " inflated: BLtraining/3342.png\n",
            " inflated: BLtraining/3343.png\n",
            " inflated: BLtraining/3344.png\n",
            " inflated: BLtraining/3345.png\n",
            " inflated: BLtraining/3346.png\n",
            " inflated: BLtraining/3347.png\n",
            " inflated: BLtraining/3348.png\n",
            " inflated: BLtraining/3349.png\n",
            " inflated: BLtraining/335.png\n",
            " inflated: BLtraining/3350.png\n",
            " inflated: BLtraining/3351.png\n",
            " inflated: BLtraining/3352.png\n",
            " inflated: BLtraining/3353.png\n",
            " inflated: BLtraining/3354.png\n",
            " inflated: BLtraining/3355.png\n",
            " inflated: BLtraining/3356.png\n",
            " inflated: BLtraining/3357.png\n",
            " inflated: BLtraining/3358.png\n",
            " inflated: BLtraining/3359.png\n",
            " inflated: BLtraining/336.png\n",
            " inflated: BLtraining/3360.png\n",
            " inflated: BLtraining/3361.png\n",
            " inflated: BLtraining/3362.png\n",
            " inflated: BLtraining/3363.png\n",
            " inflated: BLtraining/3364.png\n",
            " inflated: BLtraining/3365.png\n",
            " inflated: BLtraining/3366.png\n",
            " inflated: BLtraining/3367.png\n",
            " inflated: BLtraining/3368.png\n",
            " inflated: BLtraining/3369.png\n",
            " inflated: BLtraining/337.png\n",
            " inflated: BLtraining/3370.png\n",
            " inflated: BLtraining/3371.png\n",
            " inflated: BLtraining/3372.png\n",
            " inflated: BLtraining/3373.png\n",
            " inflated: BLtraining/3374.png\n",
            " inflated: BLtraining/3375.png\n",
            " inflated: BLtraining/3376.png\n",
            " inflated: BLtraining/3377.png\n",
            " inflated: BLtraining/3378.png\n",
            " inflated: BLtraining/3379.png\n",
            " inflated: BLtraining/338.png\n",
            " inflated: BLtraining/3380.png\n",
            " inflated: BLtraining/3381.png\n",
            " inflated: BLtraining/3382.png\n",
            " inflated: BLtraining/3383.png\n",
            " inflated: BLtraining/3384.png\n",
            " inflated: BLtraining/3385.png\n",
            " inflated: BLtraining/3386.png\n",
            " inflated: BLtraining/3387.png\n",
            " inflated: BLtraining/3388.png\n",
            " inflated: BLtraining/3389.png\n",
            " inflated: BLtraining/339.png\n",
            " inflated: BLtraining/3390.png\n",
            " inflated: BLtraining/3391.png\n",
            " inflated: BLtraining/3392.png\n",
            " inflated: BLtraining/3393.png\n",
            " inflated: BLtraining/3394.png\n",
            " inflated: BLtraining/3395.png\n",
            " inflated: BLtraining/3396.png\n",
            " inflated: BLtraining/3397.png\n",
            " inflated: BLtraining/3398.png\n",
            " inflated: BLtraining/3399.png\n",
            " inflated: BLtraining/34.png\n",
            " inflated: BLtraining/340.png\n",
            " inflated: BLtraining/3400.png\n",
            " inflated: BLtraining/3401.png\n",
            " inflated: BLtraining/3402.png\n",
            " inflated: BLtraining/3403.png\n",
            " inflated: BLtraining/3404.png\n",
            " inflated: BLtraining/3405.png\n",
            " inflated: BLtraining/3406.png\n",
            " inflated: BLtraining/3407.png\n",
            " inflated: BLtraining/3408.png\n",
            " inflated: BLtraining/3409.png\n",
            " inflated: BLtraining/341.png\n",
            " inflated: BLtraining/3410.png\n",
            " inflated: BLtraining/3411.png\n",
            " inflated: BLtraining/3412.png\n",
            " inflated: BLtraining/3413.png\n",
            " inflated: BLtraining/3414.png\n",
            " inflated: BLtraining/3415.png\n",
            " inflated: BLtraining/3416.png\n",
            " inflated: BLtraining/3417.png\n",
            " inflated: BLtraining/3418.png\n",
            " inflated: BLtraining/3419.png\n",
            " inflated: BLtraining/342.png\n",
            " inflated: BLtraining/3420.png\n",
            " inflated: BLtraining/3421.png\n",
            " inflated: BLtraining/3422.png\n",
            " inflated: BLtraining/3423.png\n",
            " inflated: BLtraining/3424.png\n",
            " inflated: BLtraining/3425.png\n",
            " inflated: BLtraining/3426.png\n",
            " inflated: BLtraining/3427.png\n",
            " inflated: BLtraining/3428.png\n",
            " inflated: BLtraining/3429.png\n",
            " inflated: BLtraining/343.png\n",
            " inflated: BLtraining/3430.png\n",
            " inflated: BLtraining/3431.png\n",
            " inflated: BLtraining/3432.png\n",
            " inflated: BLtraining/3433.png\n",
            " inflated: BLtraining/3434.png\n",
            " inflated: BLtraining/3435.png\n",
            " inflated: BLtraining/3436.png\n",
            " inflated: BLtraining/3437.png\n",
            " inflated: BLtraining/3438.png\n",
            " inflated: BLtraining/3439.png\n",
            " inflated: BLtraining/344.png\n",
            " inflated: BLtraining/3440.png\n",
            " inflated: BLtraining/3441.png\n",
            " inflated: BLtraining/3442.png\n",
            " inflated: BLtraining/3443.png\n",
            " inflated: BLtraining/3444.png\n",
            " inflated: BLtraining/3445.png\n",
            " inflated: BLtraining/3446.png\n",
            " inflated: BLtraining/3447.png\n",
            " inflated: BLtraining/3448.png\n",
            " inflated: BLtraining/3449.png\n",
            " inflated: BLtraining/345.png\n",
            " inflated: BLtraining/3450.png\n",
            " inflated: BLtraining/3451.png\n",
            " inflated: BLtraining/3452.png\n",
            " inflated: BLtraining/3453.png\n",
            " inflated: BLtraining/3454.png\n",
            " inflated: BLtraining/3455.png\n",
            " inflated: BLtraining/3456.png\n",
            " inflated: BLtraining/3457.png\n",
            " inflated: BLtraining/3458.png\n",
            " inflated: BLtraining/3459.png\n",
            " inflated: BLtraining/346.png\n",
            " inflated: BLtraining/3460.png\n",
            " inflated: BLtraining/3461.png\n",
            " inflated: BLtraining/3462.png\n",
            " inflated: BLtraining/3463.png\n",
            " inflated: BLtraining/3464.png\n",
            " inflated: BLtraining/3465.png\n",
            " inflated: BLtraining/3466.png\n",
            " inflated: BLtraining/3467.png\n",
            " inflated: BLtraining/3468.png\n",
            " inflated: BLtraining/3469.png\n",
            " inflated: BLtraining/347.png\n",
            " inflated: BLtraining/3470.png\n",
            " inflated: BLtraining/3471.png\n",
            " inflated: BLtraining/3472.png\n",
            " inflated: BLtraining/3473.png\n",
            " inflated: BLtraining/3474.png\n",
            " inflated: BLtraining/3475.png\n",
            " inflated: BLtraining/3476.png\n",
            " inflated: BLtraining/3477.png\n",
            " inflated: BLtraining/3478.png\n",
            " inflated: BLtraining/3479.png\n",
            " inflated: BLtraining/348.png\n",
            " inflated: BLtraining/3480.png\n",
            " inflated: BLtraining/3481.png\n",
            " inflated: BLtraining/3482.png\n",
            " inflated: BLtraining/3483.png\n",
            " inflated: BLtraining/3484.png\n",
            " inflated: BLtraining/3485.png\n",
            " inflated: BLtraining/3486.png\n",
            " inflated: BLtraining/3487.png\n",
            " inflated: BLtraining/3488.png\n",
            " inflated: BLtraining/3489.png\n",
            " inflated: BLtraining/349.png\n",
            " inflated: BLtraining/3490.png\n",
            " inflated: BLtraining/3491.png\n",
            " inflated: BLtraining/3492.png\n",
            " inflated: BLtraining/3493.png\n",
            " inflated: BLtraining/3494.png\n",
            " inflated: BLtraining/3495.png\n",
            " inflated: BLtraining/3496.png\n",
            " inflated: BLtraining/3497.png\n",
            " inflated: BLtraining/3498.png\n",
            " inflated: BLtraining/3499.png\n",
            " inflated: BLtraining/35.png\n",
            " inflated: BLtraining/350.png\n",
            " inflated: BLtraining/3500.png\n",
            " inflated: BLtraining/3501.png\n",
            " inflated: BLtraining/3502.png\n",
            " inflated: BLtraining/3503.png\n",
            " inflated: BLtraining/3504.png\n",
            " inflated: BLtraining/3505.png\n",
            " inflated: BLtraining/3506.png\n",
            " inflated: BLtraining/3507.png\n",
            " inflated: BLtraining/3508.png\n",
            " inflated: BLtraining/3509.png\n",
            " inflated: BLtraining/351.png\n",
            " inflated: BLtraining/3510.png\n",
            " inflated: BLtraining/3511.png\n",
            " inflated: BLtraining/3512.png\n",
            " inflated: BLtraining/3513.png\n",
            " inflated: BLtraining/3514.png\n",
            " inflated: BLtraining/3515.png\n",
            " inflated: BLtraining/3516.png\n",
            " inflated: BLtraining/3517.png\n",
            " inflated: BLtraining/3518.png\n",
            " inflated: BLtraining/3519.png\n",
            " inflated: BLtraining/352.png\n",
            " inflated: BLtraining/3520.png\n",
            " inflated: BLtraining/3521.png\n",
            " inflated: BLtraining/3522.png\n",
            " inflated: BLtraining/3523.png\n",
            " inflated: BLtraining/3524.png\n",
            " inflated: BLtraining/3525.png\n",
            " inflated: BLtraining/3526.png\n",
            " inflated: BLtraining/3527.png\n",
            " inflated: BLtraining/3528.png\n",
            " inflated: BLtraining/3529.png\n",
            " inflated: BLtraining/353.png\n",
            " inflated: BLtraining/3530.png\n",
            " inflated: BLtraining/3531.png\n",
            " inflated: BLtraining/3532.png\n",
            " inflated: BLtraining/3533.png\n",
            " inflated: BLtraining/3534.png\n",
            " inflated: BLtraining/3535.png\n",
            " inflated: BLtraining/3536.png\n",
            " inflated: BLtraining/3537.png\n",
            " inflated: BLtraining/3538.png\n",
            " inflated: BLtraining/3539.png\n",
            " inflated: BLtraining/354.png\n",
            " inflated: BLtraining/3540.png\n",
            " inflated: BLtraining/3541.png\n",
            " inflated: BLtraining/3542.png\n",
            " inflated: BLtraining/3543.png\n",
            " inflated: BLtraining/3544.png\n",
            " inflated: BLtraining/3545.png\n",
            " inflated: BLtraining/3546.png\n",
            " inflated: BLtraining/3547.png\n",
            " inflated: BLtraining/3548.png\n",
            " inflated: BLtraining/3549.png\n",
            " inflated: BLtraining/355.png\n",
            " inflated: BLtraining/3550.png\n",
            " inflated: BLtraining/3551.png\n",
            " inflated: BLtraining/3552.png\n",
            " inflated: BLtraining/3553.png\n",
            " inflated: BLtraining/3554.png\n",
            " inflated: BLtraining/3555.png\n",
            " inflated: BLtraining/3556.png\n",
            " inflated: BLtraining/3557.png\n",
            " inflated: BLtraining/3558.png\n",
            " inflated: BLtraining/3559.png\n",
            " inflated: BLtraining/356.png\n",
            " inflated: BLtraining/3560.png\n",
            " inflated: BLtraining/3561.png\n",
            " inflated: BLtraining/3562.png\n",
            " inflated: BLtraining/3563.png\n",
            " inflated: BLtraining/3564.png\n",
            " inflated: BLtraining/3565.png\n",
            " inflated: BLtraining/3566.png\n",
            " inflated: BLtraining/3567.png\n",
            " inflated: BLtraining/3568.png\n",
            " inflated: BLtraining/3569.png\n",
            " inflated: BLtraining/357.png\n",
            " inflated: BLtraining/3570.png\n",
            " inflated: BLtraining/3571.png\n",
            " inflated: BLtraining/3572.png\n",
            " inflated: BLtraining/3573.png\n",
            " inflated: BLtraining/3574.png\n",
            " inflated: BLtraining/3575.png\n",
            " inflated: BLtraining/3576.png\n",
            " inflated: BLtraining/3577.png\n",
            " inflated: BLtraining/3578.png\n",
            " inflated: BLtraining/3579.png\n",
            " inflated: BLtraining/358.png\n",
            " inflated: BLtraining/3580.png\n",
            " inflated: BLtraining/3581.png\n",
            " inflated: BLtraining/3582.png\n",
            " inflated: BLtraining/3583.png\n",
            " inflated: BLtraining/3584.png\n",
            " inflated: BLtraining/3585.png\n",
            " inflated: BLtraining/3586.png\n",
            " inflated: BLtraining/3587.png\n",
            " inflated: BLtraining/3588.png\n",
            " inflated: BLtraining/3589.png\n",
            " inflated: BLtraining/359.png\n",
            " inflated: BLtraining/3590.png\n",
            " inflated: BLtraining/3591.png\n",
            " inflated: BLtraining/3592.png\n",
            " inflated: BLtraining/3593.png\n",
            " inflated: BLtraining/3594.png\n",
            " inflated: BLtraining/3595.png\n",
            " inflated: BLtraining/3596.png\n",
            " inflated: BLtraining/3597.png\n",
            " inflated: BLtraining/3598.png\n",
            " inflated: BLtraining/3599.png\n",
            " inflated: BLtraining/36.png\n",
            " inflated: BLtraining/360.png\n",
            " inflated: BLtraining/3600.png\n",
            " inflated: BLtraining/3601.png\n",
            " inflated: BLtraining/3602.png\n",
            " inflated: BLtraining/3603.png\n",
            " inflated: BLtraining/3604.png\n",
            " inflated: BLtraining/3605.png\n",
            " inflated: BLtraining/3606.png\n",
            " inflated: BLtraining/3607.png\n",
            " inflated: BLtraining/3608.png\n",
            " inflated: BLtraining/3609.png\n",
            " inflated: BLtraining/361.png\n",
            " inflated: BLtraining/3610.png\n",
            " inflated: BLtraining/3611.png\n",
            " inflated: BLtraining/3612.png\n",
            " inflated: BLtraining/3613.png\n",
            " inflated: BLtraining/3614.png\n",
            " inflated: BLtraining/3615.png\n",
            " inflated: BLtraining/3616.png\n",
            " inflated: BLtraining/3617.png\n",
            " inflated: BLtraining/3618.png\n",
            " inflated: BLtraining/3619.png\n",
            " inflated: BLtraining/362.png\n",
            " inflated: BLtraining/3620.png\n",
            " inflated: BLtraining/3621.png\n",
            " inflated: BLtraining/3622.png\n",
            " inflated: BLtraining/3623.png\n",
            " inflated: BLtraining/3624.png\n",
            " inflated: BLtraining/3625.png\n",
            " inflated: BLtraining/3626.png\n",
            " inflated: BLtraining/3627.png\n",
            " inflated: BLtraining/3628.png\n",
            " inflated: BLtraining/3629.png\n",
            " inflated: BLtraining/363.png\n",
            " inflated: BLtraining/3630.png\n",
            " inflated: BLtraining/3631.png\n",
            " inflated: BLtraining/3632.png\n",
            " inflated: BLtraining/3633.png\n",
            " inflated: BLtraining/3634.png\n",
            " inflated: BLtraining/3635.png\n",
            " inflated: BLtraining/3636.png\n",
            " inflated: BLtraining/3637.png\n",
            " inflated: BLtraining/3638.png\n",
            " inflated: BLtraining/3639.png\n",
            " inflated: BLtraining/364.png\n",
            " inflated: BLtraining/3640.png\n",
            " inflated: BLtraining/3641.png\n",
            " inflated: BLtraining/3642.png\n",
            " inflated: BLtraining/3643.png\n",
            " inflated: BLtraining/3644.png\n",
            " inflated: BLtraining/3645.png\n",
            " inflated: BLtraining/3646.png\n",
            " inflated: BLtraining/3647.png\n",
            " inflated: BLtraining/3648.png\n",
            " inflated: BLtraining/3649.png\n",
            " inflated: BLtraining/365.png\n",
            " inflated: BLtraining/3650.png\n",
            " inflated: BLtraining/3651.png\n",
            " inflated: BLtraining/3652.png\n",
            " inflated: BLtraining/3653.png\n",
            " inflated: BLtraining/3654.png\n",
            " inflated: BLtraining/3655.png\n",
            " inflated: BLtraining/3656.png\n",
            " inflated: BLtraining/3657.png\n",
            " inflated: BLtraining/3658.png\n",
            " inflated: BLtraining/3659.png\n",
            " inflated: BLtraining/366.png\n",
            " inflated: BLtraining/3660.png\n",
            " inflated: BLtraining/3661.png\n",
            " inflated: BLtraining/3662.png\n",
            " inflated: BLtraining/3663.png\n",
            " inflated: BLtraining/3664.png\n",
            " inflated: BLtraining/3665.png\n",
            " inflated: BLtraining/3666.png\n",
            " inflated: BLtraining/3667.png\n",
            " inflated: BLtraining/3668.png\n",
            " inflated: BLtraining/3669.png\n",
            " inflated: BLtraining/367.png\n",
            " inflated: BLtraining/3670.png\n",
            " inflated: BLtraining/3671.png\n",
            " inflated: BLtraining/3672.png\n",
            " inflated: BLtraining/3673.png\n",
            " inflated: BLtraining/3674.png\n",
            " inflated: BLtraining/3675.png\n",
            " inflated: BLtraining/3676.png\n",
            " inflated: BLtraining/3677.png\n",
            " inflated: BLtraining/3678.png\n",
            " inflated: BLtraining/3679.png\n",
            " inflated: BLtraining/368.png\n",
            " inflated: BLtraining/3680.png\n",
            " inflated: BLtraining/3681.png\n",
            " inflated: BLtraining/3682.png\n",
            " inflated: BLtraining/3683.png\n",
            " inflated: BLtraining/3684.png\n",
            " inflated: BLtraining/3685.png\n",
            " inflated: BLtraining/3686.png\n",
            " inflated: BLtraining/3687.png\n",
            " inflated: BLtraining/3688.png\n",
            " inflated: BLtraining/3689.png\n",
            " inflated: BLtraining/369.png\n",
            " inflated: BLtraining/3690.png\n",
            " inflated: BLtraining/3691.png\n",
            " inflated: BLtraining/3692.png\n",
            " inflated: BLtraining/3693.png\n",
            " inflated: BLtraining/3694.png\n",
            " inflated: BLtraining/3695.png\n",
            " inflated: BLtraining/3696.png\n",
            " inflated: BLtraining/3697.png\n",
            " inflated: BLtraining/3698.png\n",
            " inflated: BLtraining/3699.png\n",
            " inflated: BLtraining/37.png\n",
            " inflated: BLtraining/370.png\n",
            " inflated: BLtraining/3700.png\n",
            " inflated: BLtraining/3701.png\n",
            " inflated: BLtraining/3702.png\n",
            " inflated: BLtraining/3703.png\n",
            " inflated: BLtraining/3704.png\n",
            " inflated: BLtraining/3705.png\n",
            " inflated: BLtraining/3706.png\n",
            " inflated: BLtraining/3707.png\n",
            " inflated: BLtraining/3708.png\n",
            " inflated: BLtraining/3709.png\n",
            " inflated: BLtraining/371.png\n",
            " inflated: BLtraining/3710.png\n",
            " inflated: BLtraining/3711.png\n",
            " inflated: BLtraining/3712.png\n",
            " inflated: BLtraining/3713.png\n",
            " inflated: BLtraining/3714.png\n",
            " inflated: BLtraining/3715.png\n",
            " inflated: BLtraining/3716.png\n",
            " inflated: BLtraining/3717.png\n",
            " inflated: BLtraining/3718.png\n",
            " inflated: BLtraining/3719.png\n",
            " inflated: BLtraining/372.png\n",
            " inflated: BLtraining/3720.png\n",
            " inflated: BLtraining/3721.png\n",
            " inflated: BLtraining/3722.png\n",
            " inflated: BLtraining/3723.png\n",
            " inflated: BLtraining/3724.png\n",
            " inflated: BLtraining/3725.png\n",
            " inflated: BLtraining/3726.png\n",
            " inflated: BLtraining/3727.png\n",
            " inflated: BLtraining/3728.png\n",
            " inflated: BLtraining/3729.png\n",
            " inflated: BLtraining/373.png\n",
            " inflated: BLtraining/3730.png\n",
            " inflated: BLtraining/3731.png\n",
            " inflated: BLtraining/3732.png\n",
            " inflated: BLtraining/3733.png\n",
            " inflated: BLtraining/3734.png\n",
            " inflated: BLtraining/3735.png\n",
            " inflated: BLtraining/3736.png\n",
            " inflated: BLtraining/3737.png\n",
            " inflated: BLtraining/3738.png\n",
            " inflated: BLtraining/3739.png\n",
            " inflated: BLtraining/374.png\n",
            " inflated: BLtraining/3740.png\n",
            " inflated: BLtraining/3741.png\n",
            " inflated: BLtraining/3742.png\n",
            " inflated: BLtraining/3743.png\n",
            " inflated: BLtraining/3744.png\n",
            " inflated: BLtraining/3745.png\n",
            " inflated: BLtraining/3746.png\n",
            " inflated: BLtraining/3747.png\n",
            " inflated: BLtraining/3748.png\n",
            " inflated: BLtraining/3749.png\n",
            " inflated: BLtraining/375.png\n",
            " inflated: BLtraining/3750.png\n",
            " inflated: BLtraining/3751.png\n",
            " inflated: BLtraining/3752.png\n",
            " inflated: BLtraining/3753.png\n",
            " inflated: BLtraining/3754.png\n",
            " inflated: BLtraining/3755.png\n",
            " inflated: BLtraining/3756.png\n",
            " inflated: BLtraining/3757.png\n",
            " inflated: BLtraining/3758.png\n",
            " inflated: BLtraining/3759.png\n",
            " inflated: BLtraining/376.png\n",
            " inflated: BLtraining/3760.png\n",
            " inflated: BLtraining/3761.png\n",
            " inflated: BLtraining/3762.png\n",
            " inflated: BLtraining/3763.png\n",
            " inflated: BLtraining/3764.png\n",
            " inflated: BLtraining/3765.png\n",
            " inflated: BLtraining/3766.png\n",
            " inflated: BLtraining/3767.png\n",
            " inflated: BLtraining/3768.png\n",
            " inflated: BLtraining/3769.png\n",
            " inflated: BLtraining/377.png\n",
            " inflated: BLtraining/3770.png\n",
            " inflated: BLtraining/3771.png\n",
            " inflated: BLtraining/3772.png\n",
            " inflated: BLtraining/3773.png\n",
            " inflated: BLtraining/3774.png\n",
            " inflated: BLtraining/3775.png\n",
            " inflated: BLtraining/3776.png\n",
            " inflated: BLtraining/3777.png\n",
            " inflated: BLtraining/3778.png\n",
            " inflated: BLtraining/3779.png\n",
            " inflated: BLtraining/378.png\n",
            " inflated: BLtraining/3780.png\n",
            " inflated: BLtraining/3781.png\n",
            " inflated: BLtraining/3782.png\n",
            " inflated: BLtraining/3783.png\n",
            " inflated: BLtraining/3784.png\n",
            " inflated: BLtraining/3785.png\n",
            " inflated: BLtraining/3786.png\n",
            " inflated: BLtraining/3787.png\n",
            " inflated: BLtraining/3788.png\n",
            " inflated: BLtraining/3789.png\n",
            " inflated: BLtraining/379.png\n",
            " inflated: BLtraining/3790.png\n",
            " inflated: BLtraining/3791.png\n",
            " inflated: BLtraining/3792.png\n",
            " inflated: BLtraining/3793.png\n",
            " inflated: BLtraining/3794.png\n",
            " inflated: BLtraining/3795.png\n",
            " inflated: BLtraining/3796.png\n",
            " inflated: BLtraining/3797.png\n",
            " inflated: BLtraining/3798.png\n",
            " inflated: BLtraining/3799.png\n",
            " inflated: BLtraining/38.png\n",
            " inflated: BLtraining/380.png\n",
            " inflated: BLtraining/3800.png\n",
            " inflated: BLtraining/3801.png\n",
            " inflated: BLtraining/3802.png\n",
            " inflated: BLtraining/3803.png\n",
            " inflated: BLtraining/3804.png\n",
            " inflated: BLtraining/3805.png\n",
            " inflated: BLtraining/3806.png\n",
            " inflated: BLtraining/3807.png\n",
            " inflated: BLtraining/3808.png\n",
            " inflated: BLtraining/3809.png\n",
            " inflated: BLtraining/381.png\n",
            " inflated: BLtraining/3810.png\n",
            " inflated: BLtraining/3811.png\n",
            " inflated: BLtraining/3812.png\n",
            " inflated: BLtraining/3813.png\n",
            " inflated: BLtraining/3814.png\n",
            " inflated: BLtraining/3815.png\n",
            " inflated: BLtraining/3816.png\n",
            " inflated: BLtraining/3817.png\n",
            " inflated: BLtraining/3818.png\n",
            " inflated: BLtraining/3819.png\n",
            " inflated: BLtraining/382.png\n",
            " inflated: BLtraining/3820.png\n",
            " inflated: BLtraining/3821.png\n",
            " inflated: BLtraining/3822.png\n",
            " inflated: BLtraining/3823.png\n",
            " inflated: BLtraining/3824.png\n",
            " inflated: BLtraining/3825.png\n",
            " inflated: BLtraining/3826.png\n",
            " inflated: BLtraining/3827.png\n",
            " inflated: BLtraining/3828.png\n",
            " inflated: BLtraining/3829.png\n",
            " inflated: BLtraining/383.png\n",
            " inflated: BLtraining/3830.png\n",
            " inflated: BLtraining/3831.png\n",
            " inflated: BLtraining/3832.png\n",
            " inflated: BLtraining/3833.png\n",
            " inflated: BLtraining/3834.png\n",
            " inflated: BLtraining/3835.png\n",
            " inflated: BLtraining/3836.png\n",
            " inflated: BLtraining/3837.png\n",
            " inflated: BLtraining/3838.png\n",
            " inflated: BLtraining/3839.png\n",
            " inflated: BLtraining/384.png\n",
            " inflated: BLtraining/3840.png\n",
            " inflated: BLtraining/3841.png\n",
            " inflated: BLtraining/3842.png\n",
            " inflated: BLtraining/3843.png\n",
            " inflated: BLtraining/3844.png\n",
            " inflated: BLtraining/3845.png\n",
            " inflated: BLtraining/3846.png\n",
            " inflated: BLtraining/3847.png\n",
            " inflated: BLtraining/3848.png\n",
            " inflated: BLtraining/3849.png\n",
            " inflated: BLtraining/385.png\n",
            " inflated: BLtraining/3850.png\n",
            " inflated: BLtraining/3851.png\n",
            " inflated: BLtraining/3852.png\n",
            " inflated: BLtraining/3853.png\n",
            " inflated: BLtraining/3854.png\n",
            " inflated: BLtraining/3855.png\n",
            " inflated: BLtraining/3856.png\n",
            " inflated: BLtraining/3857.png\n",
            " inflated: BLtraining/3858.png\n",
            " inflated: BLtraining/3859.png\n",
            " inflated: BLtraining/386.png\n",
            " inflated: BLtraining/3860.png\n",
            " inflated: BLtraining/3861.png\n",
            " inflated: BLtraining/3862.png\n",
            " inflated: BLtraining/3863.png\n",
            " inflated: BLtraining/3864.png\n",
            " inflated: BLtraining/3865.png\n",
            " inflated: BLtraining/3866.png\n",
            " inflated: BLtraining/3867.png\n",
            " inflated: BLtraining/3868.png\n",
            " inflated: BLtraining/3869.png\n",
            " inflated: BLtraining/387.png\n",
            " inflated: BLtraining/3870.png\n",
            " inflated: BLtraining/3871.png\n",
            " inflated: BLtraining/3872.png\n",
            " inflated: BLtraining/3873.png\n",
            " inflated: BLtraining/3874.png\n",
            " inflated: BLtraining/3875.png\n",
            " inflated: BLtraining/3876.png\n",
            " inflated: BLtraining/3877.png\n",
            " inflated: BLtraining/3878.png\n",
            " inflated: BLtraining/3879.png\n",
            " inflated: BLtraining/388.png\n",
            " inflated: BLtraining/3880.png\n",
            " inflated: BLtraining/3881.png\n",
            " inflated: BLtraining/3882.png\n",
            " inflated: BLtraining/3883.png\n",
            " inflated: BLtraining/3884.png\n",
            " inflated: BLtraining/3885.png\n",
            " inflated: BLtraining/3886.png\n",
            " inflated: BLtraining/3887.png\n",
            " inflated: BLtraining/3888.png\n",
            " inflated: BLtraining/3889.png\n",
            " inflated: BLtraining/389.png\n",
            " inflated: BLtraining/3890.png\n",
            " inflated: BLtraining/3891.png\n",
            " inflated: BLtraining/3892.png\n",
            " inflated: BLtraining/3893.png\n",
            " inflated: BLtraining/3894.png\n",
            " inflated: BLtraining/3895.png\n",
            " inflated: BLtraining/3896.png\n",
            " inflated: BLtraining/3897.png\n",
            " inflated: BLtraining/3898.png\n",
            " inflated: BLtraining/3899.png\n",
            " inflated: BLtraining/39.png\n",
            " inflated: BLtraining/390.png\n",
            " inflated: BLtraining/3900.png\n",
            " inflated: BLtraining/3901.png\n",
            " inflated: BLtraining/3902.png\n",
            " inflated: BLtraining/3903.png\n",
            " inflated: BLtraining/3904.png\n",
            " inflated: BLtraining/3905.png\n",
            " inflated: BLtraining/3906.png\n",
            " inflated: BLtraining/3907.png\n",
            " inflated: BLtraining/3908.png\n",
            " inflated: BLtraining/3909.png\n",
            " inflated: BLtraining/391.png\n",
            " inflated: BLtraining/3910.png\n",
            " inflated: BLtraining/3911.png\n",
            " inflated: BLtraining/3912.png\n",
            " inflated: BLtraining/3913.png\n",
            " inflated: BLtraining/3914.png\n",
            " inflated: BLtraining/3915.png\n",
            " inflated: BLtraining/3916.png\n",
            " inflated: BLtraining/3917.png\n",
            " inflated: BLtraining/3918.png\n",
            " inflated: BLtraining/3919.png\n",
            " inflated: BLtraining/392.png\n",
            " inflated: BLtraining/3920.png\n",
            " inflated: BLtraining/3921.png\n",
            " inflated: BLtraining/3922.png\n",
            " inflated: BLtraining/3923.png\n",
            " inflated: BLtraining/3924.png\n",
            " inflated: BLtraining/3925.png\n",
            " inflated: BLtraining/3926.png\n",
            " inflated: BLtraining/3927.png\n",
            " inflated: BLtraining/3928.png\n",
            " inflated: BLtraining/3929.png\n",
            " inflated: BLtraining/393.png\n",
            " inflated: BLtraining/3930.png\n",
            " inflated: BLtraining/3931.png\n",
            " inflated: BLtraining/3932.png\n",
            " inflated: BLtraining/3933.png\n",
            " inflated: BLtraining/3934.png\n",
            " inflated: BLtraining/3935.png\n",
            " inflated: BLtraining/3936.png\n",
            " inflated: BLtraining/3937.png\n",
            " inflated: BLtraining/3938.png\n",
            " inflated: BLtraining/3939.png\n",
            " inflated: BLtraining/394.png\n",
            " inflated: BLtraining/3940.png\n",
            " inflated: BLtraining/3941.png\n",
            " inflated: BLtraining/3942.png\n",
            " inflated: BLtraining/3943.png\n",
            " inflated: BLtraining/3944.png\n",
            " inflated: BLtraining/3945.png\n",
            " inflated: BLtraining/3946.png\n",
            " inflated: BLtraining/3947.png\n",
            " inflated: BLtraining/3948.png\n",
            " inflated: BLtraining/3949.png\n",
            " inflated: BLtraining/395.png\n",
            " inflated: BLtraining/3950.png\n",
            " inflated: BLtraining/3951.png\n",
            " inflated: BLtraining/3952.png\n",
            " inflated: BLtraining/3953.png\n",
            " inflated: BLtraining/3954.png\n",
            " inflated: BLtraining/3955.png\n",
            " inflated: BLtraining/3956.png\n",
            " inflated: BLtraining/3957.png\n",
            " inflated: BLtraining/3958.png\n",
            " inflated: BLtraining/3959.png\n",
            " inflated: BLtraining/396.png\n",
            " inflated: BLtraining/3960.png\n",
            " inflated: BLtraining/3961.png\n",
            " inflated: BLtraining/3962.png\n",
            " inflated: BLtraining/3963.png\n",
            " inflated: BLtraining/3964.png\n",
            " inflated: BLtraining/3965.png\n",
            " inflated: BLtraining/3966.png\n",
            " inflated: BLtraining/3967.png\n",
            " inflated: BLtraining/3968.png\n",
            " inflated: BLtraining/3969.png\n",
            " inflated: BLtraining/397.png\n",
            " inflated: BLtraining/3970.png\n",
            " inflated: BLtraining/3971.png\n",
            " inflated: BLtraining/3972.png\n",
            " inflated: BLtraining/3973.png\n",
            " inflated: BLtraining/3974.png\n",
            " inflated: BLtraining/3975.png\n",
            " inflated: BLtraining/3976.png\n",
            " inflated: BLtraining/3977.png\n",
            " inflated: BLtraining/3978.png\n",
            " inflated: BLtraining/3979.png\n",
            " inflated: BLtraining/398.png\n",
            " inflated: BLtraining/3980.png\n",
            " inflated: BLtraining/3981.png\n",
            " inflated: BLtraining/3982.png\n",
            " inflated: BLtraining/3983.png\n",
            " inflated: BLtraining/3984.png\n",
            " inflated: BLtraining/3985.png\n",
            " inflated: BLtraining/3986.png\n",
            " inflated: BLtraining/3987.png\n",
            " inflated: BLtraining/3988.png\n",
            " inflated: BLtraining/3989.png\n",
            " inflated: BLtraining/399.png\n",
            " inflated: BLtraining/3990.png\n",
            " inflated: BLtraining/3991.png\n",
            " inflated: BLtraining/3992.png\n",
            " inflated: BLtraining/3993.png\n",
            " inflated: BLtraining/3994.png\n",
            " inflated: BLtraining/3995.png\n",
            " inflated: BLtraining/3996.png\n",
            " inflated: BLtraining/3997.png\n",
            " inflated: BLtraining/3998.png\n",
            " inflated: BLtraining/3999.png\n",
            " inflated: BLtraining/4.png\n",
            " inflated: BLtraining/40.png\n",
            " inflated: BLtraining/400.png\n",
            " inflated: BLtraining/4000.png\n",
            " inflated: BLtraining/4001.png\n",
            " inflated: BLtraining/4002.png\n",
            " inflated: BLtraining/4003.png\n",
            " inflated: BLtraining/4004.png\n",
            " inflated: BLtraining/4005.png\n",
            " inflated: BLtraining/4006.png\n",
            " inflated: BLtraining/4007.png\n",
            " inflated: BLtraining/4008.png\n",
            " inflated: BLtraining/4009.png\n",
            " inflated: BLtraining/401.png\n",
            " inflated: BLtraining/4010.png\n",
            " inflated: BLtraining/4011.png\n",
            " inflated: BLtraining/4012.png\n",
            " inflated: BLtraining/4013.png\n",
            " inflated: BLtraining/4014.png\n",
            " inflated: BLtraining/4015.png\n",
            " inflated: BLtraining/4016.png\n",
            " inflated: BLtraining/4017.png\n",
            " inflated: BLtraining/4018.png\n",
            " inflated: BLtraining/4019.png\n",
            " inflated: BLtraining/402.png\n",
            " inflated: BLtraining/4020.png\n",
            " inflated: BLtraining/4021.png\n",
            " inflated: BLtraining/4022.png\n",
            " inflated: BLtraining/4023.png\n",
            " inflated: BLtraining/4024.png\n",
            " inflated: BLtraining/4025.png\n",
            " inflated: BLtraining/4026.png\n",
            " inflated: BLtraining/4027.png\n",
            " inflated: BLtraining/4028.png\n",
            " inflated: BLtraining/4029.png\n",
            " inflated: BLtraining/403.png\n",
            " inflated: BLtraining/4030.png\n",
            " inflated: BLtraining/4031.png\n",
            " inflated: BLtraining/4032.png\n",
            " inflated: BLtraining/4033.png\n",
            " inflated: BLtraining/4034.png\n",
            " inflated: BLtraining/4035.png\n",
            " inflated: BLtraining/4036.png\n",
            " inflated: BLtraining/4037.png\n",
            " inflated: BLtraining/4038.png\n",
            " inflated: BLtraining/4039.png\n",
            " inflated: BLtraining/404.png\n",
            " inflated: BLtraining/4040.png\n",
            " inflated: BLtraining/4041.png\n",
            " inflated: BLtraining/4042.png\n",
            " inflated: BLtraining/4043.png\n",
            " inflated: BLtraining/4044.png\n",
            " inflated: BLtraining/4045.png\n",
            " inflated: BLtraining/4046.png\n",
            " inflated: BLtraining/4047.png\n",
            " inflated: BLtraining/4048.png\n",
            " inflated: BLtraining/4049.png\n",
            " inflated: BLtraining/405.png\n",
            " inflated: BLtraining/4050.png\n",
            " inflated: BLtraining/4051.png\n",
            " inflated: BLtraining/4052.png\n",
            " inflated: BLtraining/4053.png\n",
            " inflated: BLtraining/4054.png\n",
            " inflated: BLtraining/4055.png\n",
            " inflated: BLtraining/4056.png\n",
            " inflated: BLtraining/4057.png\n",
            " inflated: BLtraining/4058.png\n",
            " inflated: BLtraining/4059.png\n",
            " inflated: BLtraining/406.png\n",
            " inflated: BLtraining/4060.png\n",
            " inflated: BLtraining/4061.png\n",
            " inflated: BLtraining/4062.png\n",
            " inflated: BLtraining/4063.png\n",
            " inflated: BLtraining/4064.png\n",
            " inflated: BLtraining/4065.png\n",
            " inflated: BLtraining/4066.png\n",
            " inflated: BLtraining/4067.png\n",
            " inflated: BLtraining/4068.png\n",
            " inflated: BLtraining/4069.png\n",
            " inflated: BLtraining/407.png\n",
            " inflated: BLtraining/4070.png\n",
            " inflated: BLtraining/4071.png\n",
            " inflated: BLtraining/4072.png\n",
            " inflated: BLtraining/4073.png\n",
            " inflated: BLtraining/4074.png\n",
            " inflated: BLtraining/4075.png\n",
            " inflated: BLtraining/4076.png\n",
            " inflated: BLtraining/4077.png\n",
            " inflated: BLtraining/4078.png\n",
            " inflated: BLtraining/4079.png\n",
            " inflated: BLtraining/408.png\n",
            " inflated: BLtraining/4080.png\n",
            " inflated: BLtraining/4081.png\n",
            " inflated: BLtraining/4082.png\n",
            " inflated: BLtraining/4083.png\n",
            " inflated: BLtraining/4084.png\n",
            " inflated: BLtraining/4085.png\n",
            " inflated: BLtraining/4086.png\n",
            " inflated: BLtraining/4087.png\n",
            " inflated: BLtraining/4088.png\n",
            " inflated: BLtraining/4089.png\n",
            " inflated: BLtraining/409.png\n",
            " inflated: BLtraining/4090.png\n",
            " inflated: BLtraining/4091.png\n",
            " inflated: BLtraining/4092.png\n",
            " inflated: BLtraining/4093.png\n",
            " inflated: BLtraining/4094.png\n",
            " inflated: BLtraining/4095.png\n",
            " inflated: BLtraining/4096.png\n",
            " inflated: BLtraining/4097.png\n",
            " inflated: BLtraining/4098.png\n",
            " inflated: BLtraining/4099.png\n",
            " inflated: BLtraining/41.png\n",
            " inflated: BLtraining/410.png\n",
            " inflated: BLtraining/4100.png\n",
            " inflated: BLtraining/4101.png\n",
            " inflated: BLtraining/4102.png\n",
            " inflated: BLtraining/4103.png\n",
            " inflated: BLtraining/4104.png\n",
            " inflated: BLtraining/4105.png\n",
            " inflated: BLtraining/4106.png\n",
            " inflated: BLtraining/4107.png\n",
            " inflated: BLtraining/4108.png\n",
            " inflated: BLtraining/4109.png\n",
            " inflated: BLtraining/411.png\n",
            " inflated: BLtraining/4110.png\n",
            " inflated: BLtraining/4111.png\n",
            " inflated: BLtraining/4112.png\n",
            " inflated: BLtraining/4113.png\n",
            " inflated: BLtraining/4114.png\n",
            " inflated: BLtraining/4115.png\n",
            " inflated: BLtraining/4116.png\n",
            " inflated: BLtraining/4117.png\n",
            " inflated: BLtraining/4118.png\n",
            " inflated: BLtraining/4119.png\n",
            " inflated: BLtraining/412.png\n",
            " inflated: BLtraining/4120.png\n",
            " inflated: BLtraining/4121.png\n",
            " inflated: BLtraining/4122.png\n",
            " inflated: BLtraining/4123.png\n",
            " inflated: BLtraining/4124.png\n",
            " inflated: BLtraining/4125.png\n",
            " inflated: BLtraining/4126.png\n",
            " inflated: BLtraining/4127.png\n",
            " inflated: BLtraining/4128.png\n",
            " inflated: BLtraining/4129.png\n",
            " inflated: BLtraining/413.png\n",
            " inflated: BLtraining/4130.png\n",
            " inflated: BLtraining/4131.png\n",
            " inflated: BLtraining/4132.png\n",
            " inflated: BLtraining/4133.png\n",
            " inflated: BLtraining/4134.png\n",
            " inflated: BLtraining/4135.png\n",
            " inflated: BLtraining/4136.png\n",
            " inflated: BLtraining/4137.png\n",
            " inflated: BLtraining/4138.png\n",
            " inflated: BLtraining/4139.png\n",
            " inflated: BLtraining/414.png\n",
            " inflated: BLtraining/4140.png\n",
            " inflated: BLtraining/4141.png\n",
            " inflated: BLtraining/4142.png\n",
            " inflated: BLtraining/4143.png\n",
            " inflated: BLtraining/4144.png\n",
            " inflated: BLtraining/4145.png\n",
            " inflated: BLtraining/4146.png\n",
            " inflated: BLtraining/4147.png\n",
            " inflated: BLtraining/4148.png\n",
            " inflated: BLtraining/4149.png\n",
            " inflated: BLtraining/415.png\n",
            " inflated: BLtraining/4150.png\n",
            " inflated: BLtraining/4151.png\n",
            " inflated: BLtraining/4152.png\n",
            " inflated: BLtraining/4153.png\n",
            " inflated: BLtraining/4154.png\n",
            " inflated: BLtraining/4155.png\n",
            " inflated: BLtraining/4156.png\n",
            " inflated: BLtraining/4157.png\n",
            " inflated: BLtraining/4158.png\n",
            " inflated: BLtraining/4159.png\n",
            " inflated: BLtraining/416.png\n",
            " inflated: BLtraining/4160.png\n",
            " inflated: BLtraining/4161.png\n",
            " inflated: BLtraining/4162.png\n",
            " inflated: BLtraining/4163.png\n",
            " inflated: BLtraining/4164.png\n",
            " inflated: BLtraining/4165.png\n",
            " inflated: BLtraining/4166.png\n",
            " inflated: BLtraining/4167.png\n",
            " inflated: BLtraining/4168.png\n",
            " inflated: BLtraining/4169.png\n",
            " inflated: BLtraining/417.png\n",
            " inflated: BLtraining/4170.png\n",
            " inflated: BLtraining/4171.png\n",
            " inflated: BLtraining/4172.png\n",
            " inflated: BLtraining/4173.png\n",
            " inflated: BLtraining/4174.png\n",
            " inflated: BLtraining/4175.png\n",
            " inflated: BLtraining/4176.png\n",
            " inflated: BLtraining/4177.png\n",
            " inflated: BLtraining/4178.png\n",
            " inflated: BLtraining/4179.png\n",
            " inflated: BLtraining/418.png\n",
            " inflated: BLtraining/4180.png\n",
            " inflated: BLtraining/4181.png\n",
            " inflated: BLtraining/4182.png\n",
            " inflated: BLtraining/4183.png\n",
            " inflated: BLtraining/4184.png\n",
            " inflated: BLtraining/4185.png\n",
            " inflated: BLtraining/4186.png\n",
            " inflated: BLtraining/4187.png\n",
            " inflated: BLtraining/4188.png\n",
            " inflated: BLtraining/4189.png\n",
            " inflated: BLtraining/419.png\n",
            " inflated: BLtraining/4190.png\n",
            " inflated: BLtraining/4191.png\n",
            " inflated: BLtraining/4192.png\n",
            " inflated: BLtraining/4193.png\n",
            " inflated: BLtraining/4194.png\n",
            " inflated: BLtraining/4195.png\n",
            " inflated: BLtraining/4196.png\n",
            " inflated: BLtraining/4197.png\n",
            " inflated: BLtraining/4198.png\n",
            " inflated: BLtraining/4199.png\n",
            " inflated: BLtraining/42.png\n",
            " inflated: BLtraining/420.png\n",
            " inflated: BLtraining/4200.png\n",
            " inflated: BLtraining/4201.png\n",
            " inflated: BLtraining/4202.png\n",
            " inflated: BLtraining/4203.png\n",
            " inflated: BLtraining/4204.png\n",
            " inflated: BLtraining/4205.png\n",
            " inflated: BLtraining/4206.png\n",
            " inflated: BLtraining/4207.png\n",
            " inflated: BLtraining/4208.png\n",
            " inflated: BLtraining/4209.png\n",
            " inflated: BLtraining/421.png\n",
            " inflated: BLtraining/4210.png\n",
            " inflated: BLtraining/4211.png\n",
            " inflated: BLtraining/4212.png\n",
            " inflated: BLtraining/4213.png\n",
            " inflated: BLtraining/4214.png\n",
            " inflated: BLtraining/4215.png\n",
            " inflated: BLtraining/4216.png\n",
            " inflated: BLtraining/4217.png\n",
            " inflated: BLtraining/4218.png\n",
            " inflated: BLtraining/4219.png\n",
            " inflated: BLtraining/422.png\n",
            " inflated: BLtraining/4220.png\n",
            " inflated: BLtraining/4221.png\n",
            " inflated: BLtraining/4222.png\n",
            " inflated: BLtraining/4223.png\n",
            " inflated: BLtraining/4224.png\n",
            " inflated: BLtraining/4225.png\n",
            " inflated: BLtraining/4226.png\n",
            " inflated: BLtraining/4227.png\n",
            " inflated: BLtraining/4228.png\n",
            " inflated: BLtraining/4229.png\n",
            " inflated: BLtraining/423.png\n",
            " inflated: BLtraining/4230.png\n",
            " inflated: BLtraining/4231.png\n",
            " inflated: BLtraining/4232.png\n",
            " inflated: BLtraining/4233.png\n",
            " inflated: BLtraining/4234.png\n",
            " inflated: BLtraining/4235.png\n",
            " inflated: BLtraining/4236.png\n",
            " inflated: BLtraining/4237.png\n",
            " inflated: BLtraining/4238.png\n",
            " inflated: BLtraining/4239.png\n",
            " inflated: BLtraining/424.png\n",
            " inflated: BLtraining/4240.png\n",
            " inflated: BLtraining/4241.png\n",
            " inflated: BLtraining/4242.png\n",
            " inflated: BLtraining/4243.png\n",
            " inflated: BLtraining/4244.png\n",
            " inflated: BLtraining/4245.png\n",
            " inflated: BLtraining/4246.png\n",
            " inflated: BLtraining/4247.png\n",
            " inflated: BLtraining/4248.png\n",
            " inflated: BLtraining/4249.png\n",
            " inflated: BLtraining/425.png\n",
            " inflated: BLtraining/4250.png\n",
            " inflated: BLtraining/4251.png\n",
            " inflated: BLtraining/4252.png\n",
            " inflated: BLtraining/4253.png\n",
            " inflated: BLtraining/4254.png\n",
            " inflated: BLtraining/4255.png\n",
            " inflated: BLtraining/4256.png\n",
            " inflated: BLtraining/4257.png\n",
            " inflated: BLtraining/4258.png\n",
            " inflated: BLtraining/4259.png\n",
            " inflated: BLtraining/426.png\n",
            " inflated: BLtraining/4260.png\n",
            " inflated: BLtraining/4261.png\n",
            " inflated: BLtraining/4262.png\n",
            " inflated: BLtraining/4263.png\n",
            " inflated: BLtraining/4264.png\n",
            " inflated: BLtraining/4265.png\n",
            " inflated: BLtraining/4266.png\n",
            " inflated: BLtraining/4267.png\n",
            " inflated: BLtraining/4268.png\n",
            " inflated: BLtraining/4269.png\n",
            " inflated: BLtraining/427.png\n",
            " inflated: BLtraining/4270.png\n",
            " inflated: BLtraining/4271.png\n",
            " inflated: BLtraining/4272.png\n",
            " inflated: BLtraining/4273.png\n",
            " inflated: BLtraining/4274.png\n",
            " inflated: BLtraining/4275.png\n",
            " inflated: BLtraining/4276.png\n",
            " inflated: BLtraining/4277.png\n",
            " inflated: BLtraining/4278.png\n",
            " inflated: BLtraining/4279.png\n",
            " inflated: BLtraining/428.png\n",
            " inflated: BLtraining/4280.png\n",
            " inflated: BLtraining/4281.png\n",
            " inflated: BLtraining/4282.png\n",
            " inflated: BLtraining/4283.png\n",
            " inflated: BLtraining/4284.png\n",
            " inflated: BLtraining/4285.png\n",
            " inflated: BLtraining/4286.png\n",
            " inflated: BLtraining/4287.png\n",
            " inflated: BLtraining/4288.png\n",
            " inflated: BLtraining/4289.png\n",
            " inflated: BLtraining/429.png\n",
            " inflated: BLtraining/4290.png\n",
            " inflated: BLtraining/4291.png\n",
            " inflated: BLtraining/4292.png\n",
            " inflated: BLtraining/4293.png\n",
            " inflated: BLtraining/4294.png\n",
            " inflated: BLtraining/4295.png\n",
            " inflated: BLtraining/4296.png\n",
            " inflated: BLtraining/4297.png\n",
            " inflated: BLtraining/4298.png\n",
            " inflated: BLtraining/4299.png\n",
            " inflated: BLtraining/43.png\n",
            " inflated: BLtraining/430.png\n",
            " inflated: BLtraining/4300.png\n",
            " inflated: BLtraining/4301.png\n",
            " inflated: BLtraining/4302.png\n",
            " inflated: BLtraining/4303.png\n",
            " inflated: BLtraining/4304.png\n",
            " inflated: BLtraining/4305.png\n",
            " inflated: BLtraining/4306.png\n",
            " inflated: BLtraining/4307.png\n",
            " inflated: BLtraining/4308.png\n",
            " inflated: BLtraining/4309.png\n",
            " inflated: BLtraining/431.png\n",
            " inflated: BLtraining/4310.png\n",
            " inflated: BLtraining/4311.png\n",
            " inflated: BLtraining/4312.png\n",
            " inflated: BLtraining/4313.png\n",
            " inflated: BLtraining/4314.png\n",
            " inflated: BLtraining/4315.png\n",
            " inflated: BLtraining/4316.png\n",
            " inflated: BLtraining/4317.png\n",
            " inflated: BLtraining/4318.png\n",
            " inflated: BLtraining/4319.png\n",
            " inflated: BLtraining/432.png\n",
            " inflated: BLtraining/4320.png\n",
            " inflated: BLtraining/4321.png\n",
            " inflated: BLtraining/4322.png\n",
            " inflated: BLtraining/4323.png\n",
            " inflated: BLtraining/4324.png\n",
            " inflated: BLtraining/4325.png\n",
            " inflated: BLtraining/4326.png\n",
            " inflated: BLtraining/4327.png\n",
            " inflated: BLtraining/4328.png\n",
            " inflated: BLtraining/4329.png\n",
            " inflated: BLtraining/433.png\n",
            " inflated: BLtraining/4330.png\n",
            " inflated: BLtraining/4331.png\n",
            " inflated: BLtraining/4332.png\n",
            " inflated: BLtraining/4333.png\n",
            " inflated: BLtraining/4334.png\n",
            " inflated: BLtraining/4335.png\n",
            " inflated: BLtraining/4336.png\n",
            " inflated: BLtraining/4337.png\n",
            " inflated: BLtraining/4338.png\n",
            " inflated: BLtraining/4339.png\n",
            " inflated: BLtraining/434.png\n",
            " inflated: BLtraining/4340.png\n",
            " inflated: BLtraining/4341.png\n",
            " inflated: BLtraining/4342.png\n",
            " inflated: BLtraining/4343.png\n",
            " inflated: BLtraining/4344.png\n",
            " inflated: BLtraining/4345.png\n",
            " inflated: BLtraining/4346.png\n",
            " inflated: BLtraining/4347.png\n",
            " inflated: BLtraining/4348.png\n",
            " inflated: BLtraining/4349.png\n",
            " inflated: BLtraining/435.png\n",
            " inflated: BLtraining/4350.png\n",
            " inflated: BLtraining/4351.png\n",
            " inflated: BLtraining/4352.png\n",
            " inflated: BLtraining/4353.png\n",
            " inflated: BLtraining/4354.png\n",
            " inflated: BLtraining/4355.png\n",
            " inflated: BLtraining/4356.png\n",
            " inflated: BLtraining/4357.png\n",
            " inflated: BLtraining/4358.png\n",
            " inflated: BLtraining/4359.png\n",
            " inflated: BLtraining/436.png\n",
            " inflated: BLtraining/4360.png\n",
            " inflated: BLtraining/4361.png\n",
            " inflated: BLtraining/4362.png\n",
            " inflated: BLtraining/4363.png\n",
            " inflated: BLtraining/4364.png\n",
            " inflated: BLtraining/4365.png\n",
            " inflated: BLtraining/4366.png\n",
            " inflated: BLtraining/4367.png\n",
            " inflated: BLtraining/4368.png\n",
            " inflated: BLtraining/4369.png\n",
            " inflated: BLtraining/437.png\n",
            " inflated: BLtraining/4370.png\n",
            " inflated: BLtraining/4371.png\n",
            " inflated: BLtraining/4372.png\n",
            " inflated: BLtraining/4373.png\n",
            " inflated: BLtraining/4374.png\n",
            " inflated: BLtraining/4375.png\n",
            " inflated: BLtraining/4376.png\n",
            " inflated: BLtraining/4377.png\n",
            " inflated: BLtraining/4378.png\n",
            " inflated: BLtraining/4379.png\n",
            " inflated: BLtraining/438.png\n",
            " inflated: BLtraining/4380.png\n",
            " inflated: BLtraining/4381.png\n",
            " inflated: BLtraining/4382.png\n",
            " inflated: BLtraining/4383.png\n",
            " inflated: BLtraining/4384.png\n",
            " inflated: BLtraining/4385.png\n",
            " inflated: BLtraining/4386.png\n",
            " inflated: BLtraining/4387.png\n",
            " inflated: BLtraining/4388.png\n",
            " inflated: BLtraining/4389.png\n",
            " inflated: BLtraining/439.png\n",
            " inflated: BLtraining/4390.png\n",
            " inflated: BLtraining/4391.png\n",
            " inflated: BLtraining/4392.png\n",
            " inflated: BLtraining/4393.png\n",
            " inflated: BLtraining/4394.png\n",
            " inflated: BLtraining/4395.png\n",
            " inflated: BLtraining/4396.png\n",
            " inflated: BLtraining/4397.png\n",
            " inflated: BLtraining/4398.png\n",
            " inflated: BLtraining/4399.png\n",
            " inflated: BLtraining/44.png\n",
            " inflated: BLtraining/440.png\n",
            " inflated: BLtraining/4400.png\n",
            " inflated: BLtraining/4401.png\n",
            " inflated: BLtraining/4402.png\n",
            " inflated: BLtraining/4403.png\n",
            " inflated: BLtraining/4404.png\n",
            " inflated: BLtraining/4405.png\n",
            " inflated: BLtraining/4406.png\n",
            " inflated: BLtraining/4407.png\n",
            " inflated: BLtraining/4408.png\n",
            " inflated: BLtraining/4409.png\n",
            " inflated: BLtraining/441.png\n",
            " inflated: BLtraining/4410.png\n",
            " inflated: BLtraining/4411.png\n",
            " inflated: BLtraining/4412.png\n",
            " inflated: BLtraining/4413.png\n",
            " inflated: BLtraining/4414.png\n",
            " inflated: BLtraining/4415.png\n",
            " inflated: BLtraining/4416.png\n",
            " inflated: BLtraining/4417.png\n",
            " inflated: BLtraining/4418.png\n",
            " inflated: BLtraining/4419.png\n",
            " inflated: BLtraining/442.png\n",
            " inflated: BLtraining/4420.png\n",
            " inflated: BLtraining/4421.png\n",
            " inflated: BLtraining/4422.png\n",
            " inflated: BLtraining/4423.png\n",
            " inflated: BLtraining/4424.png\n",
            " inflated: BLtraining/4425.png\n",
            " inflated: BLtraining/4426.png\n",
            " inflated: BLtraining/4427.png\n",
            " inflated: BLtraining/4428.png\n",
            " inflated: BLtraining/4429.png\n",
            " inflated: BLtraining/443.png\n",
            " inflated: BLtraining/4430.png\n",
            " inflated: BLtraining/4431.png\n",
            " inflated: BLtraining/4432.png\n",
            " inflated: BLtraining/4433.png\n",
            " inflated: BLtraining/4434.png\n",
            " inflated: BLtraining/4435.png\n",
            " inflated: BLtraining/4436.png\n",
            " inflated: BLtraining/4437.png\n",
            " inflated: BLtraining/4438.png\n",
            " inflated: BLtraining/4439.png\n",
            " inflated: BLtraining/444.png\n",
            " inflated: BLtraining/4440.png\n",
            " inflated: BLtraining/4441.png\n",
            " inflated: BLtraining/4442.png\n",
            " inflated: BLtraining/4443.png\n",
            " inflated: BLtraining/4444.png\n",
            " inflated: BLtraining/4445.png\n",
            " inflated: BLtraining/4446.png\n",
            " inflated: BLtraining/4447.png\n",
            " inflated: BLtraining/4448.png\n",
            " inflated: BLtraining/4449.png\n",
            " inflated: BLtraining/445.png\n",
            " inflated: BLtraining/4450.png\n",
            " inflated: BLtraining/4451.png\n",
            " inflated: BLtraining/4452.png\n",
            " inflated: BLtraining/4453.png\n",
            " inflated: BLtraining/4454.png\n",
            " inflated: BLtraining/4455.png\n",
            " inflated: BLtraining/4456.png\n",
            " inflated: BLtraining/4457.png\n",
            " inflated: BLtraining/4458.png\n",
            " inflated: BLtraining/4459.png\n",
            " inflated: BLtraining/446.png\n",
            " inflated: BLtraining/4460.png\n",
            " inflated: BLtraining/4461.png\n",
            " inflated: BLtraining/4462.png\n",
            " inflated: BLtraining/4463.png\n",
            " inflated: BLtraining/4464.png\n",
            " inflated: BLtraining/4465.png\n",
            " inflated: BLtraining/4466.png\n",
            " inflated: BLtraining/4467.png\n",
            " inflated: BLtraining/4468.png\n",
            " inflated: BLtraining/4469.png\n",
            " inflated: BLtraining/447.png\n",
            " inflated: BLtraining/4470.png\n",
            " inflated: BLtraining/4471.png\n",
            " inflated: BLtraining/4472.png\n",
            " inflated: BLtraining/4473.png\n",
            " inflated: BLtraining/4474.png\n",
            " inflated: BLtraining/4475.png\n",
            " inflated: BLtraining/4476.png\n",
            " inflated: BLtraining/4477.png\n",
            " inflated: BLtraining/4478.png\n",
            " inflated: BLtraining/4479.png\n",
            " inflated: BLtraining/448.png\n",
            " inflated: BLtraining/4480.png\n",
            " inflated: BLtraining/4481.png\n",
            " inflated: BLtraining/4482.png\n",
            " inflated: BLtraining/4483.png\n",
            " inflated: BLtraining/4484.png\n",
            " inflated: BLtraining/4485.png\n",
            " inflated: BLtraining/4486.png\n",
            " inflated: BLtraining/4487.png\n",
            " inflated: BLtraining/4488.png\n",
            " inflated: BLtraining/4489.png\n",
            " inflated: BLtraining/449.png\n",
            " inflated: BLtraining/4490.png\n",
            " inflated: BLtraining/4491.png\n",
            " inflated: BLtraining/4492.png\n",
            " inflated: BLtraining/4493.png\n",
            " inflated: BLtraining/4494.png\n",
            " inflated: BLtraining/4495.png\n",
            " inflated: BLtraining/4496.png\n",
            " inflated: BLtraining/4497.png\n",
            " inflated: BLtraining/4498.png\n",
            " inflated: BLtraining/4499.png\n",
            " inflated: BLtraining/45.png\n",
            " inflated: BLtraining/450.png\n",
            " inflated: BLtraining/4500.png\n",
            " inflated: BLtraining/4501.png\n",
            " inflated: BLtraining/4502.png\n",
            " inflated: BLtraining/4503.png\n",
            " inflated: BLtraining/4504.png\n",
            " inflated: BLtraining/4505.png\n",
            " inflated: BLtraining/4506.png\n",
            " inflated: BLtraining/4507.png\n",
            " inflated: BLtraining/4508.png\n",
            " inflated: BLtraining/4509.png\n",
            " inflated: BLtraining/451.png\n",
            " inflated: BLtraining/4510.png\n",
            " inflated: BLtraining/4511.png\n",
            " inflated: BLtraining/4512.png\n",
            " inflated: BLtraining/4513.png\n",
            " inflated: BLtraining/4514.png\n",
            " inflated: BLtraining/4515.png\n",
            " inflated: BLtraining/4516.png\n",
            " inflated: BLtraining/4517.png\n",
            " inflated: BLtraining/4518.png\n",
            " inflated: BLtraining/4519.png\n",
            " inflated: BLtraining/452.png\n",
            " inflated: BLtraining/4520.png\n",
            " inflated: BLtraining/4521.png\n",
            " inflated: BLtraining/4522.png\n",
            " inflated: BLtraining/4523.png\n",
            " inflated: BLtraining/4524.png\n",
            " inflated: BLtraining/4525.png\n",
            " inflated: BLtraining/4526.png\n",
            " inflated: BLtraining/4527.png\n",
            " inflated: BLtraining/4528.png\n",
            " inflated: BLtraining/4529.png\n",
            " inflated: BLtraining/453.png\n",
            " inflated: BLtraining/4530.png\n",
            " inflated: BLtraining/4531.png\n",
            " inflated: BLtraining/4532.png\n",
            " inflated: BLtraining/4533.png\n",
            " inflated: BLtraining/4534.png\n",
            " inflated: BLtraining/4535.png\n",
            " inflated: BLtraining/4536.png\n",
            " inflated: BLtraining/4537.png\n",
            " inflated: BLtraining/4538.png\n",
            " inflated: BLtraining/4539.png\n",
            " inflated: BLtraining/454.png\n",
            " inflated: BLtraining/4540.png\n",
            " inflated: BLtraining/4541.png\n",
            " inflated: BLtraining/4542.png\n",
            " inflated: BLtraining/4543.png\n",
            " inflated: BLtraining/4544.png\n",
            " inflated: BLtraining/4545.png\n",
            " inflated: BLtraining/4546.png\n",
            " inflated: BLtraining/4547.png\n",
            " inflated: BLtraining/4548.png\n",
            " inflated: BLtraining/4549.png\n",
            " inflated: BLtraining/455.png\n",
            " inflated: BLtraining/4550.png\n",
            " inflated: BLtraining/4551.png\n",
            " inflated: BLtraining/4552.png\n",
            " inflated: BLtraining/4553.png\n",
            " inflated: BLtraining/4554.png\n",
            " inflated: BLtraining/4555.png\n",
            " inflated: BLtraining/4556.png\n",
            " inflated: BLtraining/4557.png\n",
            " inflated: BLtraining/4558.png\n",
            " inflated: BLtraining/4559.png\n",
            " inflated: BLtraining/456.png\n",
            " inflated: BLtraining/4560.png\n",
            " inflated: BLtraining/4561.png\n",
            " inflated: BLtraining/4562.png\n",
            " inflated: BLtraining/4563.png\n",
            " inflated: BLtraining/4564.png\n",
            " inflated: BLtraining/4565.png\n",
            " inflated: BLtraining/4566.png\n",
            " inflated: BLtraining/4567.png\n",
            " inflated: BLtraining/4568.png\n",
            " inflated: BLtraining/4569.png\n",
            " inflated: BLtraining/457.png\n",
            " inflated: BLtraining/4570.png\n",
            " inflated: BLtraining/4571.png\n",
            " inflated: BLtraining/4572.png\n",
            " inflated: BLtraining/4573.png\n",
            " inflated: BLtraining/4574.png\n",
            " inflated: BLtraining/4575.png\n",
            " inflated: BLtraining/4576.png\n",
            " inflated: BLtraining/4577.png\n",
            " inflated: BLtraining/4578.png\n",
            " inflated: BLtraining/4579.png\n",
            " inflated: BLtraining/458.png\n",
            " inflated: BLtraining/4580.png\n",
            " inflated: BLtraining/4581.png\n",
            " inflated: BLtraining/4582.png\n",
            " inflated: BLtraining/4583.png\n",
            " inflated: BLtraining/4584.png\n",
            " inflated: BLtraining/4585.png\n",
            " inflated: BLtraining/4586.png\n",
            " inflated: BLtraining/4587.png\n",
            " inflated: BLtraining/4588.png\n",
            " inflated: BLtraining/4589.png\n",
            " inflated: BLtraining/459.png\n",
            " inflated: BLtraining/4590.png\n",
            " inflated: BLtraining/4591.png\n",
            " inflated: BLtraining/4592.png\n",
            " inflated: BLtraining/4593.png\n",
            " inflated: BLtraining/4594.png\n",
            " inflated: BLtraining/4595.png\n",
            " inflated: BLtraining/4596.png\n",
            " inflated: BLtraining/4597.png\n",
            " inflated: BLtraining/4598.png\n",
            " inflated: BLtraining/4599.png\n",
            " inflated: BLtraining/46.png\n",
            " inflated: BLtraining/460.png\n",
            " inflated: BLtraining/4600.png\n",
            " inflated: BLtraining/4601.png\n",
            " inflated: BLtraining/4602.png\n",
            " inflated: BLtraining/4603.png\n",
            " inflated: BLtraining/4604.png\n",
            " inflated: BLtraining/4605.png\n",
            " inflated: BLtraining/4606.png\n",
            " inflated: BLtraining/4607.png\n",
            " inflated: BLtraining/4608.png\n",
            " inflated: BLtraining/4609.png\n",
            " inflated: BLtraining/461.png\n",
            " inflated: BLtraining/4610.png\n",
            " inflated: BLtraining/4611.png\n",
            " inflated: BLtraining/4612.png\n",
            " inflated: BLtraining/4613.png\n",
            " inflated: BLtraining/4614.png\n",
            " inflated: BLtraining/4615.png\n",
            " inflated: BLtraining/4616.png\n",
            " inflated: BLtraining/4617.png\n",
            " inflated: BLtraining/4618.png\n",
            " inflated: BLtraining/4619.png\n",
            " inflated: BLtraining/462.png\n",
            " inflated: BLtraining/4620.png\n",
            " inflated: BLtraining/4621.png\n",
            " inflated: BLtraining/4622.png\n",
            " inflated: BLtraining/4623.png\n",
            " inflated: BLtraining/4624.png\n",
            " inflated: BLtraining/4625.png\n",
            " inflated: BLtraining/4626.png\n",
            " inflated: BLtraining/4627.png\n",
            " inflated: BLtraining/4628.png\n",
            " inflated: BLtraining/4629.png\n",
            " inflated: BLtraining/463.png\n",
            " inflated: BLtraining/4630.png\n",
            " inflated: BLtraining/4631.png\n",
            " inflated: BLtraining/4632.png\n",
            " inflated: BLtraining/4633.png\n",
            " inflated: BLtraining/4634.png\n",
            " inflated: BLtraining/4635.png\n",
            " inflated: BLtraining/4636.png\n",
            " inflated: BLtraining/4637.png\n",
            " inflated: BLtraining/4638.png\n",
            " inflated: BLtraining/4639.png\n",
            " inflated: BLtraining/464.png\n",
            " inflated: BLtraining/4640.png\n",
            " inflated: BLtraining/4641.png\n",
            " inflated: BLtraining/4642.png\n",
            " inflated: BLtraining/4643.png\n",
            " inflated: BLtraining/4644.png\n",
            " inflated: BLtraining/4645.png\n",
            " inflated: BLtraining/4646.png\n",
            " inflated: BLtraining/4647.png\n",
            " inflated: BLtraining/4648.png\n",
            " inflated: BLtraining/4649.png\n",
            " inflated: BLtraining/465.png\n",
            " inflated: BLtraining/4650.png\n",
            " inflated: BLtraining/4651.png\n",
            " inflated: BLtraining/4652.png\n",
            " inflated: BLtraining/4653.png\n",
            " inflated: BLtraining/4654.png\n",
            " inflated: BLtraining/4655.png\n",
            " inflated: BLtraining/4656.png\n",
            " inflated: BLtraining/4657.png\n",
            " inflated: BLtraining/4658.png\n",
            " inflated: BLtraining/4659.png\n",
            " inflated: BLtraining/466.png\n",
            " inflated: BLtraining/4660.png\n",
            " inflated: BLtraining/4661.png\n",
            " inflated: BLtraining/4662.png\n",
            " inflated: BLtraining/4663.png\n",
            " inflated: BLtraining/4664.png\n",
            " inflated: BLtraining/4665.png\n",
            " inflated: BLtraining/4666.png\n",
            " inflated: BLtraining/4667.png\n",
            " inflated: BLtraining/4668.png\n",
            " inflated: BLtraining/4669.png\n",
            " inflated: BLtraining/467.png\n",
            " inflated: BLtraining/4670.png\n",
            " inflated: BLtraining/4671.png\n",
            " inflated: BLtraining/4672.png\n",
            " inflated: BLtraining/4673.png\n",
            " inflated: BLtraining/4674.png\n",
            " inflated: BLtraining/4675.png\n",
            " inflated: BLtraining/4676.png\n",
            " inflated: BLtraining/4677.png\n",
            " inflated: BLtraining/4678.png\n",
            " inflated: BLtraining/4679.png\n",
            " inflated: BLtraining/468.png\n",
            " inflated: BLtraining/4680.png\n",
            " inflated: BLtraining/4681.png\n",
            " inflated: BLtraining/4682.png\n",
            " inflated: BLtraining/4683.png\n",
            " inflated: BLtraining/4684.png\n",
            " inflated: BLtraining/4685.png\n",
            " inflated: BLtraining/4686.png\n",
            " inflated: BLtraining/4687.png\n",
            " inflated: BLtraining/4688.png\n",
            " inflated: BLtraining/4689.png\n",
            " inflated: BLtraining/469.png\n",
            " inflated: BLtraining/4690.png\n",
            " inflated: BLtraining/4691.png\n",
            " inflated: BLtraining/4692.png\n",
            " inflated: BLtraining/4693.png\n",
            " inflated: BLtraining/4694.png\n",
            " inflated: BLtraining/4695.png\n",
            " inflated: BLtraining/4696.png\n",
            " inflated: BLtraining/4697.png\n",
            " inflated: BLtraining/4698.png\n",
            " inflated: BLtraining/4699.png\n",
            " inflated: BLtraining/47.png\n",
            " inflated: BLtraining/470.png\n",
            " inflated: BLtraining/4700.png\n",
            " inflated: BLtraining/4701.png\n",
            " inflated: BLtraining/4702.png\n",
            " inflated: BLtraining/4703.png\n",
            " inflated: BLtraining/4704.png\n",
            " inflated: BLtraining/4705.png\n",
            " inflated: BLtraining/4706.png\n",
            " inflated: BLtraining/4707.png\n",
            " inflated: BLtraining/4708.png\n",
            " inflated: BLtraining/4709.png\n",
            " inflated: BLtraining/471.png\n",
            " inflated: BLtraining/4710.png\n",
            " inflated: BLtraining/4711.png\n",
            " inflated: BLtraining/4712.png\n",
            " inflated: BLtraining/4713.png\n",
            " inflated: BLtraining/4714.png\n",
            " inflated: BLtraining/4715.png\n",
            " inflated: BLtraining/4716.png\n",
            " inflated: BLtraining/4717.png\n",
            " inflated: BLtraining/4718.png\n",
            " inflated: BLtraining/4719.png\n",
            " inflated: BLtraining/472.png\n",
            " inflated: BLtraining/4720.png\n",
            " inflated: BLtraining/4721.png\n",
            " inflated: BLtraining/4722.png\n",
            " inflated: BLtraining/4723.png\n",
            " inflated: BLtraining/4724.png\n",
            " inflated: BLtraining/4725.png\n",
            " inflated: BLtraining/4726.png\n",
            " inflated: BLtraining/4727.png\n",
            " inflated: BLtraining/4728.png\n",
            " inflated: BLtraining/4729.png\n",
            " inflated: BLtraining/473.png\n",
            " inflated: BLtraining/4730.png\n",
            " inflated: BLtraining/4731.png\n",
            " inflated: BLtraining/4732.png\n",
            " inflated: BLtraining/4733.png\n",
            " inflated: BLtraining/4734.png\n",
            " inflated: BLtraining/4735.png\n",
            " inflated: BLtraining/4736.png\n",
            " inflated: BLtraining/4737.png\n",
            " inflated: BLtraining/4738.png\n",
            " inflated: BLtraining/4739.png\n",
            " inflated: BLtraining/474.png\n",
            " inflated: BLtraining/4740.png\n",
            " inflated: BLtraining/4741.png\n",
            " inflated: BLtraining/4742.png\n",
            " inflated: BLtraining/4743.png\n",
            " inflated: BLtraining/4744.png\n",
            " inflated: BLtraining/4745.png\n",
            " inflated: BLtraining/4746.png\n",
            " inflated: BLtraining/4747.png\n",
            " inflated: BLtraining/4748.png\n",
            " inflated: BLtraining/4749.png\n",
            " inflated: BLtraining/475.png\n",
            " inflated: BLtraining/4750.png\n",
            " inflated: BLtraining/4751.png\n",
            " inflated: BLtraining/4752.png\n",
            " inflated: BLtraining/4753.png\n",
            " inflated: BLtraining/4754.png\n",
            " inflated: BLtraining/4755.png\n",
            " inflated: BLtraining/4756.png\n",
            " inflated: BLtraining/4757.png\n",
            " inflated: BLtraining/4758.png\n",
            " inflated: BLtraining/4759.png\n",
            " inflated: BLtraining/476.png\n",
            " inflated: BLtraining/4760.png\n",
            " inflated: BLtraining/4761.png\n",
            " inflated: BLtraining/4762.png\n",
            " inflated: BLtraining/4763.png\n",
            " inflated: BLtraining/4764.png\n",
            " inflated: BLtraining/4765.png\n",
            " inflated: BLtraining/4766.png\n",
            " inflated: BLtraining/4767.png\n",
            " inflated: BLtraining/4768.png\n",
            " inflated: BLtraining/4769.png\n",
            " inflated: BLtraining/477.png\n",
            " inflated: BLtraining/4770.png\n",
            " inflated: BLtraining/4771.png\n",
            " inflated: BLtraining/4772.png\n",
            " inflated: BLtraining/4773.png\n",
            " inflated: BLtraining/4774.png\n",
            " inflated: BLtraining/4775.png\n",
            " inflated: BLtraining/4776.png\n",
            " inflated: BLtraining/4777.png\n",
            " inflated: BLtraining/4778.png\n",
            " inflated: BLtraining/4779.png\n",
            " inflated: BLtraining/478.png\n",
            " inflated: BLtraining/4780.png\n",
            " inflated: BLtraining/4781.png\n",
            " inflated: BLtraining/4782.png\n",
            " inflated: BLtraining/4783.png\n",
            " inflated: BLtraining/4784.png\n",
            " inflated: BLtraining/4785.png\n",
            " inflated: BLtraining/4786.png\n",
            " inflated: BLtraining/4787.png\n",
            " inflated: BLtraining/4788.png\n",
            " inflated: BLtraining/4789.png\n",
            " inflated: BLtraining/479.png\n",
            " inflated: BLtraining/4790.png\n",
            " inflated: BLtraining/4791.png\n",
            " inflated: BLtraining/4792.png\n",
            " inflated: BLtraining/4793.png\n",
            " inflated: BLtraining/4794.png\n",
            " inflated: BLtraining/4795.png\n",
            " inflated: BLtraining/4796.png\n",
            " inflated: BLtraining/4797.png\n",
            " inflated: BLtraining/4798.png\n",
            " inflated: BLtraining/4799.png\n",
            " inflated: BLtraining/48.png\n",
            " inflated: BLtraining/480.png\n",
            " inflated: BLtraining/4800.png\n",
            " inflated: BLtraining/4801.png\n",
            " inflated: BLtraining/4802.png\n",
            " inflated: BLtraining/4803.png\n",
            " inflated: BLtraining/4804.png\n",
            " inflated: BLtraining/4805.png\n",
            " inflated: BLtraining/4806.png\n",
            " inflated: BLtraining/4807.png\n",
            " inflated: BLtraining/4808.png\n",
            " inflated: BLtraining/4809.png\n",
            " inflated: BLtraining/481.png\n",
            " inflated: BLtraining/4810.png\n",
            " inflated: BLtraining/4811.png\n",
            " inflated: BLtraining/4812.png\n",
            " inflated: BLtraining/4813.png\n",
            " inflated: BLtraining/4814.png\n",
            " inflated: BLtraining/4815.png\n",
            " inflated: BLtraining/4816.png\n",
            " inflated: BLtraining/4817.png\n",
            " inflated: BLtraining/4818.png\n",
            " inflated: BLtraining/4819.png\n",
            " inflated: BLtraining/482.png\n",
            " inflated: BLtraining/4820.png\n",
            " inflated: BLtraining/4821.png\n",
            " inflated: BLtraining/4822.png\n",
            " inflated: BLtraining/4823.png\n",
            " inflated: BLtraining/4824.png\n",
            " inflated: BLtraining/4825.png\n",
            " inflated: BLtraining/4826.png\n",
            " inflated: BLtraining/4827.png\n",
            " inflated: BLtraining/4828.png\n",
            " inflated: BLtraining/4829.png\n",
            " inflated: BLtraining/483.png\n",
            " inflated: BLtraining/4830.png\n",
            " inflated: BLtraining/4831.png\n",
            " inflated: BLtraining/4832.png\n",
            " inflated: BLtraining/4833.png\n",
            " inflated: BLtraining/4834.png\n",
            " inflated: BLtraining/4835.png\n",
            " inflated: BLtraining/4836.png\n",
            " inflated: BLtraining/4837.png\n",
            " inflated: BLtraining/4838.png\n",
            " inflated: BLtraining/4839.png\n",
            " inflated: BLtraining/484.png\n",
            " inflated: BLtraining/4840.png\n",
            " inflated: BLtraining/4841.png\n",
            " inflated: BLtraining/4842.png\n",
            " inflated: BLtraining/4843.png\n",
            " inflated: BLtraining/4844.png\n",
            " inflated: BLtraining/4845.png\n",
            " inflated: BLtraining/4846.png\n",
            " inflated: BLtraining/4847.png\n",
            " inflated: BLtraining/4848.png\n",
            " inflated: BLtraining/4849.png\n",
            " inflated: BLtraining/485.png\n",
            " inflated: BLtraining/4850.png\n",
            " inflated: BLtraining/4851.png\n",
            " inflated: BLtraining/4852.png\n",
            " inflated: BLtraining/4853.png\n",
            " inflated: BLtraining/4854.png\n",
            " inflated: BLtraining/4855.png\n",
            " inflated: BLtraining/4856.png\n",
            " inflated: BLtraining/4857.png\n",
            " inflated: BLtraining/4858.png\n",
            " inflated: BLtraining/4859.png\n",
            " inflated: BLtraining/486.png\n",
            " inflated: BLtraining/4860.png\n",
            " inflated: BLtraining/4861.png\n",
            " inflated: BLtraining/4862.png\n",
            " inflated: BLtraining/4863.png\n",
            " inflated: BLtraining/4864.png\n",
            " inflated: BLtraining/4865.png\n",
            " inflated: BLtraining/4866.png\n",
            " inflated: BLtraining/4867.png\n",
            " inflated: BLtraining/4868.png\n",
            " inflated: BLtraining/4869.png\n",
            " inflated: BLtraining/487.png\n",
            " inflated: BLtraining/4870.png\n",
            " inflated: BLtraining/4871.png\n",
            " inflated: BLtraining/4872.png\n",
            " inflated: BLtraining/4873.png\n",
            " inflated: BLtraining/4874.png\n",
            " inflated: BLtraining/4875.png\n",
            " inflated: BLtraining/4876.png\n",
            " inflated: BLtraining/4877.png\n",
            " inflated: BLtraining/4878.png\n",
            " inflated: BLtraining/4879.png\n",
            " inflated: BLtraining/488.png\n",
            " inflated: BLtraining/4880.png\n",
            " inflated: BLtraining/4881.png\n",
            " inflated: BLtraining/4882.png\n",
            " inflated: BLtraining/4883.png\n",
            " inflated: BLtraining/4884.png\n",
            " inflated: BLtraining/4885.png\n",
            " inflated: BLtraining/4886.png\n",
            " inflated: BLtraining/4887.png\n",
            " inflated: BLtraining/4888.png\n",
            " inflated: BLtraining/4889.png\n",
            " inflated: BLtraining/489.png\n",
            " inflated: BLtraining/4890.png\n",
            " inflated: BLtraining/4891.png\n",
            " inflated: BLtraining/4892.png\n",
            " inflated: BLtraining/4893.png\n",
            " inflated: BLtraining/4894.png\n",
            " inflated: BLtraining/4895.png\n",
            " inflated: BLtraining/4896.png\n",
            " inflated: BLtraining/4897.png\n",
            " inflated: BLtraining/4898.png\n",
            " inflated: BLtraining/4899.png\n",
            " inflated: BLtraining/49.png\n",
            " inflated: BLtraining/490.png\n",
            " inflated: BLtraining/4900.png\n",
            " inflated: BLtraining/4901.png\n",
            " inflated: BLtraining/4902.png\n",
            " inflated: BLtraining/4903.png\n",
            " inflated: BLtraining/4904.png\n",
            " inflated: BLtraining/4905.png\n",
            " inflated: BLtraining/4906.png\n",
            " inflated: BLtraining/4907.png\n",
            " inflated: BLtraining/4908.png\n",
            " inflated: BLtraining/4909.png\n",
            " inflated: BLtraining/491.png\n",
            " inflated: BLtraining/4910.png\n",
            " inflated: BLtraining/4911.png\n",
            " inflated: BLtraining/4912.png\n",
            " inflated: BLtraining/4913.png\n",
            " inflated: BLtraining/4914.png\n",
            " inflated: BLtraining/4915.png\n",
            " inflated: BLtraining/4916.png\n",
            " inflated: BLtraining/4917.png\n",
            " inflated: BLtraining/4918.png\n",
            " inflated: BLtraining/4919.png\n",
            " inflated: BLtraining/492.png\n",
            " inflated: BLtraining/4920.png\n",
            " inflated: BLtraining/4921.png\n",
            " inflated: BLtraining/4922.png\n",
            " inflated: BLtraining/4923.png\n",
            " inflated: BLtraining/4924.png\n",
            " inflated: BLtraining/4925.png\n",
            " inflated: BLtraining/4926.png\n",
            " inflated: BLtraining/4927.png\n",
            " inflated: BLtraining/4928.png\n",
            " inflated: BLtraining/4929.png\n",
            " inflated: BLtraining/493.png\n",
            " inflated: BLtraining/4930.png\n",
            " inflated: BLtraining/4931.png\n",
            " inflated: BLtraining/4932.png\n",
            " inflated: BLtraining/4933.png\n",
            " inflated: BLtraining/4934.png\n",
            " inflated: BLtraining/4935.png\n",
            " inflated: BLtraining/4936.png\n",
            " inflated: BLtraining/4937.png\n",
            " inflated: BLtraining/4938.png\n",
            " inflated: BLtraining/4939.png\n",
            " inflated: BLtraining/494.png\n",
            " inflated: BLtraining/4940.png\n",
            " inflated: BLtraining/4941.png\n",
            " inflated: BLtraining/4942.png\n",
            " inflated: BLtraining/4943.png\n",
            " inflated: BLtraining/4944.png\n",
            " inflated: BLtraining/4945.png\n",
            " inflated: BLtraining/4946.png\n",
            " inflated: BLtraining/4947.png\n",
            " inflated: BLtraining/4948.png\n",
            " inflated: BLtraining/4949.png\n",
            " inflated: BLtraining/495.png\n",
            " inflated: BLtraining/4950.png\n",
            " inflated: BLtraining/4951.png\n",
            " inflated: BLtraining/4952.png\n",
            " inflated: BLtraining/4953.png\n",
            " inflated: BLtraining/4954.png\n",
            " inflated: BLtraining/4955.png\n",
            " inflated: BLtraining/4956.png\n",
            " inflated: BLtraining/4957.png\n",
            " inflated: BLtraining/4958.png\n",
            " inflated: BLtraining/4959.png\n",
            " inflated: BLtraining/496.png\n",
            " inflated: BLtraining/4960.png\n",
            " inflated: BLtraining/4961.png\n",
            " inflated: BLtraining/4962.png\n",
            " inflated: BLtraining/4963.png\n",
            " inflated: BLtraining/4964.png\n",
            " inflated: BLtraining/4965.png\n",
            " inflated: BLtraining/4966.png\n",
            " inflated: BLtraining/4967.png\n",
            " inflated: BLtraining/4968.png\n",
            " inflated: BLtraining/4969.png\n",
            " inflated: BLtraining/497.png\n",
            " inflated: BLtraining/4970.png\n",
            " inflated: BLtraining/4971.png\n",
            " inflated: BLtraining/4972.png\n",
            " inflated: BLtraining/4973.png\n",
            " inflated: BLtraining/4974.png\n",
            " inflated: BLtraining/4975.png\n",
            " inflated: BLtraining/4976.png\n",
            " inflated: BLtraining/4977.png\n",
            " inflated: BLtraining/4978.png\n",
            " inflated: BLtraining/4979.png\n",
            " inflated: BLtraining/498.png\n",
            " inflated: BLtraining/4980.png\n",
            " inflated: BLtraining/4981.png\n",
            " inflated: BLtraining/4982.png\n",
            " inflated: BLtraining/4983.png\n",
            " inflated: BLtraining/4984.png\n",
            " inflated: BLtraining/4985.png\n",
            " inflated: BLtraining/4986.png\n",
            " inflated: BLtraining/4987.png\n",
            " inflated: BLtraining/4988.png\n",
            " inflated: BLtraining/4989.png\n",
            " inflated: BLtraining/499.png\n",
            " inflated: BLtraining/4990.png\n",
            " inflated: BLtraining/4991.png\n",
            " inflated: BLtraining/4992.png\n",
            " inflated: BLtraining/4993.png\n",
            " inflated: BLtraining/4994.png\n",
            " inflated: BLtraining/4995.png\n",
            " inflated: BLtraining/4996.png\n",
            " inflated: BLtraining/4997.png\n",
            " inflated: BLtraining/4998.png\n",
            " inflated: BLtraining/4999.png\n",
            " inflated: BLtraining/5.png\n",
            " inflated: BLtraining/50.png\n",
            " inflated: BLtraining/500.png\n",
            " inflated: BLtraining/5000.png\n",
            " inflated: BLtraining/5001.png\n",
            " inflated: BLtraining/5002.png\n",
            " inflated: BLtraining/5003.png\n",
            " inflated: BLtraining/5004.png\n",
            " inflated: BLtraining/5005.png\n",
            " inflated: BLtraining/5006.png\n",
            " inflated: BLtraining/5007.png\n",
            " inflated: BLtraining/5008.png\n",
            " inflated: BLtraining/5009.png\n",
            " inflated: BLtraining/501.png\n",
            " inflated: BLtraining/5010.png\n",
            " inflated: BLtraining/5011.png\n",
            " inflated: BLtraining/5012.png\n",
            " inflated: BLtraining/5013.png\n",
            " inflated: BLtraining/5014.png\n",
            " inflated: BLtraining/5015.png\n",
            " inflated: BLtraining/5016.png\n",
            " inflated: BLtraining/5017.png\n",
            " inflated: BLtraining/5018.png\n",
            " inflated: BLtraining/5019.png\n",
            " inflated: BLtraining/502.png\n",
            " inflated: BLtraining/5020.png\n",
            " inflated: BLtraining/5021.png\n",
            " inflated: BLtraining/5022.png\n",
            " inflated: BLtraining/5023.png\n",
            " inflated: BLtraining/5024.png\n",
            " inflated: BLtraining/5025.png\n",
            " inflated: BLtraining/5026.png\n",
            " inflated: BLtraining/5027.png\n",
            " inflated: BLtraining/5028.png\n",
            " inflated: BLtraining/5029.png\n",
            " inflated: BLtraining/503.png\n",
            " inflated: BLtraining/5030.png\n",
            " inflated: BLtraining/5031.png\n",
            " inflated: BLtraining/5032.png\n",
            " inflated: BLtraining/5033.png\n",
            " inflated: BLtraining/5034.png\n",
            " inflated: BLtraining/5035.png\n",
            " inflated: BLtraining/5036.png\n",
            " inflated: BLtraining/5037.png\n",
            " inflated: BLtraining/5038.png\n",
            " inflated: BLtraining/5039.png\n",
            " inflated: BLtraining/504.png\n",
            " inflated: BLtraining/5040.png\n",
            " inflated: BLtraining/5041.png\n",
            " inflated: BLtraining/5042.png\n",
            " inflated: BLtraining/5043.png\n",
            " inflated: BLtraining/5044.png\n",
            " inflated: BLtraining/5045.png\n",
            " inflated: BLtraining/5046.png\n",
            " inflated: BLtraining/5047.png\n",
            " inflated: BLtraining/5048.png\n",
            " inflated: BLtraining/5049.png\n",
            " inflated: BLtraining/505.png\n",
            " inflated: BLtraining/5050.png\n",
            " inflated: BLtraining/5051.png\n",
            " inflated: BLtraining/5052.png\n",
            " inflated: BLtraining/5053.png\n",
            " inflated: BLtraining/5054.png\n",
            " inflated: BLtraining/5055.png\n",
            " inflated: BLtraining/5056.png\n",
            " inflated: BLtraining/5057.png\n",
            " inflated: BLtraining/5058.png\n",
            " inflated: BLtraining/5059.png\n",
            " inflated: BLtraining/506.png\n",
            " inflated: BLtraining/5060.png\n",
            " inflated: BLtraining/5061.png\n",
            " inflated: BLtraining/5062.png\n",
            " inflated: BLtraining/5063.png\n",
            " inflated: BLtraining/5064.png\n",
            " inflated: BLtraining/5065.png\n",
            " inflated: BLtraining/5066.png\n",
            " inflated: BLtraining/5067.png\n",
            " inflated: BLtraining/5068.png\n",
            " inflated: BLtraining/5069.png\n",
            " inflated: BLtraining/507.png\n",
            " inflated: BLtraining/5070.png\n",
            " inflated: BLtraining/5071.png\n",
            " inflated: BLtraining/5072.png\n",
            " inflated: BLtraining/5073.png\n",
            " inflated: BLtraining/5074.png\n",
            " inflated: BLtraining/5075.png\n",
            " inflated: BLtraining/5076.png\n",
            " inflated: BLtraining/5077.png\n",
            " inflated: BLtraining/5078.png\n",
            " inflated: BLtraining/5079.png\n",
            " inflated: BLtraining/508.png\n",
            " inflated: BLtraining/5080.png\n",
            " inflated: BLtraining/5081.png\n",
            " inflated: BLtraining/5082.png\n",
            " inflated: BLtraining/5083.png\n",
            " inflated: BLtraining/5084.png\n",
            " inflated: BLtraining/5085.png\n",
            " inflated: BLtraining/5086.png\n",
            " inflated: BLtraining/5087.png\n",
            " inflated: BLtraining/5088.png\n",
            " inflated: BLtraining/5089.png\n",
            " inflated: BLtraining/509.png\n",
            " inflated: BLtraining/5090.png\n",
            " inflated: BLtraining/5091.png\n",
            " inflated: BLtraining/5092.png\n",
            " inflated: BLtraining/5093.png\n",
            " inflated: BLtraining/5094.png\n",
            " inflated: BLtraining/5095.png\n",
            " inflated: BLtraining/5096.png\n",
            " inflated: BLtraining/5097.png\n",
            " inflated: BLtraining/5098.png\n",
            " inflated: BLtraining/5099.png\n",
            " inflated: BLtraining/51.png\n",
            " inflated: BLtraining/510.png\n",
            " inflated: BLtraining/5100.png\n",
            " inflated: BLtraining/5101.png\n",
            " inflated: BLtraining/5102.png\n",
            " inflated: BLtraining/5103.png\n",
            " inflated: BLtraining/5104.png\n",
            " inflated: BLtraining/5105.png\n",
            " inflated: BLtraining/5106.png\n",
            " inflated: BLtraining/5107.png\n",
            " inflated: BLtraining/5108.png\n",
            " inflated: BLtraining/5109.png\n",
            " inflated: BLtraining/511.png\n",
            " inflated: BLtraining/5110.png\n",
            " inflated: BLtraining/5111.png\n",
            " inflated: BLtraining/5112.png\n",
            " inflated: BLtraining/5113.png\n",
            " inflated: BLtraining/5114.png\n",
            " inflated: BLtraining/5115.png\n",
            " inflated: BLtraining/5116.png\n",
            " inflated: BLtraining/5117.png\n",
            " inflated: BLtraining/5118.png\n",
            " inflated: BLtraining/5119.png\n",
            " inflated: BLtraining/512.png\n",
            " inflated: BLtraining/5120.png\n",
            " inflated: BLtraining/5121.png\n",
            " inflated: BLtraining/5122.png\n",
            " inflated: BLtraining/5123.png\n",
            " inflated: BLtraining/5124.png\n",
            " inflated: BLtraining/5125.png\n",
            " inflated: BLtraining/5126.png\n",
            " inflated: BLtraining/5127.png\n",
            " inflated: BLtraining/5128.png\n",
            " inflated: BLtraining/5129.png\n",
            " inflated: BLtraining/513.png\n",
            " inflated: BLtraining/5130.png\n",
            " inflated: BLtraining/5131.png\n",
            " inflated: BLtraining/5132.png\n",
            " inflated: BLtraining/5133.png\n",
            " inflated: BLtraining/5134.png\n",
            " inflated: BLtraining/5135.png\n",
            " inflated: BLtraining/5136.png\n",
            " inflated: BLtraining/5137.png\n",
            " inflated: BLtraining/5138.png\n",
            " inflated: BLtraining/5139.png\n",
            " inflated: BLtraining/514.png\n",
            " inflated: BLtraining/5140.png\n",
            " inflated: BLtraining/5141.png\n",
            " inflated: BLtraining/5142.png\n",
            " inflated: BLtraining/5143.png\n",
            " inflated: BLtraining/5144.png\n",
            " inflated: BLtraining/5145.png\n",
            " inflated: BLtraining/5146.png\n",
            " inflated: BLtraining/5147.png\n",
            " inflated: BLtraining/5148.png\n",
            " inflated: BLtraining/5149.png\n",
            " inflated: BLtraining/515.png\n",
            " inflated: BLtraining/5150.png\n",
            " inflated: BLtraining/5151.png\n",
            " inflated: BLtraining/5152.png\n",
            " inflated: BLtraining/5153.png\n",
            " inflated: BLtraining/5154.png\n",
            " inflated: BLtraining/5155.png\n",
            " inflated: BLtraining/5156.png\n",
            " inflated: BLtraining/5157.png\n",
            " inflated: BLtraining/5158.png\n",
            " inflated: BLtraining/5159.png\n",
            " inflated: BLtraining/516.png\n",
            " inflated: BLtraining/5160.png\n",
            " inflated: BLtraining/5161.png\n",
            " inflated: BLtraining/5162.png\n",
            " inflated: BLtraining/5163.png\n",
            " inflated: BLtraining/5164.png\n",
            " inflated: BLtraining/5165.png\n",
            " inflated: BLtraining/5166.png\n",
            " inflated: BLtraining/5167.png\n",
            " inflated: BLtraining/5168.png\n",
            " inflated: BLtraining/5169.png\n",
            " inflated: BLtraining/517.png\n",
            " inflated: BLtraining/5170.png\n",
            " inflated: BLtraining/5171.png\n",
            " inflated: BLtraining/5172.png\n",
            " inflated: BLtraining/5173.png\n",
            " inflated: BLtraining/5174.png\n",
            " inflated: BLtraining/5175.png\n",
            " inflated: BLtraining/5176.png\n",
            " inflated: BLtraining/5177.png\n",
            " inflated: BLtraining/5178.png\n",
            " inflated: BLtraining/5179.png\n",
            " inflated: BLtraining/518.png\n",
            " inflated: BLtraining/5180.png\n",
            " inflated: BLtraining/5181.png\n",
            " inflated: BLtraining/5182.png\n",
            " inflated: BLtraining/5183.png\n",
            " inflated: BLtraining/5184.png\n",
            " inflated: BLtraining/5185.png\n",
            " inflated: BLtraining/5186.png\n",
            " inflated: BLtraining/5187.png\n",
            " inflated: BLtraining/5188.png\n",
            " inflated: BLtraining/5189.png\n",
            " inflated: BLtraining/519.png\n",
            " inflated: BLtraining/5190.png\n",
            " inflated: BLtraining/5191.png\n",
            " inflated: BLtraining/5192.png\n",
            " inflated: BLtraining/5193.png\n",
            " inflated: BLtraining/5194.png\n",
            " inflated: BLtraining/5195.png\n",
            " inflated: BLtraining/5196.png\n",
            " inflated: BLtraining/5197.png\n",
            " inflated: BLtraining/5198.png\n",
            " inflated: BLtraining/5199.png\n",
            " inflated: BLtraining/52.png\n",
            " inflated: BLtraining/520.png\n",
            " inflated: BLtraining/5200.png\n",
            " inflated: BLtraining/5201.png\n",
            " inflated: BLtraining/5202.png\n",
            " inflated: BLtraining/5203.png\n",
            " inflated: BLtraining/5204.png\n",
            " inflated: BLtraining/5205.png\n",
            " inflated: BLtraining/5206.png\n",
            " inflated: BLtraining/5207.png\n",
            " inflated: BLtraining/5208.png\n",
            " inflated: BLtraining/5209.png\n",
            " inflated: BLtraining/521.png\n",
            " inflated: BLtraining/5210.png\n",
            " inflated: BLtraining/5211.png\n",
            " inflated: BLtraining/5212.png\n",
            " inflated: BLtraining/5213.png\n",
            " inflated: BLtraining/5214.png\n",
            " inflated: BLtraining/5215.png\n",
            " inflated: BLtraining/5216.png\n",
            " inflated: BLtraining/5217.png\n",
            " inflated: BLtraining/5218.png\n",
            " inflated: BLtraining/5219.png\n",
            " inflated: BLtraining/522.png\n",
            " inflated: BLtraining/5220.png\n",
            " inflated: BLtraining/5221.png\n",
            " inflated: BLtraining/5222.png\n",
            " inflated: BLtraining/5223.png\n",
            " inflated: BLtraining/5224.png\n",
            " inflated: BLtraining/5225.png\n",
            " inflated: BLtraining/5226.png\n",
            " inflated: BLtraining/5227.png\n",
            " inflated: BLtraining/5228.png\n",
            " inflated: BLtraining/5229.png\n",
            " inflated: BLtraining/523.png\n",
            " inflated: BLtraining/5230.png\n",
            " inflated: BLtraining/5231.png\n",
            " inflated: BLtraining/5232.png\n",
            " inflated: BLtraining/5233.png\n",
            " inflated: BLtraining/5234.png\n",
            " inflated: BLtraining/5235.png\n",
            " inflated: BLtraining/5236.png\n",
            " inflated: BLtraining/5237.png\n",
            " inflated: BLtraining/5238.png\n",
            " inflated: BLtraining/5239.png\n",
            " inflated: BLtraining/524.png\n",
            " inflated: BLtraining/5240.png\n",
            " inflated: BLtraining/5241.png\n",
            " inflated: BLtraining/5242.png\n",
            " inflated: BLtraining/5243.png\n",
            " inflated: BLtraining/5244.png\n",
            " inflated: BLtraining/5245.png\n",
            " inflated: BLtraining/5246.png\n",
            " inflated: BLtraining/5247.png\n",
            " inflated: BLtraining/5248.png\n",
            " inflated: BLtraining/5249.png\n",
            " inflated: BLtraining/525.png\n",
            " inflated: BLtraining/5250.png\n",
            " inflated: BLtraining/5251.png\n",
            " inflated: BLtraining/5252.png\n",
            " inflated: BLtraining/5253.png\n",
            " inflated: BLtraining/5254.png\n",
            " inflated: BLtraining/5255.png\n",
            " inflated: BLtraining/5256.png\n",
            " inflated: BLtraining/5257.png\n",
            " inflated: BLtraining/5258.png\n",
            " inflated: BLtraining/5259.png\n",
            " inflated: BLtraining/526.png\n",
            " inflated: BLtraining/5260.png\n",
            " inflated: BLtraining/5261.png\n",
            " inflated: BLtraining/5262.png\n",
            " inflated: BLtraining/5263.png\n",
            " inflated: BLtraining/5264.png\n",
            " inflated: BLtraining/5265.png\n",
            " inflated: BLtraining/5266.png\n",
            " inflated: BLtraining/5267.png\n",
            " inflated: BLtraining/5268.png\n",
            " inflated: BLtraining/5269.png\n",
            " inflated: BLtraining/527.png\n",
            " inflated: BLtraining/5270.png\n",
            " inflated: BLtraining/5271.png\n",
            " inflated: BLtraining/5272.png\n",
            " inflated: BLtraining/5273.png\n",
            " inflated: BLtraining/5274.png\n",
            " inflated: BLtraining/5275.png\n",
            " inflated: BLtraining/5276.png\n",
            " inflated: BLtraining/5277.png\n",
            " inflated: BLtraining/5278.png\n",
            " inflated: BLtraining/5279.png\n",
            " inflated: BLtraining/528.png\n",
            " inflated: BLtraining/5280.png\n",
            " inflated: BLtraining/5281.png\n",
            " inflated: BLtraining/5282.png\n",
            " inflated: BLtraining/5283.png\n",
            " inflated: BLtraining/5284.png\n",
            " inflated: BLtraining/5285.png\n",
            " inflated: BLtraining/5286.png\n",
            " inflated: BLtraining/5287.png\n",
            " inflated: BLtraining/5288.png\n",
            " inflated: BLtraining/5289.png\n",
            " inflated: BLtraining/529.png\n",
            " inflated: BLtraining/5290.png\n",
            " inflated: BLtraining/5291.png\n",
            " inflated: BLtraining/5292.png\n",
            " inflated: BLtraining/5293.png\n",
            " inflated: BLtraining/5294.png\n",
            " inflated: BLtraining/5295.png\n",
            " inflated: BLtraining/5296.png\n",
            " inflated: BLtraining/5297.png\n",
            " inflated: BLtraining/5298.png\n",
            " inflated: BLtraining/5299.png\n",
            " inflated: BLtraining/53.png\n",
            " inflated: BLtraining/530.png\n",
            " inflated: BLtraining/5300.png\n",
            " inflated: BLtraining/5301.png\n",
            " inflated: BLtraining/5302.png\n",
            " inflated: BLtraining/5303.png\n",
            " inflated: BLtraining/5304.png\n",
            " inflated: BLtraining/5305.png\n",
            " inflated: BLtraining/5306.png\n",
            " inflated: BLtraining/5307.png\n",
            " inflated: BLtraining/5308.png\n",
            " inflated: BLtraining/5309.png\n",
            " inflated: BLtraining/531.png\n",
            " inflated: BLtraining/5310.png\n",
            " inflated: BLtraining/5311.png\n",
            " inflated: BLtraining/5312.png\n",
            " inflated: BLtraining/5313.png\n",
            " inflated: BLtraining/5314.png\n",
            " inflated: BLtraining/5315.png\n",
            " inflated: BLtraining/5316.png\n",
            " inflated: BLtraining/5317.png\n",
            " inflated: BLtraining/5318.png\n",
            " inflated: BLtraining/5319.png\n",
            " inflated: BLtraining/532.png\n",
            " inflated: BLtraining/5320.png\n",
            " inflated: BLtraining/5321.png\n",
            " inflated: BLtraining/5322.png\n",
            " inflated: BLtraining/5323.png\n",
            " inflated: BLtraining/5324.png\n",
            " inflated: BLtraining/5325.png\n",
            " inflated: BLtraining/5326.png\n",
            " inflated: BLtraining/5327.png\n",
            " inflated: BLtraining/5328.png\n",
            " inflated: BLtraining/5329.png\n",
            " inflated: BLtraining/533.png\n",
            " inflated: BLtraining/5330.png\n",
            " inflated: BLtraining/5331.png\n",
            " inflated: BLtraining/5332.png\n",
            " inflated: BLtraining/5333.png\n",
            " inflated: BLtraining/5334.png\n",
            " inflated: BLtraining/5335.png\n",
            " inflated: BLtraining/5336.png\n",
            " inflated: BLtraining/5337.png\n",
            " inflated: BLtraining/5338.png\n",
            " inflated: BLtraining/5339.png\n",
            " inflated: BLtraining/534.png\n",
            " inflated: BLtraining/5340.png\n",
            " inflated: BLtraining/5341.png\n",
            " inflated: BLtraining/5342.png\n",
            " inflated: BLtraining/5343.png\n",
            " inflated: BLtraining/5344.png\n",
            " inflated: BLtraining/5345.png\n",
            " inflated: BLtraining/5346.png\n",
            " inflated: BLtraining/5347.png\n",
            " inflated: BLtraining/5348.png\n",
            " inflated: BLtraining/5349.png\n",
            " inflated: BLtraining/535.png\n",
            " inflated: BLtraining/5350.png\n",
            " inflated: BLtraining/5351.png\n",
            " inflated: BLtraining/5352.png\n",
            " inflated: BLtraining/5353.png\n",
            " inflated: BLtraining/5354.png\n",
            " inflated: BLtraining/5355.png\n",
            " inflated: BLtraining/5356.png\n",
            " inflated: BLtraining/5357.png\n",
            " inflated: BLtraining/5358.png\n",
            " inflated: BLtraining/5359.png\n",
            " inflated: BLtraining/536.png\n",
            " inflated: BLtraining/5360.png\n",
            " inflated: BLtraining/5361.png\n",
            " inflated: BLtraining/5362.png\n",
            " inflated: BLtraining/5363.png\n",
            " inflated: BLtraining/5364.png\n",
            " inflated: BLtraining/5365.png\n",
            " inflated: BLtraining/5366.png\n",
            " inflated: BLtraining/5367.png\n",
            " inflated: BLtraining/5368.png\n",
            " inflated: BLtraining/5369.png\n",
            " inflated: BLtraining/537.png\n",
            " inflated: BLtraining/5370.png\n",
            " inflated: BLtraining/5371.png\n",
            " inflated: BLtraining/5372.png\n",
            " inflated: BLtraining/5373.png\n",
            " inflated: BLtraining/5374.png\n",
            " inflated: BLtraining/5375.png\n",
            " inflated: BLtraining/5376.png\n",
            " inflated: BLtraining/5377.png\n",
            " inflated: BLtraining/5378.png\n",
            " inflated: BLtraining/5379.png\n",
            " inflated: BLtraining/538.png\n",
            " inflated: BLtraining/5380.png\n",
            " inflated: BLtraining/5381.png\n",
            " inflated: BLtraining/5382.png\n",
            " inflated: BLtraining/5383.png\n",
            " inflated: BLtraining/5384.png\n",
            " inflated: BLtraining/5385.png\n",
            " inflated: BLtraining/5386.png\n",
            " inflated: BLtraining/5387.png\n",
            " inflated: BLtraining/5388.png\n",
            " inflated: BLtraining/5389.png\n",
            " inflated: BLtraining/539.png\n",
            " inflated: BLtraining/5390.png\n",
            " inflated: BLtraining/5391.png\n",
            " inflated: BLtraining/5392.png\n",
            " inflated: BLtraining/5393.png\n",
            " inflated: BLtraining/5394.png\n",
            " inflated: BLtraining/5395.png\n",
            " inflated: BLtraining/5396.png\n",
            " inflated: BLtraining/5397.png\n",
            " inflated: BLtraining/5398.png\n",
            " inflated: BLtraining/5399.png\n",
            " inflated: BLtraining/54.png\n",
            " inflated: BLtraining/540.png\n",
            " inflated: BLtraining/5400.png\n",
            " inflated: BLtraining/5401.png\n",
            " inflated: BLtraining/5402.png\n",
            " inflated: BLtraining/5403.png\n",
            " inflated: BLtraining/5404.png\n",
            " inflated: BLtraining/5405.png\n",
            " inflated: BLtraining/5406.png\n",
            " inflated: BLtraining/5407.png\n",
            " inflated: BLtraining/5408.png\n",
            " inflated: BLtraining/5409.png\n",
            " inflated: BLtraining/541.png\n",
            " inflated: BLtraining/5410.png\n",
            " inflated: BLtraining/5411.png\n",
            " inflated: BLtraining/5412.png\n",
            " inflated: BLtraining/5413.png\n",
            " inflated: BLtraining/5414.png\n",
            " inflated: BLtraining/5415.png\n",
            " inflated: BLtraining/5416.png\n",
            " inflated: BLtraining/5417.png\n",
            " inflated: BLtraining/5418.png\n",
            " inflated: BLtraining/5419.png\n",
            " inflated: BLtraining/542.png\n",
            " inflated: BLtraining/5420.png\n",
            " inflated: BLtraining/5421.png\n",
            " inflated: BLtraining/5422.png\n",
            " inflated: BLtraining/5423.png\n",
            " inflated: BLtraining/5424.png\n",
            " inflated: BLtraining/5425.png\n",
            " inflated: BLtraining/5426.png\n",
            " inflated: BLtraining/5427.png\n",
            " inflated: BLtraining/5428.png\n",
            " inflated: BLtraining/5429.png\n",
            " inflated: BLtraining/543.png\n",
            " inflated: BLtraining/5430.png\n",
            " inflated: BLtraining/5431.png\n",
            " inflated: BLtraining/5432.png\n",
            " inflated: BLtraining/5433.png\n",
            " inflated: BLtraining/5434.png\n",
            " inflated: BLtraining/5435.png\n",
            " inflated: BLtraining/5436.png\n",
            " inflated: BLtraining/5437.png\n",
            " inflated: BLtraining/5438.png\n",
            " inflated: BLtraining/5439.png\n",
            " inflated: BLtraining/544.png\n",
            " inflated: BLtraining/5440.png\n",
            " inflated: BLtraining/5441.png\n",
            " inflated: BLtraining/5442.png\n",
            " inflated: BLtraining/5443.png\n",
            " inflated: BLtraining/5444.png\n",
            " inflated: BLtraining/5445.png\n",
            " inflated: BLtraining/5446.png\n",
            " inflated: BLtraining/5447.png\n",
            " inflated: BLtraining/5448.png\n",
            " inflated: BLtraining/5449.png\n",
            " inflated: BLtraining/545.png\n",
            " inflated: BLtraining/5450.png\n",
            " inflated: BLtraining/5451.png\n",
            " inflated: BLtraining/5452.png\n",
            " inflated: BLtraining/5453.png\n",
            " inflated: BLtraining/5454.png\n",
            " inflated: BLtraining/5455.png\n",
            " inflated: BLtraining/5456.png\n",
            " inflated: BLtraining/5457.png\n",
            " inflated: BLtraining/5458.png\n",
            " inflated: BLtraining/5459.png\n",
            " inflated: BLtraining/546.png\n",
            " inflated: BLtraining/5460.png\n",
            " inflated: BLtraining/5461.png\n",
            " inflated: BLtraining/5462.png\n",
            " inflated: BLtraining/5463.png\n",
            " inflated: BLtraining/5464.png\n",
            " inflated: BLtraining/5465.png\n",
            " inflated: BLtraining/5466.png\n",
            " inflated: BLtraining/5467.png\n",
            " inflated: BLtraining/5468.png\n",
            " inflated: BLtraining/5469.png\n",
            " inflated: BLtraining/547.png\n",
            " inflated: BLtraining/5470.png\n",
            " inflated: BLtraining/5471.png\n",
            " inflated: BLtraining/5472.png\n",
            " inflated: BLtraining/5473.png\n",
            " inflated: BLtraining/5474.png\n",
            " inflated: BLtraining/5475.png\n",
            " inflated: BLtraining/5476.png\n",
            " inflated: BLtraining/5477.png\n",
            " inflated: BLtraining/5478.png\n",
            " inflated: BLtraining/5479.png\n",
            " inflated: BLtraining/548.png\n",
            " inflated: BLtraining/5480.png\n",
            " inflated: BLtraining/5481.png\n",
            " inflated: BLtraining/5482.png\n",
            " inflated: BLtraining/5483.png\n",
            " inflated: BLtraining/5484.png\n",
            " inflated: BLtraining/5485.png\n",
            " inflated: BLtraining/5486.png\n",
            " inflated: BLtraining/5487.png\n",
            " inflated: BLtraining/5488.png\n",
            " inflated: BLtraining/5489.png\n",
            " inflated: BLtraining/549.png\n",
            " inflated: BLtraining/5490.png\n",
            " inflated: BLtraining/5491.png\n",
            " inflated: BLtraining/5492.png\n",
            " inflated: BLtraining/5493.png\n",
            " inflated: BLtraining/5494.png\n",
            " inflated: BLtraining/5495.png\n",
            " inflated: BLtraining/5496.png\n",
            " inflated: BLtraining/5497.png\n",
            " inflated: BLtraining/5498.png\n",
            " inflated: BLtraining/5499.png\n",
            " inflated: BLtraining/55.png\n",
            " inflated: BLtraining/550.png\n",
            " inflated: BLtraining/5500.png\n",
            " inflated: BLtraining/5501.png\n",
            " inflated: BLtraining/5502.png\n",
            " inflated: BLtraining/5503.png\n",
            " inflated: BLtraining/5504.png\n",
            " inflated: BLtraining/5505.png\n",
            " inflated: BLtraining/5506.png\n",
            " inflated: BLtraining/5507.png\n",
            " inflated: BLtraining/5508.png\n",
            " inflated: BLtraining/5509.png\n",
            " inflated: BLtraining/551.png\n",
            " inflated: BLtraining/5510.png\n",
            " inflated: BLtraining/5511.png\n",
            " inflated: BLtraining/5512.png\n",
            " inflated: BLtraining/5513.png\n",
            " inflated: BLtraining/5514.png\n",
            " inflated: BLtraining/5515.png\n",
            " inflated: BLtraining/5516.png\n",
            " inflated: BLtraining/5517.png\n",
            " inflated: BLtraining/5518.png\n",
            " inflated: BLtraining/5519.png\n",
            " inflated: BLtraining/552.png\n",
            " inflated: BLtraining/5520.png\n",
            " inflated: BLtraining/5521.png\n",
            " inflated: BLtraining/5522.png\n",
            " inflated: BLtraining/5523.png\n",
            " inflated: BLtraining/5524.png\n",
            " inflated: BLtraining/5525.png\n",
            " inflated: BLtraining/5526.png\n",
            " inflated: BLtraining/5527.png\n",
            " inflated: BLtraining/5528.png\n",
            " inflated: BLtraining/5529.png\n",
            " inflated: BLtraining/553.png\n",
            " inflated: BLtraining/5530.png\n",
            " inflated: BLtraining/5531.png\n",
            " inflated: BLtraining/5532.png\n",
            " inflated: BLtraining/5533.png\n",
            " inflated: BLtraining/5534.png\n",
            " inflated: BLtraining/5535.png\n",
            " inflated: BLtraining/5536.png\n",
            " inflated: BLtraining/5537.png\n",
            " inflated: BLtraining/5538.png\n",
            " inflated: BLtraining/5539.png\n",
            " inflated: BLtraining/554.png\n",
            " inflated: BLtraining/5540.png\n",
            " inflated: BLtraining/5541.png\n",
            " inflated: BLtraining/5542.png\n",
            " inflated: BLtraining/5543.png\n",
            " inflated: BLtraining/5544.png\n",
            " inflated: BLtraining/5545.png\n",
            " inflated: BLtraining/5546.png\n",
            " inflated: BLtraining/5547.png\n",
            " inflated: BLtraining/5548.png\n",
            " inflated: BLtraining/5549.png\n",
            " inflated: BLtraining/555.png\n",
            " inflated: BLtraining/5550.png\n",
            " inflated: BLtraining/5551.png\n",
            " inflated: BLtraining/5552.png\n",
            " inflated: BLtraining/5553.png\n",
            " inflated: BLtraining/5554.png\n",
            " inflated: BLtraining/5555.png\n",
            " inflated: BLtraining/5556.png\n",
            " inflated: BLtraining/5557.png\n",
            " inflated: BLtraining/5558.png\n",
            " inflated: BLtraining/5559.png\n",
            " inflated: BLtraining/556.png\n",
            " inflated: BLtraining/5560.png\n",
            " inflated: BLtraining/5561.png\n",
            " inflated: BLtraining/5562.png\n",
            " inflated: BLtraining/5563.png\n",
            " inflated: BLtraining/5564.png\n",
            " inflated: BLtraining/5565.png\n",
            " inflated: BLtraining/5566.png\n",
            " inflated: BLtraining/5567.png\n",
            " inflated: BLtraining/5568.png\n",
            " inflated: BLtraining/5569.png\n",
            " inflated: BLtraining/557.png\n",
            " inflated: BLtraining/5570.png\n",
            " inflated: BLtraining/5571.png\n",
            " inflated: BLtraining/5572.png\n",
            " inflated: BLtraining/5573.png\n",
            " inflated: BLtraining/5574.png\n",
            " inflated: BLtraining/5575.png\n",
            " inflated: BLtraining/5576.png\n",
            " inflated: BLtraining/5577.png\n",
            " inflated: BLtraining/5578.png\n",
            " inflated: BLtraining/5579.png\n",
            " inflated: BLtraining/558.png\n",
            " inflated: BLtraining/5580.png\n",
            " inflated: BLtraining/5581.png\n",
            " inflated: BLtraining/5582.png\n",
            " inflated: BLtraining/5583.png\n",
            " inflated: BLtraining/5584.png\n",
            " inflated: BLtraining/5585.png\n",
            " inflated: BLtraining/5586.png\n",
            " inflated: BLtraining/5587.png\n",
            " inflated: BLtraining/5588.png\n",
            " inflated: BLtraining/5589.png\n",
            " inflated: BLtraining/559.png\n",
            " inflated: BLtraining/5590.png\n",
            " inflated: BLtraining/5591.png\n",
            " inflated: BLtraining/5592.png\n",
            " inflated: BLtraining/5593.png\n",
            " inflated: BLtraining/5594.png\n",
            " inflated: BLtraining/5595.png\n",
            " inflated: BLtraining/5596.png\n",
            " inflated: BLtraining/5597.png\n",
            " inflated: BLtraining/5598.png\n",
            " inflated: BLtraining/5599.png\n",
            " inflated: BLtraining/56.png\n",
            " inflated: BLtraining/560.png\n",
            " inflated: BLtraining/5600.png\n",
            " inflated: BLtraining/5601.png\n",
            " inflated: BLtraining/5602.png\n",
            " inflated: BLtraining/5603.png\n",
            " inflated: BLtraining/5604.png\n",
            " inflated: BLtraining/5605.png\n",
            " inflated: BLtraining/5606.png\n",
            " inflated: BLtraining/5607.png\n",
            " inflated: BLtraining/5608.png\n",
            " inflated: BLtraining/5609.png\n",
            " inflated: BLtraining/561.png\n",
            " inflated: BLtraining/5610.png\n",
            " inflated: BLtraining/5611.png\n",
            " inflated: BLtraining/5612.png\n",
            " inflated: BLtraining/5613.png\n",
            " inflated: BLtraining/5614.png\n",
            " inflated: BLtraining/5615.png\n",
            " inflated: BLtraining/5616.png\n",
            " inflated: BLtraining/5617.png\n",
            " inflated: BLtraining/5618.png\n",
            " inflated: BLtraining/5619.png\n",
            " inflated: BLtraining/562.png\n",
            " inflated: BLtraining/5620.png\n",
            " inflated: BLtraining/5621.png\n",
            " inflated: BLtraining/5622.png\n",
            " inflated: BLtraining/5623.png\n",
            " inflated: BLtraining/5624.png\n",
            " inflated: BLtraining/5625.png\n",
            " inflated: BLtraining/5626.png\n",
            " inflated: BLtraining/5627.png\n",
            " inflated: BLtraining/5628.png\n",
            " inflated: BLtraining/5629.png\n",
            " inflated: BLtraining/563.png\n",
            " inflated: BLtraining/5630.png\n",
            " inflated: BLtraining/5631.png\n",
            " inflated: BLtraining/5632.png\n",
            " inflated: BLtraining/5633.png\n",
            " inflated: BLtraining/5634.png\n",
            " inflated: BLtraining/5635.png\n",
            " inflated: BLtraining/5636.png\n",
            " inflated: BLtraining/5637.png\n",
            " inflated: BLtraining/5638.png\n",
            " inflated: BLtraining/5639.png\n",
            " inflated: BLtraining/564.png\n",
            " inflated: BLtraining/5640.png\n",
            " inflated: BLtraining/5641.png\n",
            " inflated: BLtraining/5642.png\n",
            " inflated: BLtraining/5643.png\n",
            " inflated: BLtraining/5644.png\n",
            " inflated: BLtraining/5645.png\n",
            " inflated: BLtraining/5646.png\n",
            " inflated: BLtraining/5647.png\n",
            " inflated: BLtraining/5648.png\n",
            " inflated: BLtraining/5649.png\n",
            " inflated: BLtraining/565.png\n",
            " inflated: BLtraining/5650.png\n",
            " inflated: BLtraining/5651.png\n",
            " inflated: BLtraining/5652.png\n",
            " inflated: BLtraining/5653.png\n",
            " inflated: BLtraining/5654.png\n",
            " inflated: BLtraining/5655.png\n",
            " inflated: BLtraining/5656.png\n",
            " inflated: BLtraining/5657.png\n",
            " inflated: BLtraining/5658.png\n",
            " inflated: BLtraining/5659.png\n",
            " inflated: BLtraining/566.png\n",
            " inflated: BLtraining/5660.png\n",
            " inflated: BLtraining/5661.png\n",
            " inflated: BLtraining/5662.png\n",
            " inflated: BLtraining/5663.png\n",
            " inflated: BLtraining/5664.png\n",
            " inflated: BLtraining/5665.png\n",
            " inflated: BLtraining/5666.png\n",
            " inflated: BLtraining/5667.png\n",
            " inflated: BLtraining/5668.png\n",
            " inflated: BLtraining/5669.png\n",
            " inflated: BLtraining/567.png\n",
            " inflated: BLtraining/5670.png\n",
            " inflated: BLtraining/5671.png\n",
            " inflated: BLtraining/5672.png\n",
            " inflated: BLtraining/5673.png\n",
            " inflated: BLtraining/5674.png\n",
            " inflated: BLtraining/5675.png\n",
            " inflated: BLtraining/5676.png\n",
            " inflated: BLtraining/5677.png\n",
            " inflated: BLtraining/5678.png\n",
            " inflated: BLtraining/5679.png\n",
            " inflated: BLtraining/568.png\n",
            " inflated: BLtraining/5680.png\n",
            " inflated: BLtraining/5681.png\n",
            " inflated: BLtraining/5682.png\n",
            " inflated: BLtraining/5683.png\n",
            " inflated: BLtraining/5684.png\n",
            " inflated: BLtraining/5685.png\n",
            " inflated: BLtraining/5686.png\n",
            " inflated: BLtraining/5687.png\n",
            " inflated: BLtraining/5688.png\n",
            " inflated: BLtraining/5689.png\n",
            " inflated: BLtraining/569.png\n",
            " inflated: BLtraining/5690.png\n",
            " inflated: BLtraining/5691.png\n",
            " inflated: BLtraining/5692.png\n",
            " inflated: BLtraining/5693.png\n",
            " inflated: BLtraining/5694.png\n",
            " inflated: BLtraining/5695.png\n",
            " inflated: BLtraining/5696.png\n",
            " inflated: BLtraining/5697.png\n",
            " inflated: BLtraining/5698.png\n",
            " inflated: BLtraining/5699.png\n",
            " inflated: BLtraining/57.png\n",
            " inflated: BLtraining/570.png\n",
            " inflated: BLtraining/5700.png\n",
            " inflated: BLtraining/5701.png\n",
            " inflated: BLtraining/5702.png\n",
            " inflated: BLtraining/5703.png\n",
            " inflated: BLtraining/5704.png\n",
            " inflated: BLtraining/5705.png\n",
            " inflated: BLtraining/5706.png\n",
            " inflated: BLtraining/5707.png\n",
            " inflated: BLtraining/5708.png\n",
            " inflated: BLtraining/5709.png\n",
            " inflated: BLtraining/571.png\n",
            " inflated: BLtraining/5710.png\n",
            " inflated: BLtraining/5711.png\n",
            " inflated: BLtraining/5712.png\n",
            " inflated: BLtraining/5713.png\n",
            " inflated: BLtraining/5714.png\n",
            " inflated: BLtraining/5715.png\n",
            " inflated: BLtraining/5716.png\n",
            " inflated: BLtraining/5717.png\n",
            " inflated: BLtraining/5718.png\n",
            " inflated: BLtraining/5719.png\n",
            " inflated: BLtraining/572.png\n",
            " inflated: BLtraining/5720.png\n",
            " inflated: BLtraining/5721.png\n",
            " inflated: BLtraining/5722.png\n",
            " inflated: BLtraining/5723.png\n",
            " inflated: BLtraining/5724.png\n",
            " inflated: BLtraining/5725.png\n",
            " inflated: BLtraining/5726.png\n",
            " inflated: BLtraining/5727.png\n",
            " inflated: BLtraining/5728.png\n",
            " inflated: BLtraining/5729.png\n",
            " inflated: BLtraining/573.png\n",
            " inflated: BLtraining/5730.png\n",
            " inflated: BLtraining/5731.png\n",
            " inflated: BLtraining/5732.png\n",
            " inflated: BLtraining/5733.png\n",
            " inflated: BLtraining/5734.png\n",
            " inflated: BLtraining/5735.png\n",
            " inflated: BLtraining/5736.png\n",
            " inflated: BLtraining/5737.png\n",
            " inflated: BLtraining/5738.png\n",
            " inflated: BLtraining/5739.png\n",
            " inflated: BLtraining/574.png\n",
            " inflated: BLtraining/5740.png\n",
            " inflated: BLtraining/5741.png\n",
            " inflated: BLtraining/5742.png\n",
            " inflated: BLtraining/5743.png\n",
            " inflated: BLtraining/5744.png\n",
            " inflated: BLtraining/5745.png\n",
            " inflated: BLtraining/5746.png\n",
            " inflated: BLtraining/5747.png\n",
            " inflated: BLtraining/5748.png\n",
            " inflated: BLtraining/5749.png\n",
            " inflated: BLtraining/575.png\n",
            " inflated: BLtraining/5750.png\n",
            " inflated: BLtraining/5751.png\n",
            " inflated: BLtraining/5752.png\n",
            " inflated: BLtraining/5753.png\n",
            " inflated: BLtraining/5754.png\n",
            " inflated: BLtraining/5755.png\n",
            " inflated: BLtraining/5756.png\n",
            " inflated: BLtraining/5757.png\n",
            " inflated: BLtraining/5758.png\n",
            " inflated: BLtraining/5759.png\n",
            " inflated: BLtraining/576.png\n",
            " inflated: BLtraining/5760.png\n",
            " inflated: BLtraining/5761.png\n",
            " inflated: BLtraining/5762.png\n",
            " inflated: BLtraining/5763.png\n",
            " inflated: BLtraining/5764.png\n",
            " inflated: BLtraining/5765.png\n",
            " inflated: BLtraining/5766.png\n",
            " inflated: BLtraining/5767.png\n",
            " inflated: BLtraining/5768.png\n",
            " inflated: BLtraining/5769.png\n",
            " inflated: BLtraining/577.png\n",
            " inflated: BLtraining/5770.png\n",
            " inflated: BLtraining/5771.png\n",
            " inflated: BLtraining/5772.png\n",
            " inflated: BLtraining/5773.png\n",
            " inflated: BLtraining/5774.png\n",
            " inflated: BLtraining/5775.png\n",
            " inflated: BLtraining/5776.png\n",
            " inflated: BLtraining/5777.png\n",
            " inflated: BLtraining/5778.png\n",
            " inflated: BLtraining/5779.png\n",
            " inflated: BLtraining/578.png\n",
            " inflated: BLtraining/5780.png\n",
            " inflated: BLtraining/5781.png\n",
            " inflated: BLtraining/5782.png\n",
            " inflated: BLtraining/5783.png\n",
            " inflated: BLtraining/5784.png\n",
            " inflated: BLtraining/5785.png\n",
            " inflated: BLtraining/5786.png\n",
            " inflated: BLtraining/5787.png\n",
            " inflated: BLtraining/5788.png\n",
            " inflated: BLtraining/5789.png\n",
            " inflated: BLtraining/579.png\n",
            " inflated: BLtraining/5790.png\n",
            " inflated: BLtraining/5791.png\n",
            " inflated: BLtraining/5792.png\n",
            " inflated: BLtraining/5793.png\n",
            " inflated: BLtraining/5794.png\n",
            " inflated: BLtraining/5795.png\n",
            " inflated: BLtraining/5796.png\n",
            " inflated: BLtraining/5797.png\n",
            " inflated: BLtraining/5798.png\n",
            " inflated: BLtraining/5799.png\n",
            " inflated: BLtraining/58.png\n",
            " inflated: BLtraining/580.png\n",
            " inflated: BLtraining/5800.png\n",
            " inflated: BLtraining/5801.png\n",
            " inflated: BLtraining/5802.png\n",
            " inflated: BLtraining/5803.png\n",
            " inflated: BLtraining/5804.png\n",
            " inflated: BLtraining/5805.png\n",
            " inflated: BLtraining/5806.png\n",
            " inflated: BLtraining/5807.png\n",
            " inflated: BLtraining/5808.png\n",
            " inflated: BLtraining/5809.png\n",
            " inflated: BLtraining/581.png\n",
            " inflated: BLtraining/5810.png\n",
            " inflated: BLtraining/5811.png\n",
            " inflated: BLtraining/5812.png\n",
            " inflated: BLtraining/5813.png\n",
            " inflated: BLtraining/5814.png\n",
            " inflated: BLtraining/5815.png\n",
            " inflated: BLtraining/5816.png\n",
            " inflated: BLtraining/5817.png\n",
            " inflated: BLtraining/5818.png\n",
            " inflated: BLtraining/5819.png\n",
            " inflated: BLtraining/582.png\n",
            " inflated: BLtraining/5820.png\n",
            " inflated: BLtraining/5821.png\n",
            " inflated: BLtraining/5822.png\n",
            " inflated: BLtraining/5823.png\n",
            " inflated: BLtraining/5824.png\n",
            " inflated: BLtraining/5825.png\n",
            " inflated: BLtraining/5826.png\n",
            " inflated: BLtraining/5827.png\n",
            " inflated: BLtraining/5828.png\n",
            " inflated: BLtraining/5829.png\n",
            " inflated: BLtraining/583.png\n",
            " inflated: BLtraining/5830.png\n",
            " inflated: BLtraining/5831.png\n",
            " inflated: BLtraining/5832.png\n",
            " inflated: BLtraining/5833.png\n",
            " inflated: BLtraining/5834.png\n",
            " inflated: BLtraining/5835.png\n",
            " inflated: BLtraining/5836.png\n",
            " inflated: BLtraining/5837.png\n",
            " inflated: BLtraining/5838.png\n",
            " inflated: BLtraining/5839.png\n",
            " inflated: BLtraining/584.png\n",
            " inflated: BLtraining/5840.png\n",
            " inflated: BLtraining/5841.png\n",
            " inflated: BLtraining/5842.png\n",
            " inflated: BLtraining/5843.png\n",
            " inflated: BLtraining/5844.png\n",
            " inflated: BLtraining/5845.png\n",
            " inflated: BLtraining/5846.png\n",
            " inflated: BLtraining/5847.png\n",
            " inflated: BLtraining/5848.png\n",
            " inflated: BLtraining/5849.png\n",
            " inflated: BLtraining/585.png\n",
            " inflated: BLtraining/5850.png\n",
            " inflated: BLtraining/5851.png\n",
            " inflated: BLtraining/5852.png\n",
            " inflated: BLtraining/5853.png\n",
            " inflated: BLtraining/5854.png\n",
            " inflated: BLtraining/5855.png\n",
            " inflated: BLtraining/5856.png\n",
            " inflated: BLtraining/5857.png\n",
            " inflated: BLtraining/5858.png\n",
            " inflated: BLtraining/5859.png\n",
            " inflated: BLtraining/586.png\n",
            " inflated: BLtraining/5860.png\n",
            " inflated: BLtraining/5861.png\n",
            " inflated: BLtraining/5862.png\n",
            " inflated: BLtraining/5863.png\n",
            " inflated: BLtraining/5864.png\n",
            " inflated: BLtraining/5865.png\n",
            " inflated: BLtraining/5866.png\n",
            " inflated: BLtraining/5867.png\n",
            " inflated: BLtraining/5868.png\n",
            " inflated: BLtraining/5869.png\n",
            " inflated: BLtraining/587.png\n",
            " inflated: BLtraining/5870.png\n",
            " inflated: BLtraining/5871.png\n",
            " inflated: BLtraining/5872.png\n",
            " inflated: BLtraining/5873.png\n",
            " inflated: BLtraining/5874.png\n",
            " inflated: BLtraining/5875.png\n",
            " inflated: BLtraining/5876.png\n",
            " inflated: BLtraining/5877.png\n",
            " inflated: BLtraining/5878.png\n",
            " inflated: BLtraining/5879.png\n",
            " inflated: BLtraining/588.png\n",
            " inflated: BLtraining/5880.png\n",
            " inflated: BLtraining/5881.png\n",
            " inflated: BLtraining/5882.png\n",
            " inflated: BLtraining/5883.png\n",
            " inflated: BLtraining/5884.png\n",
            " inflated: BLtraining/5885.png\n",
            " inflated: BLtraining/5886.png\n",
            " inflated: BLtraining/5887.png\n",
            " inflated: BLtraining/5888.png\n",
            " inflated: BLtraining/5889.png\n",
            " inflated: BLtraining/589.png\n",
            " inflated: BLtraining/5890.png\n",
            " inflated: BLtraining/5891.png\n",
            " inflated: BLtraining/5892.png\n",
            " inflated: BLtraining/5893.png\n",
            " inflated: BLtraining/5894.png\n",
            " inflated: BLtraining/5895.png\n",
            " inflated: BLtraining/5896.png\n",
            " inflated: BLtraining/5897.png\n",
            " inflated: BLtraining/5898.png\n",
            " inflated: BLtraining/5899.png\n",
            " inflated: BLtraining/59.png\n",
            " inflated: BLtraining/590.png\n",
            " inflated: BLtraining/5900.png\n",
            " inflated: BLtraining/5901.png\n",
            " inflated: BLtraining/5902.png\n",
            " inflated: BLtraining/5903.png\n",
            " inflated: BLtraining/5904.png\n",
            " inflated: BLtraining/5905.png\n",
            " inflated: BLtraining/5906.png\n",
            " inflated: BLtraining/5907.png\n",
            " inflated: BLtraining/5908.png\n",
            " inflated: BLtraining/5909.png\n",
            " inflated: BLtraining/591.png\n",
            " inflated: BLtraining/5910.png\n",
            " inflated: BLtraining/5911.png\n",
            " inflated: BLtraining/5912.png\n",
            " inflated: BLtraining/5913.png\n",
            " inflated: BLtraining/5914.png\n",
            " inflated: BLtraining/5915.png\n",
            " inflated: BLtraining/5916.png\n",
            " inflated: BLtraining/5917.png\n",
            " inflated: BLtraining/5918.png\n",
            " inflated: BLtraining/5919.png\n",
            " inflated: BLtraining/592.png\n",
            " inflated: BLtraining/5920.png\n",
            " inflated: BLtraining/5921.png\n",
            " inflated: BLtraining/5922.png\n",
            " inflated: BLtraining/5923.png\n",
            " inflated: BLtraining/5924.png\n",
            " inflated: BLtraining/5925.png\n",
            " inflated: BLtraining/5926.png\n",
            " inflated: BLtraining/5927.png\n",
            " inflated: BLtraining/5928.png\n",
            " inflated: BLtraining/5929.png\n",
            " inflated: BLtraining/593.png\n",
            " inflated: BLtraining/5930.png\n",
            " inflated: BLtraining/5931.png\n",
            " inflated: BLtraining/5932.png\n",
            " inflated: BLtraining/5933.png\n",
            " inflated: BLtraining/5934.png\n",
            " inflated: BLtraining/5935.png\n",
            " inflated: BLtraining/5936.png\n",
            " inflated: BLtraining/5937.png\n",
            " inflated: BLtraining/5938.png\n",
            " inflated: BLtraining/5939.png\n",
            " inflated: BLtraining/594.png\n",
            " inflated: BLtraining/5940.png\n",
            " inflated: BLtraining/5941.png\n",
            " inflated: BLtraining/5942.png\n",
            " inflated: BLtraining/5943.png\n",
            " inflated: BLtraining/5944.png\n",
            " inflated: BLtraining/5945.png\n",
            " inflated: BLtraining/5946.png\n",
            " inflated: BLtraining/5947.png\n",
            " inflated: BLtraining/5948.png\n",
            " inflated: BLtraining/5949.png\n",
            " inflated: BLtraining/595.png\n",
            " inflated: BLtraining/5950.png\n",
            " inflated: BLtraining/5951.png\n",
            " inflated: BLtraining/5952.png\n",
            " inflated: BLtraining/5953.png\n",
            " inflated: BLtraining/5954.png\n",
            " inflated: BLtraining/5955.png\n",
            " inflated: BLtraining/5956.png\n",
            " inflated: BLtraining/5957.png\n",
            " inflated: BLtraining/5958.png\n",
            " inflated: BLtraining/5959.png\n",
            " inflated: BLtraining/596.png\n",
            " inflated: BLtraining/5960.png\n",
            " inflated: BLtraining/5961.png\n",
            " inflated: BLtraining/5962.png\n",
            " inflated: BLtraining/5963.png\n",
            " inflated: BLtraining/5964.png\n",
            " inflated: BLtraining/5965.png\n",
            " inflated: BLtraining/5966.png\n",
            " inflated: BLtraining/5967.png\n",
            " inflated: BLtraining/5968.png\n",
            " inflated: BLtraining/5969.png\n",
            " inflated: BLtraining/597.png\n",
            " inflated: BLtraining/5970.png\n",
            " inflated: BLtraining/5971.png\n",
            " inflated: BLtraining/5972.png\n",
            " inflated: BLtraining/5973.png\n",
            " inflated: BLtraining/5974.png\n",
            " inflated: BLtraining/5975.png\n",
            " inflated: BLtraining/5976.png\n",
            " inflated: BLtraining/5977.png\n",
            " inflated: BLtraining/5978.png\n",
            " inflated: BLtraining/5979.png\n",
            " inflated: BLtraining/598.png\n",
            " inflated: BLtraining/5980.png\n",
            " inflated: BLtraining/5981.png\n",
            " inflated: BLtraining/5982.png\n",
            " inflated: BLtraining/5983.png\n",
            " inflated: BLtraining/5984.png\n",
            " inflated: BLtraining/5985.png\n",
            " inflated: BLtraining/5986.png\n",
            " inflated: BLtraining/5987.png\n",
            " inflated: BLtraining/5988.png\n",
            " inflated: BLtraining/5989.png\n",
            " inflated: BLtraining/599.png\n",
            " inflated: BLtraining/5990.png\n",
            " inflated: BLtraining/5991.png\n",
            " inflated: BLtraining/5992.png\n",
            " inflated: BLtraining/5993.png\n",
            " inflated: BLtraining/5994.png\n",
            " inflated: BLtraining/5995.png\n",
            " inflated: BLtraining/5996.png\n",
            " inflated: BLtraining/5997.png\n",
            " inflated: BLtraining/5998.png\n",
            " inflated: BLtraining/5999.png\n",
            " inflated: BLtraining/6.png\n",
            " inflated: BLtraining/60.png\n",
            " inflated: BLtraining/600.png\n",
            " inflated: BLtraining/6000.png\n",
            " inflated: BLtraining/6001.png\n",
            " inflated: BLtraining/6002.png\n",
            " inflated: BLtraining/6003.png\n",
            " inflated: BLtraining/6004.png\n",
            " inflated: BLtraining/6005.png\n",
            " inflated: BLtraining/6006.png\n",
            " inflated: BLtraining/6007.png\n",
            " inflated: BLtraining/6008.png\n",
            " inflated: BLtraining/6009.png\n",
            " inflated: BLtraining/601.png\n",
            " inflated: BLtraining/6010.png\n",
            " inflated: BLtraining/6011.png\n",
            " inflated: BLtraining/6012.png\n",
            " inflated: BLtraining/6013.png\n",
            " inflated: BLtraining/6014.png\n",
            " inflated: BLtraining/6015.png\n",
            " inflated: BLtraining/6016.png\n",
            " inflated: BLtraining/6017.png\n",
            " inflated: BLtraining/6018.png\n",
            " inflated: BLtraining/6019.png\n",
            " inflated: BLtraining/602.png\n",
            " inflated: BLtraining/6020.png\n",
            " inflated: BLtraining/6021.png\n",
            " inflated: BLtraining/6022.png\n",
            " inflated: BLtraining/6023.png\n",
            " inflated: BLtraining/6024.png\n",
            " inflated: BLtraining/6025.png\n",
            " inflated: BLtraining/6026.png\n",
            " inflated: BLtraining/6027.png\n",
            " inflated: BLtraining/6028.png\n",
            " inflated: BLtraining/6029.png\n",
            " inflated: BLtraining/603.png\n",
            " inflated: BLtraining/6030.png\n",
            " inflated: BLtraining/6031.png\n",
            " inflated: BLtraining/6032.png\n",
            " inflated: BLtraining/6033.png\n",
            " inflated: BLtraining/6034.png\n",
            " inflated: BLtraining/6035.png\n",
            " inflated: BLtraining/6036.png\n",
            " inflated: BLtraining/6037.png\n",
            " inflated: BLtraining/6038.png\n",
            " inflated: BLtraining/6039.png\n",
            " inflated: BLtraining/604.png\n",
            " inflated: BLtraining/6040.png\n",
            " inflated: BLtraining/6041.png\n",
            " inflated: BLtraining/6042.png\n",
            " inflated: BLtraining/6043.png\n",
            " inflated: BLtraining/6044.png\n",
            " inflated: BLtraining/6045.png\n",
            " inflated: BLtraining/6046.png\n",
            " inflated: BLtraining/6047.png\n",
            " inflated: BLtraining/6048.png\n",
            " inflated: BLtraining/6049.png\n",
            " inflated: BLtraining/605.png\n",
            " inflated: BLtraining/6050.png\n",
            " inflated: BLtraining/6051.png\n",
            " inflated: BLtraining/6052.png\n",
            " inflated: BLtraining/6053.png\n",
            " inflated: BLtraining/6054.png\n",
            " inflated: BLtraining/6055.png\n",
            " inflated: BLtraining/6056.png\n",
            " inflated: BLtraining/6057.png\n",
            " inflated: BLtraining/6058.png\n",
            " inflated: BLtraining/6059.png\n",
            " inflated: BLtraining/606.png\n",
            " inflated: BLtraining/6060.png\n",
            " inflated: BLtraining/6061.png\n",
            " inflated: BLtraining/6062.png\n",
            " inflated: BLtraining/6063.png\n",
            " inflated: BLtraining/6064.png\n",
            " inflated: BLtraining/6065.png\n",
            " inflated: BLtraining/6066.png\n",
            " inflated: BLtraining/6067.png\n",
            " inflated: BLtraining/6068.png\n",
            " inflated: BLtraining/6069.png\n",
            " inflated: BLtraining/607.png\n",
            " inflated: BLtraining/6070.png\n",
            " inflated: BLtraining/6071.png\n",
            " inflated: BLtraining/6072.png\n",
            " inflated: BLtraining/6073.png\n",
            " inflated: BLtraining/6074.png\n",
            " inflated: BLtraining/6075.png\n",
            " inflated: BLtraining/6076.png\n",
            " inflated: BLtraining/6077.png\n",
            " inflated: BLtraining/6078.png\n",
            " inflated: BLtraining/6079.png\n",
            " inflated: BLtraining/608.png\n",
            " inflated: BLtraining/6080.png\n",
            " inflated: BLtraining/6081.png\n",
            " inflated: BLtraining/6082.png\n",
            " inflated: BLtraining/6083.png\n",
            " inflated: BLtraining/6084.png\n",
            " inflated: BLtraining/6085.png\n",
            " inflated: BLtraining/6086.png\n",
            " inflated: BLtraining/6087.png\n",
            " inflated: BLtraining/6088.png\n",
            " inflated: BLtraining/6089.png\n",
            " inflated: BLtraining/609.png\n",
            " inflated: BLtraining/6090.png\n",
            " inflated: BLtraining/6091.png\n",
            " inflated: BLtraining/6092.png\n",
            " inflated: BLtraining/6093.png\n",
            " inflated: BLtraining/6094.png\n",
            " inflated: BLtraining/6095.png\n",
            " inflated: BLtraining/6096.png\n",
            " inflated: BLtraining/6097.png\n",
            " inflated: BLtraining/6098.png\n",
            " inflated: BLtraining/6099.png\n",
            " inflated: BLtraining/61.png\n",
            " inflated: BLtraining/610.png\n",
            " inflated: BLtraining/6100.png\n",
            " inflated: BLtraining/6101.png\n",
            " inflated: BLtraining/6102.png\n",
            " inflated: BLtraining/6103.png\n",
            " inflated: BLtraining/6104.png\n",
            " inflated: BLtraining/6105.png\n",
            " inflated: BLtraining/6106.png\n",
            " inflated: BLtraining/6107.png\n",
            " inflated: BLtraining/6108.png\n",
            " inflated: BLtraining/6109.png\n",
            " inflated: BLtraining/611.png\n",
            " inflated: BLtraining/6110.png\n",
            " inflated: BLtraining/6111.png\n",
            " inflated: BLtraining/6112.png\n",
            " inflated: BLtraining/6113.png\n",
            " inflated: BLtraining/6114.png\n",
            " inflated: BLtraining/6115.png\n",
            " inflated: BLtraining/6116.png\n",
            " inflated: BLtraining/6117.png\n",
            " inflated: BLtraining/6118.png\n",
            " inflated: BLtraining/6119.png\n",
            " inflated: BLtraining/612.png\n",
            " inflated: BLtraining/6120.png\n",
            " inflated: BLtraining/6121.png\n",
            " inflated: BLtraining/6122.png\n",
            " inflated: BLtraining/6123.png\n",
            " inflated: BLtraining/6124.png\n",
            " inflated: BLtraining/6125.png\n",
            " inflated: BLtraining/6126.png\n",
            " inflated: BLtraining/6127.png\n",
            " inflated: BLtraining/6128.png\n",
            " inflated: BLtraining/6129.png\n",
            " inflated: BLtraining/613.png\n",
            " inflated: BLtraining/6130.png\n",
            " inflated: BLtraining/6131.png\n",
            " inflated: BLtraining/6132.png\n",
            " inflated: BLtraining/6133.png\n",
            " inflated: BLtraining/6134.png\n",
            " inflated: BLtraining/6135.png\n",
            " inflated: BLtraining/6136.png\n",
            " inflated: BLtraining/6137.png\n",
            " inflated: BLtraining/6138.png\n",
            " inflated: BLtraining/6139.png\n",
            " inflated: BLtraining/614.png\n",
            " inflated: BLtraining/6140.png\n",
            " inflated: BLtraining/6141.png\n",
            " inflated: BLtraining/6142.png\n",
            " inflated: BLtraining/6143.png\n",
            " inflated: BLtraining/6144.png\n",
            " inflated: BLtraining/6145.png\n",
            " inflated: BLtraining/6146.png\n",
            " inflated: BLtraining/6147.png\n",
            " inflated: BLtraining/6148.png\n",
            " inflated: BLtraining/6149.png\n",
            " inflated: BLtraining/615.png\n",
            " inflated: BLtraining/6150.png\n",
            " inflated: BLtraining/6151.png\n",
            " inflated: BLtraining/6152.png\n",
            " inflated: BLtraining/6153.png\n",
            " inflated: BLtraining/6154.png\n",
            " inflated: BLtraining/6155.png\n",
            " inflated: BLtraining/6156.png\n",
            " inflated: BLtraining/6157.png\n",
            " inflated: BLtraining/6158.png\n",
            " inflated: BLtraining/6159.png\n",
            " inflated: BLtraining/616.png\n",
            " inflated: BLtraining/6160.png\n",
            " inflated: BLtraining/6161.png\n",
            " inflated: BLtraining/6162.png\n",
            " inflated: BLtraining/6163.png\n",
            " inflated: BLtraining/6164.png\n",
            " inflated: BLtraining/6165.png\n",
            " inflated: BLtraining/6166.png\n",
            " inflated: BLtraining/6167.png\n",
            " inflated: BLtraining/6168.png\n",
            " inflated: BLtraining/6169.png\n",
            " inflated: BLtraining/617.png\n",
            " inflated: BLtraining/6170.png\n",
            " inflated: BLtraining/6171.png\n",
            " inflated: BLtraining/6172.png\n",
            " inflated: BLtraining/6173.png\n",
            " inflated: BLtraining/6174.png\n",
            " inflated: BLtraining/6175.png\n",
            " inflated: BLtraining/6176.png\n",
            " inflated: BLtraining/6177.png\n",
            " inflated: BLtraining/6178.png\n",
            " inflated: BLtraining/6179.png\n",
            " inflated: BLtraining/618.png\n",
            " inflated: BLtraining/6180.png\n",
            " inflated: BLtraining/6181.png\n",
            " inflated: BLtraining/6182.png\n",
            " inflated: BLtraining/6183.png\n",
            " inflated: BLtraining/6184.png\n",
            " inflated: BLtraining/6185.png\n",
            " inflated: BLtraining/6186.png\n",
            " inflated: BLtraining/6187.png\n",
            " inflated: BLtraining/6188.png\n",
            " inflated: BLtraining/6189.png\n",
            " inflated: BLtraining/619.png\n",
            " inflated: BLtraining/6190.png\n",
            " inflated: BLtraining/6191.png\n",
            " inflated: BLtraining/6192.png\n",
            " inflated: BLtraining/6193.png\n",
            " inflated: BLtraining/6194.png\n",
            " inflated: BLtraining/6195.png\n",
            " inflated: BLtraining/6196.png\n",
            " inflated: BLtraining/6197.png\n",
            " inflated: BLtraining/6198.png\n",
            " inflated: BLtraining/6199.png\n",
            " inflated: BLtraining/62.png\n",
            " inflated: BLtraining/620.png\n",
            " inflated: BLtraining/6200.png\n",
            " inflated: BLtraining/6201.png\n",
            " inflated: BLtraining/6202.png\n",
            " inflated: BLtraining/6203.png\n",
            " inflated: BLtraining/6204.png\n",
            " inflated: BLtraining/6205.png\n",
            " inflated: BLtraining/6206.png\n",
            " inflated: BLtraining/6207.png\n",
            " inflated: BLtraining/6208.png\n",
            " inflated: BLtraining/6209.png\n",
            " inflated: BLtraining/621.png\n",
            " inflated: BLtraining/6210.png\n",
            " inflated: BLtraining/6211.png\n",
            " inflated: BLtraining/6212.png\n",
            " inflated: BLtraining/6213.png\n",
            " inflated: BLtraining/6214.png\n",
            " inflated: BLtraining/6215.png\n",
            " inflated: BLtraining/6216.png\n",
            " inflated: BLtraining/6217.png\n",
            " inflated: BLtraining/6218.png\n",
            " inflated: BLtraining/6219.png\n",
            " inflated: BLtraining/622.png\n",
            " inflated: BLtraining/6220.png\n",
            " inflated: BLtraining/6221.png\n",
            " inflated: BLtraining/6222.png\n",
            " inflated: BLtraining/6223.png\n",
            " inflated: BLtraining/6224.png\n",
            " inflated: BLtraining/6225.png\n",
            " inflated: BLtraining/6226.png\n",
            " inflated: BLtraining/6227.png\n",
            " inflated: BLtraining/6228.png\n",
            " inflated: BLtraining/6229.png\n",
            " inflated: BLtraining/623.png\n",
            " inflated: BLtraining/6230.png\n",
            " inflated: BLtraining/6231.png\n",
            " inflated: BLtraining/6232.png\n",
            " inflated: BLtraining/6233.png\n",
            " inflated: BLtraining/6234.png\n",
            " inflated: BLtraining/6235.png\n",
            " inflated: BLtraining/6236.png\n",
            " inflated: BLtraining/6237.png\n",
            " inflated: BLtraining/6238.png\n",
            " inflated: BLtraining/6239.png\n",
            " inflated: BLtraining/624.png\n",
            " inflated: BLtraining/6240.png\n",
            " inflated: BLtraining/6241.png\n",
            " inflated: BLtraining/6242.png\n",
            " inflated: BLtraining/6243.png\n",
            " inflated: BLtraining/6244.png\n",
            " inflated: BLtraining/6245.png\n",
            " inflated: BLtraining/6246.png\n",
            " inflated: BLtraining/6247.png\n",
            " inflated: BLtraining/6248.png\n",
            " inflated: BLtraining/6249.png\n",
            " inflated: BLtraining/625.png\n",
            " inflated: BLtraining/6250.png\n",
            " inflated: BLtraining/6251.png\n",
            " inflated: BLtraining/6252.png\n",
            " inflated: BLtraining/6253.png\n",
            " inflated: BLtraining/6254.png\n",
            " inflated: BLtraining/6255.png\n",
            " inflated: BLtraining/6256.png\n",
            " inflated: BLtraining/6257.png\n",
            " inflated: BLtraining/6258.png\n",
            " inflated: BLtraining/6259.png\n",
            " inflated: BLtraining/626.png\n",
            " inflated: BLtraining/6260.png\n",
            " inflated: BLtraining/6261.png\n",
            " inflated: BLtraining/6262.png\n",
            " inflated: BLtraining/6263.png\n",
            " inflated: BLtraining/6264.png\n",
            " inflated: BLtraining/6265.png\n",
            " inflated: BLtraining/6266.png\n",
            " inflated: BLtraining/6267.png\n",
            " inflated: BLtraining/6268.png\n",
            " inflated: BLtraining/6269.png\n",
            " inflated: BLtraining/627.png\n",
            " inflated: BLtraining/6270.png\n",
            " inflated: BLtraining/6271.png\n",
            " inflated: BLtraining/6272.png\n",
            " inflated: BLtraining/6273.png\n",
            " inflated: BLtraining/6274.png\n",
            " inflated: BLtraining/6275.png\n",
            " inflated: BLtraining/6276.png\n",
            " inflated: BLtraining/6277.png\n",
            " inflated: BLtraining/6278.png\n",
            " inflated: BLtraining/6279.png\n",
            " inflated: BLtraining/628.png\n",
            " inflated: BLtraining/6280.png\n",
            " inflated: BLtraining/6281.png\n",
            " inflated: BLtraining/6282.png\n",
            " inflated: BLtraining/6283.png\n",
            " inflated: BLtraining/6284.png\n",
            " inflated: BLtraining/6285.png\n",
            " inflated: BLtraining/6286.png\n",
            " inflated: BLtraining/6287.png\n",
            " inflated: BLtraining/6288.png\n",
            " inflated: BLtraining/6289.png\n",
            " inflated: BLtraining/629.png\n",
            " inflated: BLtraining/6290.png\n",
            " inflated: BLtraining/6291.png\n",
            " inflated: BLtraining/6292.png\n",
            " inflated: BLtraining/6293.png\n",
            " inflated: BLtraining/6294.png\n",
            " inflated: BLtraining/6295.png\n",
            " inflated: BLtraining/6296.png\n",
            " inflated: BLtraining/6297.png\n",
            " inflated: BLtraining/6298.png\n",
            " inflated: BLtraining/6299.png\n",
            " inflated: BLtraining/63.png\n",
            " inflated: BLtraining/630.png\n",
            " inflated: BLtraining/6300.png\n",
            " inflated: BLtraining/6301.png\n",
            " inflated: BLtraining/6302.png\n",
            " inflated: BLtraining/6303.png\n",
            " inflated: BLtraining/6304.png\n",
            " inflated: BLtraining/6305.png\n",
            " inflated: BLtraining/6306.png\n",
            " inflated: BLtraining/6307.png\n",
            " inflated: BLtraining/6308.png\n",
            " inflated: BLtraining/6309.png\n",
            " inflated: BLtraining/631.png\n",
            " inflated: BLtraining/6310.png\n",
            " inflated: BLtraining/6311.png\n",
            " inflated: BLtraining/6312.png\n",
            " inflated: BLtraining/6313.png\n",
            " inflated: BLtraining/6314.png\n",
            " inflated: BLtraining/6315.png\n",
            " inflated: BLtraining/6316.png\n",
            " inflated: BLtraining/6317.png\n",
            " inflated: BLtraining/6318.png\n",
            " inflated: BLtraining/6319.png\n",
            " inflated: BLtraining/632.png\n",
            " inflated: BLtraining/6320.png\n",
            " inflated: BLtraining/6321.png\n",
            " inflated: BLtraining/6322.png\n",
            " inflated: BLtraining/6323.png\n",
            " inflated: BLtraining/6324.png\n",
            " inflated: BLtraining/6325.png\n",
            " inflated: BLtraining/6326.png\n",
            " inflated: BLtraining/6327.png\n",
            " inflated: BLtraining/6328.png\n",
            " inflated: BLtraining/6329.png\n",
            " inflated: BLtraining/633.png\n",
            " inflated: BLtraining/6330.png\n",
            " inflated: BLtraining/6331.png\n",
            " inflated: BLtraining/6332.png\n",
            " inflated: BLtraining/6333.png\n",
            " inflated: BLtraining/6334.png\n",
            " inflated: BLtraining/6335.png\n",
            " inflated: BLtraining/6336.png\n",
            " inflated: BLtraining/6337.png\n",
            " inflated: BLtraining/6338.png\n",
            " inflated: BLtraining/6339.png\n",
            " inflated: BLtraining/634.png\n",
            " inflated: BLtraining/6340.png\n",
            " inflated: BLtraining/6341.png\n",
            " inflated: BLtraining/6342.png\n",
            " inflated: BLtraining/6343.png\n",
            " inflated: BLtraining/6344.png\n",
            " inflated: BLtraining/6345.png\n",
            " inflated: BLtraining/6346.png\n",
            " inflated: BLtraining/6347.png\n",
            " inflated: BLtraining/6348.png\n",
            " inflated: BLtraining/6349.png\n",
            " inflated: BLtraining/635.png\n",
            " inflated: BLtraining/6350.png\n",
            " inflated: BLtraining/6351.png\n",
            " inflated: BLtraining/6352.png\n",
            " inflated: BLtraining/6353.png\n",
            " inflated: BLtraining/6354.png\n",
            " inflated: BLtraining/6355.png\n",
            " inflated: BLtraining/6356.png\n",
            " inflated: BLtraining/6357.png\n",
            " inflated: BLtraining/6358.png\n",
            " inflated: BLtraining/6359.png\n",
            " inflated: BLtraining/636.png\n",
            " inflated: BLtraining/6360.png\n",
            " inflated: BLtraining/6361.png\n",
            " inflated: BLtraining/6362.png\n",
            " inflated: BLtraining/6363.png\n",
            " inflated: BLtraining/6364.png\n",
            " inflated: BLtraining/6365.png\n",
            " inflated: BLtraining/6366.png\n",
            " inflated: BLtraining/6367.png\n",
            " inflated: BLtraining/6368.png\n",
            " inflated: BLtraining/6369.png\n",
            " inflated: BLtraining/637.png\n",
            " inflated: BLtraining/6370.png\n",
            " inflated: BLtraining/6371.png\n",
            " inflated: BLtraining/6372.png\n",
            " inflated: BLtraining/6373.png\n",
            " inflated: BLtraining/6374.png\n",
            " inflated: BLtraining/6375.png\n",
            " inflated: BLtraining/6376.png\n",
            " inflated: BLtraining/6377.png\n",
            " inflated: BLtraining/6378.png\n",
            " inflated: BLtraining/6379.png\n",
            " inflated: BLtraining/638.png\n",
            " inflated: BLtraining/6380.png\n",
            " inflated: BLtraining/6381.png\n",
            " inflated: BLtraining/6382.png\n",
            " inflated: BLtraining/6383.png\n",
            " inflated: BLtraining/6384.png\n",
            " inflated: BLtraining/6385.png\n",
            " inflated: BLtraining/6386.png\n",
            " inflated: BLtraining/6387.png\n",
            " inflated: BLtraining/6388.png\n",
            " inflated: BLtraining/6389.png\n",
            " inflated: BLtraining/639.png\n",
            " inflated: BLtraining/6390.png\n",
            " inflated: BLtraining/6391.png\n",
            " inflated: BLtraining/6392.png\n",
            " inflated: BLtraining/6393.png\n",
            " inflated: BLtraining/6394.png\n",
            " inflated: BLtraining/6395.png\n",
            " inflated: BLtraining/6396.png\n",
            " inflated: BLtraining/6397.png\n",
            " inflated: BLtraining/6398.png\n",
            " inflated: BLtraining/6399.png\n",
            " inflated: BLtraining/64.png\n",
            " inflated: BLtraining/640.png\n",
            " inflated: BLtraining/6400.png\n",
            " inflated: BLtraining/6401.png\n",
            " inflated: BLtraining/6402.png\n",
            " inflated: BLtraining/6403.png\n",
            " inflated: BLtraining/6404.png\n",
            " inflated: BLtraining/6405.png\n",
            " inflated: BLtraining/6406.png\n",
            " inflated: BLtraining/6407.png\n",
            " inflated: BLtraining/6408.png\n",
            " inflated: BLtraining/6409.png\n",
            " inflated: BLtraining/641.png\n",
            " inflated: BLtraining/6410.png\n",
            " inflated: BLtraining/6411.png\n",
            " inflated: BLtraining/6412.png\n",
            " inflated: BLtraining/6413.png\n",
            " inflated: BLtraining/6414.png\n",
            " inflated: BLtraining/6415.png\n",
            " inflated: BLtraining/6416.png\n",
            " inflated: BLtraining/6417.png\n",
            " inflated: BLtraining/6418.png\n",
            " inflated: BLtraining/6419.png\n",
            " inflated: BLtraining/642.png\n",
            " inflated: BLtraining/6420.png\n",
            " inflated: BLtraining/6421.png\n",
            " inflated: BLtraining/6422.png\n",
            " inflated: BLtraining/6423.png\n",
            " inflated: BLtraining/6424.png\n",
            " inflated: BLtraining/6425.png\n",
            " inflated: BLtraining/6426.png\n",
            " inflated: BLtraining/6427.png\n",
            " inflated: BLtraining/6428.png\n",
            " inflated: BLtraining/6429.png\n",
            " inflated: BLtraining/643.png\n",
            " inflated: BLtraining/6430.png\n",
            " inflated: BLtraining/6431.png\n",
            " inflated: BLtraining/6432.png\n",
            " inflated: BLtraining/6433.png\n",
            " inflated: BLtraining/6434.png\n",
            " inflated: BLtraining/6435.png\n",
            " inflated: BLtraining/6436.png\n",
            " inflated: BLtraining/6437.png\n",
            " inflated: BLtraining/6438.png\n",
            " inflated: BLtraining/6439.png\n",
            " inflated: BLtraining/644.png\n",
            " inflated: BLtraining/6440.png\n",
            " inflated: BLtraining/6441.png\n",
            " inflated: BLtraining/6442.png\n",
            " inflated: BLtraining/6443.png\n",
            " inflated: BLtraining/6444.png\n",
            " inflated: BLtraining/6445.png\n",
            " inflated: BLtraining/6446.png\n",
            " inflated: BLtraining/6447.png\n",
            " inflated: BLtraining/6448.png\n",
            " inflated: BLtraining/6449.png\n",
            " inflated: BLtraining/645.png\n",
            " inflated: BLtraining/6450.png\n",
            " inflated: BLtraining/6451.png\n",
            " inflated: BLtraining/6452.png\n",
            " inflated: BLtraining/6453.png\n",
            " inflated: BLtraining/6454.png\n",
            " inflated: BLtraining/6455.png\n",
            " inflated: BLtraining/6456.png\n",
            " inflated: BLtraining/6457.png\n",
            " inflated: BLtraining/6458.png\n",
            " inflated: BLtraining/6459.png\n",
            " inflated: BLtraining/646.png\n",
            " inflated: BLtraining/6460.png\n",
            " inflated: BLtraining/6461.png\n",
            " inflated: BLtraining/6462.png\n",
            " inflated: BLtraining/6463.png\n",
            " inflated: BLtraining/6464.png\n",
            " inflated: BLtraining/6465.png\n",
            " inflated: BLtraining/6466.png\n",
            " inflated: BLtraining/6467.png\n",
            " inflated: BLtraining/6468.png\n",
            " inflated: BLtraining/6469.png\n",
            " inflated: BLtraining/647.png\n",
            " inflated: BLtraining/6470.png\n",
            " inflated: BLtraining/6471.png\n",
            " inflated: BLtraining/6472.png\n",
            " inflated: BLtraining/6473.png\n",
            " inflated: BLtraining/6474.png\n",
            " inflated: BLtraining/6475.png\n",
            " inflated: BLtraining/6476.png\n",
            " inflated: BLtraining/6477.png\n",
            " inflated: BLtraining/6478.png\n",
            " inflated: BLtraining/6479.png\n",
            " inflated: BLtraining/648.png\n",
            " inflated: BLtraining/6480.png\n",
            " inflated: BLtraining/6481.png\n",
            " inflated: BLtraining/6482.png\n",
            " inflated: BLtraining/6483.png\n",
            " inflated: BLtraining/6484.png\n",
            " inflated: BLtraining/6485.png\n",
            " inflated: BLtraining/6486.png\n",
            " inflated: BLtraining/6487.png\n",
            " inflated: BLtraining/6488.png\n",
            " inflated: BLtraining/6489.png\n",
            " inflated: BLtraining/649.png\n",
            " inflated: BLtraining/6490.png\n",
            " inflated: BLtraining/6491.png\n",
            " inflated: BLtraining/6492.png\n",
            " inflated: BLtraining/6493.png\n",
            " inflated: BLtraining/6494.png\n",
            " inflated: BLtraining/6495.png\n",
            " inflated: BLtraining/6496.png\n",
            " inflated: BLtraining/6497.png\n",
            " inflated: BLtraining/6498.png\n",
            " inflated: BLtraining/6499.png\n",
            " inflated: BLtraining/65.png\n",
            " inflated: BLtraining/650.png\n",
            " inflated: BLtraining/6500.png\n",
            " inflated: BLtraining/6501.png\n",
            " inflated: BLtraining/6502.png\n",
            " inflated: BLtraining/6503.png\n",
            " inflated: BLtraining/6504.png\n",
            " inflated: BLtraining/6505.png\n",
            " inflated: BLtraining/6506.png\n",
            " inflated: BLtraining/6507.png\n",
            " inflated: BLtraining/6508.png\n",
            " inflated: BLtraining/6509.png\n",
            " inflated: BLtraining/651.png\n",
            " inflated: BLtraining/6510.png\n",
            " inflated: BLtraining/6511.png\n",
            " inflated: BLtraining/6512.png\n",
            " inflated: BLtraining/6513.png\n",
            " inflated: BLtraining/6514.png\n",
            " inflated: BLtraining/6515.png\n",
            " inflated: BLtraining/6516.png\n",
            " inflated: BLtraining/6517.png\n",
            " inflated: BLtraining/6518.png\n",
            " inflated: BLtraining/6519.png\n",
            " inflated: BLtraining/652.png\n",
            " inflated: BLtraining/6520.png\n",
            " inflated: BLtraining/6521.png\n",
            " inflated: BLtraining/6522.png\n",
            " inflated: BLtraining/6523.png\n",
            " inflated: BLtraining/6524.png\n",
            " inflated: BLtraining/6525.png\n",
            " inflated: BLtraining/6526.png\n",
            " inflated: BLtraining/6527.png\n",
            " inflated: BLtraining/6528.png\n",
            " inflated: BLtraining/6529.png\n",
            " inflated: BLtraining/653.png\n",
            " inflated: BLtraining/6530.png\n",
            " inflated: BLtraining/6531.png\n",
            " inflated: BLtraining/6532.png\n",
            " inflated: BLtraining/6533.png\n",
            " inflated: BLtraining/6534.png\n",
            " inflated: BLtraining/6535.png\n",
            " inflated: BLtraining/6536.png\n",
            " inflated: BLtraining/6537.png\n",
            " inflated: BLtraining/6538.png\n",
            " inflated: BLtraining/6539.png\n",
            " inflated: BLtraining/654.png\n",
            " inflated: BLtraining/6540.png\n",
            " inflated: BLtraining/6541.png\n",
            " inflated: BLtraining/6542.png\n",
            " inflated: BLtraining/6543.png\n",
            " inflated: BLtraining/6544.png\n",
            " inflated: BLtraining/6545.png\n",
            " inflated: BLtraining/6546.png\n",
            " inflated: BLtraining/6547.png\n",
            " inflated: BLtraining/6548.png\n",
            " inflated: BLtraining/6549.png\n",
            " inflated: BLtraining/655.png\n",
            " inflated: BLtraining/6550.png\n",
            " inflated: BLtraining/6551.png\n",
            " inflated: BLtraining/6552.png\n",
            " inflated: BLtraining/6553.png\n",
            " inflated: BLtraining/6554.png\n",
            " inflated: BLtraining/6555.png\n",
            " inflated: BLtraining/6556.png\n",
            " inflated: BLtraining/6557.png\n",
            " inflated: BLtraining/6558.png\n",
            " inflated: BLtraining/6559.png\n",
            " inflated: BLtraining/656.png\n",
            " inflated: BLtraining/6560.png\n",
            " inflated: BLtraining/6561.png\n",
            " inflated: BLtraining/6562.png\n",
            " inflated: BLtraining/6563.png\n",
            " inflated: BLtraining/6564.png\n",
            " inflated: BLtraining/6565.png\n",
            " inflated: BLtraining/6566.png\n",
            " inflated: BLtraining/6567.png\n",
            " inflated: BLtraining/6568.png\n",
            " inflated: BLtraining/6569.png\n",
            " inflated: BLtraining/657.png\n",
            " inflated: BLtraining/6570.png\n",
            " inflated: BLtraining/6571.png\n",
            " inflated: BLtraining/6572.png\n",
            " inflated: BLtraining/6573.png\n",
            " inflated: BLtraining/6574.png\n",
            " inflated: BLtraining/6575.png\n",
            " inflated: BLtraining/6576.png\n",
            " inflated: BLtraining/6577.png\n",
            " inflated: BLtraining/6578.png\n",
            " inflated: BLtraining/6579.png\n",
            " inflated: BLtraining/658.png\n",
            " inflated: BLtraining/6580.png\n",
            " inflated: BLtraining/6581.png\n",
            " inflated: BLtraining/6582.png\n",
            " inflated: BLtraining/6583.png\n",
            " inflated: BLtraining/6584.png\n",
            " inflated: BLtraining/6585.png\n",
            " inflated: BLtraining/6586.png\n",
            " inflated: BLtraining/6587.png\n",
            " inflated: BLtraining/6588.png\n",
            " inflated: BLtraining/6589.png\n",
            " inflated: BLtraining/659.png\n",
            " inflated: BLtraining/6590.png\n",
            " inflated: BLtraining/6591.png\n",
            " inflated: BLtraining/6592.png\n",
            " inflated: BLtraining/6593.png\n",
            " inflated: BLtraining/6594.png\n",
            " inflated: BLtraining/6595.png\n",
            " inflated: BLtraining/6596.png\n",
            " inflated: BLtraining/6597.png\n",
            " inflated: BLtraining/6598.png\n",
            " inflated: BLtraining/6599.png\n",
            " inflated: BLtraining/66.png\n",
            " inflated: BLtraining/660.png\n",
            " inflated: BLtraining/6600.png\n",
            " inflated: BLtraining/6601.png\n",
            " inflated: BLtraining/6602.png\n",
            " inflated: BLtraining/6603.png\n",
            " inflated: BLtraining/6604.png\n",
            " inflated: BLtraining/6605.png\n",
            " inflated: BLtraining/6606.png\n",
            " inflated: BLtraining/6607.png\n",
            " inflated: BLtraining/6608.png\n",
            " inflated: BLtraining/6609.png\n",
            " inflated: BLtraining/661.png\n",
            " inflated: BLtraining/6610.png\n",
            " inflated: BLtraining/6611.png\n",
            " inflated: BLtraining/6612.png\n",
            " inflated: BLtraining/6613.png\n",
            " inflated: BLtraining/6614.png\n",
            " inflated: BLtraining/6615.png\n",
            " inflated: BLtraining/6616.png\n",
            " inflated: BLtraining/6617.png\n",
            " inflated: BLtraining/6618.png\n",
            " inflated: BLtraining/6619.png\n",
            " inflated: BLtraining/662.png\n",
            " inflated: BLtraining/6620.png\n",
            " inflated: BLtraining/6621.png\n",
            " inflated: BLtraining/6622.png\n",
            " inflated: BLtraining/6623.png\n",
            " inflated: BLtraining/6624.png\n",
            " inflated: BLtraining/6625.png\n",
            " inflated: BLtraining/6626.png\n",
            " inflated: BLtraining/6627.png\n",
            " inflated: BLtraining/6628.png\n",
            " inflated: BLtraining/6629.png\n",
            " inflated: BLtraining/663.png\n",
            " inflated: BLtraining/6630.png\n",
            " inflated: BLtraining/6631.png\n",
            " inflated: BLtraining/6632.png\n",
            " inflated: BLtraining/6633.png\n",
            " inflated: BLtraining/6634.png\n",
            " inflated: BLtraining/6635.png\n",
            " inflated: BLtraining/6636.png\n",
            " inflated: BLtraining/6637.png\n",
            " inflated: BLtraining/6638.png\n",
            " inflated: BLtraining/6639.png\n",
            " inflated: BLtraining/664.png\n",
            " inflated: BLtraining/6640.png\n",
            " inflated: BLtraining/6641.png\n",
            " inflated: BLtraining/6642.png\n",
            " inflated: BLtraining/6643.png\n",
            " inflated: BLtraining/6644.png\n",
            " inflated: BLtraining/6645.png\n",
            " inflated: BLtraining/6646.png\n",
            " inflated: BLtraining/6647.png\n",
            " inflated: BLtraining/6648.png\n",
            " inflated: BLtraining/6649.png\n",
            " inflated: BLtraining/665.png\n",
            " inflated: BLtraining/6650.png\n",
            " inflated: BLtraining/6651.png\n",
            " inflated: BLtraining/6652.png\n",
            " inflated: BLtraining/6653.png\n",
            " inflated: BLtraining/6654.png\n",
            " inflated: BLtraining/6655.png\n",
            " inflated: BLtraining/6656.png\n",
            " inflated: BLtraining/6657.png\n",
            " inflated: BLtraining/6658.png\n",
            " inflated: BLtraining/6659.png\n",
            " inflated: BLtraining/666.png\n",
            " inflated: BLtraining/6660.png\n",
            " inflated: BLtraining/6661.png\n",
            " inflated: BLtraining/6662.png\n",
            " inflated: BLtraining/6663.png\n",
            " inflated: BLtraining/6664.png\n",
            " inflated: BLtraining/6665.png\n",
            " inflated: BLtraining/6666.png\n",
            " inflated: BLtraining/6667.png\n",
            " inflated: BLtraining/6668.png\n",
            " inflated: BLtraining/6669.png\n",
            " inflated: BLtraining/667.png\n",
            " inflated: BLtraining/6670.png\n",
            " inflated: BLtraining/6671.png\n",
            " inflated: BLtraining/6672.png\n",
            " inflated: BLtraining/6673.png\n",
            " inflated: BLtraining/6674.png\n",
            " inflated: BLtraining/6675.png\n",
            " inflated: BLtraining/6676.png\n",
            " inflated: BLtraining/6677.png\n",
            " inflated: BLtraining/6678.png\n",
            " inflated: BLtraining/6679.png\n",
            " inflated: BLtraining/668.png\n",
            " inflated: BLtraining/6680.png\n",
            " inflated: BLtraining/6681.png\n",
            " inflated: BLtraining/6682.png\n",
            " inflated: BLtraining/6683.png\n",
            " inflated: BLtraining/6684.png\n",
            " inflated: BLtraining/6685.png\n",
            " inflated: BLtraining/6686.png\n",
            " inflated: BLtraining/6687.png\n",
            " inflated: BLtraining/6688.png\n",
            " inflated: BLtraining/6689.png\n",
            " inflated: BLtraining/669.png\n",
            " inflated: BLtraining/6690.png\n",
            " inflated: BLtraining/6691.png\n",
            " inflated: BLtraining/6692.png\n",
            " inflated: BLtraining/6693.png\n",
            " inflated: BLtraining/6694.png\n",
            " inflated: BLtraining/6695.png\n",
            " inflated: BLtraining/6696.png\n",
            " inflated: BLtraining/6697.png\n",
            " inflated: BLtraining/6698.png\n",
            " inflated: BLtraining/6699.png\n",
            " inflated: BLtraining/67.png\n",
            " inflated: BLtraining/670.png\n",
            " inflated: BLtraining/6700.png\n",
            " inflated: BLtraining/6701.png\n",
            " inflated: BLtraining/6702.png\n",
            " inflated: BLtraining/6703.png\n",
            " inflated: BLtraining/6704.png\n",
            " inflated: BLtraining/6705.png\n",
            " inflated: BLtraining/6706.png\n",
            " inflated: BLtraining/6707.png\n",
            " inflated: BLtraining/6708.png\n",
            " inflated: BLtraining/6709.png\n",
            " inflated: BLtraining/671.png\n",
            " inflated: BLtraining/6710.png\n",
            " inflated: BLtraining/6711.png\n",
            " inflated: BLtraining/6712.png\n",
            " inflated: BLtraining/6713.png\n",
            " inflated: BLtraining/6714.png\n",
            " inflated: BLtraining/6715.png\n",
            " inflated: BLtraining/6716.png\n",
            " inflated: BLtraining/6717.png\n",
            " inflated: BLtraining/6718.png\n",
            " inflated: BLtraining/6719.png\n",
            " inflated: BLtraining/672.png\n",
            " inflated: BLtraining/6720.png\n",
            " inflated: BLtraining/6721.png\n",
            " inflated: BLtraining/6722.png\n",
            " inflated: BLtraining/6723.png\n",
            " inflated: BLtraining/6724.png\n",
            " inflated: BLtraining/6725.png\n",
            " inflated: BLtraining/6726.png\n",
            " inflated: BLtraining/6727.png\n",
            " inflated: BLtraining/6728.png\n",
            " inflated: BLtraining/6729.png\n",
            " inflated: BLtraining/673.png\n",
            " inflated: BLtraining/6730.png\n",
            " inflated: BLtraining/6731.png\n",
            " inflated: BLtraining/6732.png\n",
            " inflated: BLtraining/6733.png\n",
            " inflated: BLtraining/6734.png\n",
            " inflated: BLtraining/6735.png\n",
            " inflated: BLtraining/6736.png\n",
            " inflated: BLtraining/6737.png\n",
            " inflated: BLtraining/6738.png\n",
            " inflated: BLtraining/6739.png\n",
            " inflated: BLtraining/674.png\n",
            " inflated: BLtraining/6740.png\n",
            " inflated: BLtraining/6741.png\n",
            " inflated: BLtraining/6742.png\n",
            " inflated: BLtraining/6743.png\n",
            " inflated: BLtraining/6744.png\n",
            " inflated: BLtraining/6745.png\n",
            " inflated: BLtraining/6746.png\n",
            " inflated: BLtraining/6747.png\n",
            " inflated: BLtraining/6748.png\n",
            " inflated: BLtraining/6749.png\n",
            " inflated: BLtraining/675.png\n",
            " inflated: BLtraining/6750.png\n",
            " inflated: BLtraining/6751.png\n",
            " inflated: BLtraining/6752.png\n",
            " inflated: BLtraining/6753.png\n",
            " inflated: BLtraining/6754.png\n",
            " inflated: BLtraining/6755.png\n",
            " inflated: BLtraining/6756.png\n",
            " inflated: BLtraining/6757.png\n",
            " inflated: BLtraining/6758.png\n",
            " inflated: BLtraining/6759.png\n",
            " inflated: BLtraining/676.png\n",
            " inflated: BLtraining/6760.png\n",
            " inflated: BLtraining/6761.png\n",
            " inflated: BLtraining/6762.png\n",
            " inflated: BLtraining/6763.png\n",
            " inflated: BLtraining/6764.png\n",
            " inflated: BLtraining/6765.png\n",
            " inflated: BLtraining/6766.png\n",
            " inflated: BLtraining/6767.png\n",
            " inflated: BLtraining/6768.png\n",
            " inflated: BLtraining/6769.png\n",
            " inflated: BLtraining/677.png\n",
            " inflated: BLtraining/6770.png\n",
            " inflated: BLtraining/6771.png\n",
            " inflated: BLtraining/6772.png\n",
            " inflated: BLtraining/6773.png\n",
            " inflated: BLtraining/6774.png\n",
            " inflated: BLtraining/6775.png\n",
            " inflated: BLtraining/6776.png\n",
            " inflated: BLtraining/6777.png\n",
            " inflated: BLtraining/6778.png\n",
            " inflated: BLtraining/6779.png\n",
            " inflated: BLtraining/678.png\n",
            " inflated: BLtraining/6780.png\n",
            " inflated: BLtraining/6781.png\n",
            " inflated: BLtraining/6782.png\n",
            " inflated: BLtraining/6783.png\n",
            " inflated: BLtraining/6784.png\n",
            " inflated: BLtraining/6785.png\n",
            " inflated: BLtraining/6786.png\n",
            " inflated: BLtraining/6787.png\n",
            " inflated: BLtraining/6788.png\n",
            " inflated: BLtraining/6789.png\n",
            " inflated: BLtraining/679.png\n",
            " inflated: BLtraining/6790.png\n",
            " inflated: BLtraining/6791.png\n",
            " inflated: BLtraining/6792.png\n",
            " inflated: BLtraining/6793.png\n",
            " inflated: BLtraining/6794.png\n",
            " inflated: BLtraining/6795.png\n",
            " inflated: BLtraining/6796.png\n",
            " inflated: BLtraining/6797.png\n",
            " inflated: BLtraining/6798.png\n",
            " inflated: BLtraining/6799.png\n",
            " inflated: BLtraining/68.png\n",
            " inflated: BLtraining/680.png\n",
            " inflated: BLtraining/6800.png\n",
            " inflated: BLtraining/6801.png\n",
            " inflated: BLtraining/6802.png\n",
            " inflated: BLtraining/6803.png\n",
            " inflated: BLtraining/6804.png\n",
            " inflated: BLtraining/6805.png\n",
            " inflated: BLtraining/6806.png\n",
            " inflated: BLtraining/6807.png\n",
            " inflated: BLtraining/6808.png\n",
            " inflated: BLtraining/6809.png\n",
            " inflated: BLtraining/681.png\n",
            " inflated: BLtraining/6810.png\n",
            " inflated: BLtraining/6811.png\n",
            " inflated: BLtraining/6812.png\n",
            " inflated: BLtraining/6813.png\n",
            " inflated: BLtraining/6814.png\n",
            " inflated: BLtraining/6815.png\n",
            " inflated: BLtraining/6816.png\n",
            " inflated: BLtraining/6817.png\n",
            " inflated: BLtraining/6818.png\n",
            " inflated: BLtraining/6819.png\n",
            " inflated: BLtraining/682.png\n",
            " inflated: BLtraining/6820.png\n",
            " inflated: BLtraining/6821.png\n",
            " inflated: BLtraining/6822.png\n",
            " inflated: BLtraining/6823.png\n",
            " inflated: BLtraining/6824.png\n",
            " inflated: BLtraining/6825.png\n",
            " inflated: BLtraining/6826.png\n",
            " inflated: BLtraining/6827.png\n",
            " inflated: BLtraining/6828.png\n",
            " inflated: BLtraining/6829.png\n",
            " inflated: BLtraining/683.png\n",
            " inflated: BLtraining/6830.png\n",
            " inflated: BLtraining/6831.png\n",
            " inflated: BLtraining/6832.png\n",
            " inflated: BLtraining/6833.png\n",
            " inflated: BLtraining/6834.png\n",
            " inflated: BLtraining/6835.png\n",
            " inflated: BLtraining/6836.png\n",
            " inflated: BLtraining/6837.png\n",
            " inflated: BLtraining/6838.png\n",
            " inflated: BLtraining/6839.png\n",
            " inflated: BLtraining/684.png\n",
            " inflated: BLtraining/6840.png\n",
            " inflated: BLtraining/6841.png\n",
            " inflated: BLtraining/6842.png\n",
            " inflated: BLtraining/6843.png\n",
            " inflated: BLtraining/6844.png\n",
            " inflated: BLtraining/6845.png\n",
            " inflated: BLtraining/6846.png\n",
            " inflated: BLtraining/6847.png\n",
            " inflated: BLtraining/6848.png\n",
            " inflated: BLtraining/6849.png\n",
            " inflated: BLtraining/685.png\n",
            " inflated: BLtraining/6850.png\n",
            " inflated: BLtraining/6851.png\n",
            " inflated: BLtraining/6852.png\n",
            " inflated: BLtraining/6853.png\n",
            " inflated: BLtraining/6854.png\n",
            " inflated: BLtraining/6855.png\n",
            " inflated: BLtraining/6856.png\n",
            " inflated: BLtraining/6857.png\n",
            " inflated: BLtraining/6858.png\n",
            " inflated: BLtraining/6859.png\n",
            " inflated: BLtraining/686.png\n",
            " inflated: BLtraining/6860.png\n",
            " inflated: BLtraining/6861.png\n",
            " inflated: BLtraining/6862.png\n",
            " inflated: BLtraining/6863.png\n",
            " inflated: BLtraining/6864.png\n",
            " inflated: BLtraining/6865.png\n",
            " inflated: BLtraining/6866.png\n",
            " inflated: BLtraining/6867.png\n",
            " inflated: BLtraining/6868.png\n",
            " inflated: BLtraining/6869.png\n",
            " inflated: BLtraining/687.png\n",
            " inflated: BLtraining/6870.png\n",
            " inflated: BLtraining/6871.png\n",
            " inflated: BLtraining/6872.png\n",
            " inflated: BLtraining/6873.png\n",
            " inflated: BLtraining/6874.png\n",
            " inflated: BLtraining/6875.png\n",
            " inflated: BLtraining/6876.png\n",
            " inflated: BLtraining/6877.png\n",
            " inflated: BLtraining/6878.png\n",
            " inflated: BLtraining/6879.png\n",
            " inflated: BLtraining/688.png\n",
            " inflated: BLtraining/6880.png\n",
            " inflated: BLtraining/6881.png\n",
            " inflated: BLtraining/6882.png\n",
            " inflated: BLtraining/6883.png\n",
            " inflated: BLtraining/6884.png\n",
            " inflated: BLtraining/6885.png\n",
            " inflated: BLtraining/6886.png\n",
            " inflated: BLtraining/6887.png\n",
            " inflated: BLtraining/6888.png\n",
            " inflated: BLtraining/6889.png\n",
            " inflated: BLtraining/689.png\n",
            " inflated: BLtraining/6890.png\n",
            " inflated: BLtraining/6891.png\n",
            " inflated: BLtraining/6892.png\n",
            " inflated: BLtraining/6893.png\n",
            " inflated: BLtraining/6894.png\n",
            " inflated: BLtraining/6895.png\n",
            " inflated: BLtraining/6896.png\n",
            " inflated: BLtraining/6897.png\n",
            " inflated: BLtraining/6898.png\n",
            " inflated: BLtraining/6899.png\n",
            " inflated: BLtraining/69.png\n",
            " inflated: BLtraining/690.png\n",
            " inflated: BLtraining/6900.png\n",
            " inflated: BLtraining/6901.png\n",
            " inflated: BLtraining/6902.png\n",
            " inflated: BLtraining/6903.png\n",
            " inflated: BLtraining/6904.png\n",
            " inflated: BLtraining/6905.png\n",
            " inflated: BLtraining/6906.png\n",
            " inflated: BLtraining/6907.png\n",
            " inflated: BLtraining/6908.png\n",
            " inflated: BLtraining/6909.png\n",
            " inflated: BLtraining/691.png\n",
            " inflated: BLtraining/6910.png\n",
            " inflated: BLtraining/6911.png\n",
            " inflated: BLtraining/6912.png\n",
            " inflated: BLtraining/6913.png\n",
            " inflated: BLtraining/6914.png\n",
            " inflated: BLtraining/6915.png\n",
            " inflated: BLtraining/6916.png\n",
            " inflated: BLtraining/6917.png\n",
            " inflated: BLtraining/6918.png\n",
            " inflated: BLtraining/6919.png\n",
            " inflated: BLtraining/692.png\n",
            " inflated: BLtraining/6920.png\n",
            " inflated: BLtraining/6921.png\n",
            " inflated: BLtraining/6922.png\n",
            " inflated: BLtraining/6923.png\n",
            " inflated: BLtraining/6924.png\n",
            " inflated: BLtraining/6925.png\n",
            " inflated: BLtraining/6926.png\n",
            " inflated: BLtraining/6927.png\n",
            " inflated: BLtraining/6928.png\n",
            " inflated: BLtraining/6929.png\n",
            " inflated: BLtraining/693.png\n",
            " inflated: BLtraining/6930.png\n",
            " inflated: BLtraining/6931.png\n",
            " inflated: BLtraining/6932.png\n",
            " inflated: BLtraining/6933.png\n",
            " inflated: BLtraining/6934.png\n",
            " inflated: BLtraining/6935.png\n",
            " inflated: BLtraining/6936.png\n",
            " inflated: BLtraining/6937.png\n",
            " inflated: BLtraining/6938.png\n",
            " inflated: BLtraining/6939.png\n",
            " inflated: BLtraining/694.png\n",
            " inflated: BLtraining/6940.png\n",
            " inflated: BLtraining/6941.png\n",
            " inflated: BLtraining/6942.png\n",
            " inflated: BLtraining/6943.png\n",
            " inflated: BLtraining/6944.png\n",
            " inflated: BLtraining/6945.png\n",
            " inflated: BLtraining/6946.png\n",
            " inflated: BLtraining/6947.png\n",
            " inflated: BLtraining/6948.png\n",
            " inflated: BLtraining/6949.png\n",
            " inflated: BLtraining/695.png\n",
            " inflated: BLtraining/6950.png\n",
            " inflated: BLtraining/6951.png\n",
            " inflated: BLtraining/6952.png\n",
            " inflated: BLtraining/6953.png\n",
            " inflated: BLtraining/6954.png\n",
            " inflated: BLtraining/6955.png\n",
            " inflated: BLtraining/6956.png\n",
            " inflated: BLtraining/6957.png\n",
            " inflated: BLtraining/6958.png\n",
            " inflated: BLtraining/6959.png\n",
            " inflated: BLtraining/696.png\n",
            " inflated: BLtraining/6960.png\n",
            " inflated: BLtraining/6961.png\n",
            " inflated: BLtraining/6962.png\n",
            " inflated: BLtraining/6963.png\n",
            " inflated: BLtraining/6964.png\n",
            " inflated: BLtraining/6965.png\n",
            " inflated: BLtraining/6966.png\n",
            " inflated: BLtraining/6967.png\n",
            " inflated: BLtraining/6968.png\n",
            " inflated: BLtraining/6969.png\n",
            " inflated: BLtraining/697.png\n",
            " inflated: BLtraining/6970.png\n",
            " inflated: BLtraining/6971.png\n",
            " inflated: BLtraining/6972.png\n",
            " inflated: BLtraining/6973.png\n",
            " inflated: BLtraining/6974.png\n",
            " inflated: BLtraining/6975.png\n",
            " inflated: BLtraining/6976.png\n",
            " inflated: BLtraining/6977.png\n",
            " inflated: BLtraining/6978.png\n",
            " inflated: BLtraining/6979.png\n",
            " inflated: BLtraining/698.png\n",
            " inflated: BLtraining/6980.png\n",
            " inflated: BLtraining/6981.png\n",
            " inflated: BLtraining/6982.png\n",
            " inflated: BLtraining/6983.png\n",
            " inflated: BLtraining/6984.png\n",
            " inflated: BLtraining/6985.png\n",
            " inflated: BLtraining/6986.png\n",
            " inflated: BLtraining/6987.png\n",
            " inflated: BLtraining/6988.png\n",
            " inflated: BLtraining/6989.png\n",
            " inflated: BLtraining/699.png\n",
            " inflated: BLtraining/6990.png\n",
            " inflated: BLtraining/6991.png\n",
            " inflated: BLtraining/6992.png\n",
            " inflated: BLtraining/6993.png\n",
            " inflated: BLtraining/6994.png\n",
            " inflated: BLtraining/6995.png\n",
            " inflated: BLtraining/6996.png\n",
            " inflated: BLtraining/6997.png\n",
            " inflated: BLtraining/6998.png\n",
            " inflated: BLtraining/6999.png\n",
            " inflated: BLtraining/7.png\n",
            " inflated: BLtraining/70.png\n",
            " inflated: BLtraining/700.png\n",
            " inflated: BLtraining/7000.png\n",
            " inflated: BLtraining/7001.png\n",
            " inflated: BLtraining/7002.png\n",
            " inflated: BLtraining/7003.png\n",
            " inflated: BLtraining/7004.png\n",
            " inflated: BLtraining/7005.png\n",
            " inflated: BLtraining/7006.png\n",
            " inflated: BLtraining/7007.png\n",
            " inflated: BLtraining/7008.png\n",
            " inflated: BLtraining/7009.png\n",
            " inflated: BLtraining/701.png\n",
            " inflated: BLtraining/7010.png\n",
            " inflated: BLtraining/7011.png\n",
            " inflated: BLtraining/7012.png\n",
            " inflated: BLtraining/7013.png\n",
            " inflated: BLtraining/7014.png\n",
            " inflated: BLtraining/7015.png\n",
            " inflated: BLtraining/7016.png\n",
            " inflated: BLtraining/7017.png\n",
            " inflated: BLtraining/7018.png\n",
            " inflated: BLtraining/7019.png\n",
            " inflated: BLtraining/702.png\n",
            " inflated: BLtraining/7020.png\n",
            " inflated: BLtraining/7021.png\n",
            " inflated: BLtraining/7022.png\n",
            " inflated: BLtraining/7023.png\n",
            " inflated: BLtraining/7024.png\n",
            " inflated: BLtraining/7025.png\n",
            " inflated: BLtraining/7026.png\n",
            " inflated: BLtraining/7027.png\n",
            " inflated: BLtraining/7028.png\n",
            " inflated: BLtraining/7029.png\n",
            " inflated: BLtraining/703.png\n",
            " inflated: BLtraining/7030.png\n",
            " inflated: BLtraining/7031.png\n",
            " inflated: BLtraining/7032.png\n",
            " inflated: BLtraining/7033.png\n",
            " inflated: BLtraining/7034.png\n",
            " inflated: BLtraining/7035.png\n",
            " inflated: BLtraining/7036.png\n",
            " inflated: BLtraining/7037.png\n",
            " inflated: BLtraining/7038.png\n",
            " inflated: BLtraining/7039.png\n",
            " inflated: BLtraining/704.png\n",
            " inflated: BLtraining/7040.png\n",
            " inflated: BLtraining/7041.png\n",
            " inflated: BLtraining/7042.png\n",
            " inflated: BLtraining/7043.png\n",
            " inflated: BLtraining/7044.png\n",
            " inflated: BLtraining/7045.png\n",
            " inflated: BLtraining/7046.png\n",
            " inflated: BLtraining/7047.png\n",
            " inflated: BLtraining/7048.png\n",
            " inflated: BLtraining/7049.png\n",
            " inflated: BLtraining/705.png\n",
            " inflated: BLtraining/7050.png\n",
            " inflated: BLtraining/7051.png\n",
            " inflated: BLtraining/7052.png\n",
            " inflated: BLtraining/7053.png\n",
            " inflated: BLtraining/7054.png\n",
            " inflated: BLtraining/7055.png\n",
            " inflated: BLtraining/7056.png\n",
            " inflated: BLtraining/7057.png\n",
            " inflated: BLtraining/7058.png\n",
            " inflated: BLtraining/7059.png\n",
            " inflated: BLtraining/706.png\n",
            " inflated: BLtraining/7060.png\n",
            " inflated: BLtraining/7061.png\n",
            " inflated: BLtraining/7062.png\n",
            " inflated: BLtraining/7063.png\n",
            " inflated: BLtraining/7064.png\n",
            " inflated: BLtraining/7065.png\n",
            " inflated: BLtraining/7066.png\n",
            " inflated: BLtraining/7067.png\n",
            " inflated: BLtraining/7068.png\n",
            " inflated: BLtraining/7069.png\n",
            " inflated: BLtraining/707.png\n",
            " inflated: BLtraining/7070.png\n",
            " inflated: BLtraining/7071.png\n",
            " inflated: BLtraining/7072.png\n",
            " inflated: BLtraining/7073.png\n",
            " inflated: BLtraining/7074.png\n",
            " inflated: BLtraining/7075.png\n",
            " inflated: BLtraining/7076.png\n",
            " inflated: BLtraining/7077.png\n",
            " inflated: BLtraining/7078.png\n",
            " inflated: BLtraining/7079.png\n",
            " inflated: BLtraining/708.png\n",
            " inflated: BLtraining/7080.png\n",
            " inflated: BLtraining/7081.png\n",
            " inflated: BLtraining/7082.png\n",
            " inflated: BLtraining/7083.png\n",
            " inflated: BLtraining/7084.png\n",
            " inflated: BLtraining/7085.png\n",
            " inflated: BLtraining/7086.png\n",
            " inflated: BLtraining/7087.png\n",
            " inflated: BLtraining/7088.png\n",
            " inflated: BLtraining/7089.png\n",
            " inflated: BLtraining/709.png\n",
            " inflated: BLtraining/7090.png\n",
            " inflated: BLtraining/7091.png\n",
            " inflated: BLtraining/7092.png\n",
            " inflated: BLtraining/7093.png\n",
            " inflated: BLtraining/7094.png\n",
            " inflated: BLtraining/7095.png\n",
            " inflated: BLtraining/7096.png\n",
            " inflated: BLtraining/7097.png\n",
            " inflated: BLtraining/7098.png\n",
            " inflated: BLtraining/7099.png\n",
            " inflated: BLtraining/71.png\n",
            " inflated: BLtraining/710.png\n",
            " inflated: BLtraining/7100.png\n",
            " inflated: BLtraining/7101.png\n",
            " inflated: BLtraining/7102.png\n",
            " inflated: BLtraining/7103.png\n",
            " inflated: BLtraining/7104.png\n",
            " inflated: BLtraining/7105.png\n",
            " inflated: BLtraining/7106.png\n",
            " inflated: BLtraining/7107.png\n",
            " inflated: BLtraining/7108.png\n",
            " inflated: BLtraining/7109.png\n",
            " inflated: BLtraining/711.png\n",
            " inflated: BLtraining/7110.png\n",
            " inflated: BLtraining/7111.png\n",
            " inflated: BLtraining/7112.png\n",
            " inflated: BLtraining/7113.png\n",
            " inflated: BLtraining/7114.png\n",
            " inflated: BLtraining/7115.png\n",
            " inflated: BLtraining/7116.png\n",
            " inflated: BLtraining/7117.png\n",
            " inflated: BLtraining/7118.png\n",
            " inflated: BLtraining/7119.png\n",
            " inflated: BLtraining/712.png\n",
            " inflated: BLtraining/7120.png\n",
            " inflated: BLtraining/7121.png\n",
            " inflated: BLtraining/7122.png\n",
            " inflated: BLtraining/7123.png\n",
            " inflated: BLtraining/7124.png\n",
            " inflated: BLtraining/7125.png\n",
            " inflated: BLtraining/7126.png\n",
            " inflated: BLtraining/7127.png\n",
            " inflated: BLtraining/7128.png\n",
            " inflated: BLtraining/7129.png\n",
            " inflated: BLtraining/713.png\n",
            " inflated: BLtraining/7130.png\n",
            " inflated: BLtraining/7131.png\n",
            " inflated: BLtraining/7132.png\n",
            " inflated: BLtraining/7133.png\n",
            " inflated: BLtraining/7134.png\n",
            " inflated: BLtraining/7135.png\n",
            " inflated: BLtraining/7136.png\n",
            " inflated: BLtraining/7137.png\n",
            " inflated: BLtraining/7138.png\n",
            " inflated: BLtraining/7139.png\n",
            " inflated: BLtraining/714.png\n",
            " inflated: BLtraining/7140.png\n",
            " inflated: BLtraining/7141.png\n",
            " inflated: BLtraining/7142.png\n",
            " inflated: BLtraining/7143.png\n",
            " inflated: BLtraining/7144.png\n",
            " inflated: BLtraining/7145.png\n",
            " inflated: BLtraining/7146.png\n",
            " inflated: BLtraining/7147.png\n",
            " inflated: BLtraining/7148.png\n",
            " inflated: BLtraining/7149.png\n",
            " inflated: BLtraining/715.png\n",
            " inflated: BLtraining/7150.png\n",
            " inflated: BLtraining/7151.png\n",
            " inflated: BLtraining/7152.png\n",
            " inflated: BLtraining/7153.png\n",
            " inflated: BLtraining/7154.png\n",
            " inflated: BLtraining/7155.png\n",
            " inflated: BLtraining/7156.png\n",
            " inflated: BLtraining/7157.png\n",
            " inflated: BLtraining/7158.png\n",
            " inflated: BLtraining/7159.png\n",
            " inflated: BLtraining/716.png\n",
            " inflated: BLtraining/7160.png\n",
            " inflated: BLtraining/7161.png\n",
            " inflated: BLtraining/7162.png\n",
            " inflated: BLtraining/7163.png\n",
            " inflated: BLtraining/7164.png\n",
            " inflated: BLtraining/7165.png\n",
            " inflated: BLtraining/7166.png\n",
            " inflated: BLtraining/7167.png\n",
            " inflated: BLtraining/7168.png\n",
            " inflated: BLtraining/7169.png\n",
            " inflated: BLtraining/717.png\n",
            " inflated: BLtraining/7170.png\n",
            " inflated: BLtraining/7171.png\n",
            " inflated: BLtraining/7172.png\n",
            " inflated: BLtraining/7173.png\n",
            " inflated: BLtraining/7174.png\n",
            " inflated: BLtraining/7175.png\n",
            " inflated: BLtraining/7176.png\n",
            " inflated: BLtraining/7177.png\n",
            " inflated: BLtraining/7178.png\n",
            " inflated: BLtraining/7179.png\n",
            " inflated: BLtraining/718.png\n",
            " inflated: BLtraining/7180.png\n",
            " inflated: BLtraining/7181.png\n",
            " inflated: BLtraining/7182.png\n",
            " inflated: BLtraining/7183.png\n",
            " inflated: BLtraining/7184.png\n",
            " inflated: BLtraining/7185.png\n",
            " inflated: BLtraining/7186.png\n",
            " inflated: BLtraining/7187.png\n",
            " inflated: BLtraining/7188.png\n",
            " inflated: BLtraining/7189.png\n",
            " inflated: BLtraining/719.png\n",
            " inflated: BLtraining/7190.png\n",
            " inflated: BLtraining/7191.png\n",
            " inflated: BLtraining/7192.png\n",
            " inflated: BLtraining/7193.png\n",
            " inflated: BLtraining/7194.png\n",
            " inflated: BLtraining/7195.png\n",
            " inflated: BLtraining/7196.png\n",
            " inflated: BLtraining/7197.png\n",
            " inflated: BLtraining/7198.png\n",
            " inflated: BLtraining/7199.png\n",
            " inflated: BLtraining/72.png\n",
            " inflated: BLtraining/720.png\n",
            " inflated: BLtraining/7200.png\n",
            " inflated: BLtraining/7201.png\n",
            " inflated: BLtraining/7202.png\n",
            " inflated: BLtraining/7203.png\n",
            " inflated: BLtraining/7204.png\n",
            " inflated: BLtraining/7205.png\n",
            " inflated: BLtraining/7206.png\n",
            " inflated: BLtraining/7207.png\n",
            " inflated: BLtraining/7208.png\n",
            " inflated: BLtraining/7209.png\n",
            " inflated: BLtraining/721.png\n",
            " inflated: BLtraining/7210.png\n",
            " inflated: BLtraining/7211.png\n",
            " inflated: BLtraining/7212.png\n",
            " inflated: BLtraining/7213.png\n",
            " inflated: BLtraining/7214.png\n",
            " inflated: BLtraining/7215.png\n",
            " inflated: BLtraining/7216.png\n",
            " inflated: BLtraining/7217.png\n",
            " inflated: BLtraining/7218.png\n",
            " inflated: BLtraining/7219.png\n",
            " inflated: BLtraining/722.png\n",
            " inflated: BLtraining/7220.png\n",
            " inflated: BLtraining/7221.png\n",
            " inflated: BLtraining/7222.png\n",
            " inflated: BLtraining/7223.png\n",
            " inflated: BLtraining/7224.png\n",
            " inflated: BLtraining/7225.png\n",
            " inflated: BLtraining/7226.png\n",
            " inflated: BLtraining/7227.png\n",
            " inflated: BLtraining/7228.png\n",
            " inflated: BLtraining/7229.png\n",
            " inflated: BLtraining/723.png\n",
            " inflated: BLtraining/7230.png\n",
            " inflated: BLtraining/7231.png\n",
            " inflated: BLtraining/7232.png\n",
            " inflated: BLtraining/7233.png\n",
            " inflated: BLtraining/7234.png\n",
            " inflated: BLtraining/7235.png\n",
            " inflated: BLtraining/7236.png\n",
            " inflated: BLtraining/7237.png\n",
            " inflated: BLtraining/7238.png\n",
            " inflated: BLtraining/7239.png\n",
            " inflated: BLtraining/724.png\n",
            " inflated: BLtraining/7240.png\n",
            " inflated: BLtraining/7241.png\n",
            " inflated: BLtraining/7242.png\n",
            " inflated: BLtraining/7243.png\n",
            " inflated: BLtraining/7244.png\n",
            " inflated: BLtraining/7245.png\n",
            " inflated: BLtraining/7246.png\n",
            " inflated: BLtraining/7247.png\n",
            " inflated: BLtraining/7248.png\n",
            " inflated: BLtraining/7249.png\n",
            " inflated: BLtraining/725.png\n",
            " inflated: BLtraining/7250.png\n",
            " inflated: BLtraining/7251.png\n",
            " inflated: BLtraining/7252.png\n",
            " inflated: BLtraining/7253.png\n",
            " inflated: BLtraining/7254.png\n",
            " inflated: BLtraining/7255.png\n",
            " inflated: BLtraining/7256.png\n",
            " inflated: BLtraining/7257.png\n",
            " inflated: BLtraining/7258.png\n",
            " inflated: BLtraining/7259.png\n",
            " inflated: BLtraining/726.png\n",
            " inflated: BLtraining/7260.png\n",
            " inflated: BLtraining/7261.png\n",
            " inflated: BLtraining/7262.png\n",
            " inflated: BLtraining/7263.png\n",
            " inflated: BLtraining/7264.png\n",
            " inflated: BLtraining/7265.png\n",
            " inflated: BLtraining/7266.png\n",
            " inflated: BLtraining/7267.png\n",
            " inflated: BLtraining/7268.png\n",
            " inflated: BLtraining/7269.png\n",
            " inflated: BLtraining/727.png\n",
            " inflated: BLtraining/7270.png\n",
            " inflated: BLtraining/7271.png\n",
            " inflated: BLtraining/7272.png\n",
            " inflated: BLtraining/7273.png\n",
            " inflated: BLtraining/7274.png\n",
            " inflated: BLtraining/7275.png\n",
            " inflated: BLtraining/7276.png\n",
            " inflated: BLtraining/7277.png\n",
            " inflated: BLtraining/7278.png\n",
            " inflated: BLtraining/7279.png\n",
            " inflated: BLtraining/728.png\n",
            " inflated: BLtraining/7280.png\n",
            " inflated: BLtraining/7281.png\n",
            " inflated: BLtraining/7282.png\n",
            " inflated: BLtraining/7283.png\n",
            " inflated: BLtraining/7284.png\n",
            " inflated: BLtraining/7285.png\n",
            " inflated: BLtraining/7286.png\n",
            " inflated: BLtraining/7287.png\n",
            " inflated: BLtraining/7288.png\n",
            " inflated: BLtraining/7289.png\n",
            " inflated: BLtraining/729.png\n",
            " inflated: BLtraining/7290.png\n",
            " inflated: BLtraining/7291.png\n",
            " inflated: BLtraining/7292.png\n",
            " inflated: BLtraining/7293.png\n",
            " inflated: BLtraining/7294.png\n",
            " inflated: BLtraining/7295.png\n",
            " inflated: BLtraining/7296.png\n",
            " inflated: BLtraining/7297.png\n",
            " inflated: BLtraining/7298.png\n",
            " inflated: BLtraining/7299.png\n",
            " inflated: BLtraining/73.png\n",
            " inflated: BLtraining/730.png\n",
            " inflated: BLtraining/7300.png\n",
            " inflated: BLtraining/7301.png\n",
            " inflated: BLtraining/7302.png\n",
            " inflated: BLtraining/7303.png\n",
            " inflated: BLtraining/7304.png\n",
            " inflated: BLtraining/7305.png\n",
            " inflated: BLtraining/7306.png\n",
            " inflated: BLtraining/7307.png\n",
            " inflated: BLtraining/7308.png\n",
            " inflated: BLtraining/7309.png\n",
            " inflated: BLtraining/731.png\n",
            " inflated: BLtraining/7310.png\n",
            " inflated: BLtraining/7311.png\n",
            " inflated: BLtraining/7312.png\n",
            " inflated: BLtraining/7313.png\n",
            " inflated: BLtraining/7314.png\n",
            " inflated: BLtraining/7315.png\n",
            " inflated: BLtraining/7316.png\n",
            " inflated: BLtraining/7317.png\n",
            " inflated: BLtraining/7318.png\n",
            " inflated: BLtraining/7319.png\n",
            " inflated: BLtraining/732.png\n",
            " inflated: BLtraining/7320.png\n",
            " inflated: BLtraining/7321.png\n",
            " inflated: BLtraining/7322.png\n",
            " inflated: BLtraining/7323.png\n",
            " inflated: BLtraining/733.png\n",
            " inflated: BLtraining/734.png\n",
            " inflated: BLtraining/735.png\n",
            " inflated: BLtraining/736.png\n",
            " inflated: BLtraining/737.png\n",
            " inflated: BLtraining/738.png\n",
            " inflated: BLtraining/739.png\n",
            " inflated: BLtraining/74.png\n",
            " inflated: BLtraining/740.png\n",
            " inflated: BLtraining/741.png\n",
            " inflated: BLtraining/742.png\n",
            " inflated: BLtraining/743.png\n",
            " inflated: BLtraining/744.png\n",
            " inflated: BLtraining/745.png\n",
            " inflated: BLtraining/746.png\n",
            " inflated: BLtraining/747.png\n",
            " inflated: BLtraining/748.png\n",
            " inflated: BLtraining/749.png\n",
            " inflated: BLtraining/75.png\n",
            " inflated: BLtraining/750.png\n",
            " inflated: BLtraining/751.png\n",
            " inflated: BLtraining/752.png\n",
            " inflated: BLtraining/753.png\n",
            " inflated: BLtraining/754.png\n",
            " inflated: BLtraining/755.png\n",
            " inflated: BLtraining/756.png\n",
            " inflated: BLtraining/757.png\n",
            " inflated: BLtraining/758.png\n",
            " inflated: BLtraining/759.png\n",
            " inflated: BLtraining/76.png\n",
            " inflated: BLtraining/760.png\n",
            " inflated: BLtraining/761.png\n",
            " inflated: BLtraining/762.png\n",
            " inflated: BLtraining/763.png\n",
            " inflated: BLtraining/764.png\n",
            " inflated: BLtraining/765.png\n",
            " inflated: BLtraining/766.png\n",
            " inflated: BLtraining/767.png\n",
            " inflated: BLtraining/768.png\n",
            " inflated: BLtraining/769.png\n",
            " inflated: BLtraining/77.png\n",
            " inflated: BLtraining/770.png\n",
            " inflated: BLtraining/771.png\n",
            " inflated: BLtraining/772.png\n",
            " inflated: BLtraining/773.png\n",
            " inflated: BLtraining/774.png\n",
            " inflated: BLtraining/775.png\n",
            " inflated: BLtraining/776.png\n",
            " inflated: BLtraining/777.png\n",
            " inflated: BLtraining/778.png\n",
            " inflated: BLtraining/779.png\n",
            " inflated: BLtraining/78.png\n",
            " inflated: BLtraining/780.png\n",
            " inflated: BLtraining/781.png\n",
            " inflated: BLtraining/782.png\n",
            " inflated: BLtraining/783.png\n",
            " inflated: BLtraining/784.png\n",
            " inflated: BLtraining/785.png\n",
            " inflated: BLtraining/786.png\n",
            " inflated: BLtraining/787.png\n",
            " inflated: BLtraining/788.png\n",
            " inflated: BLtraining/789.png\n",
            " inflated: BLtraining/79.png\n",
            " inflated: BLtraining/790.png\n",
            " inflated: BLtraining/791.png\n",
            " inflated: BLtraining/792.png\n",
            " inflated: BLtraining/793.png\n",
            " inflated: BLtraining/794.png\n",
            " inflated: BLtraining/795.png\n",
            " inflated: BLtraining/796.png\n",
            " inflated: BLtraining/797.png\n",
            " inflated: BLtraining/798.png\n",
            " inflated: BLtraining/799.png\n",
            " inflated: BLtraining/8.png\n",
            " inflated: BLtraining/80.png\n",
            " inflated: BLtraining/800.png\n",
            " inflated: BLtraining/801.png\n",
            " inflated: BLtraining/802.png\n",
            " inflated: BLtraining/803.png\n",
            " inflated: BLtraining/804.png\n",
            " inflated: BLtraining/805.png\n",
            " inflated: BLtraining/806.png\n",
            " inflated: BLtraining/807.png\n",
            " inflated: BLtraining/808.png\n",
            " inflated: BLtraining/809.png\n",
            " inflated: BLtraining/81.png\n",
            " inflated: BLtraining/810.png\n",
            " inflated: BLtraining/811.png\n",
            " inflated: BLtraining/812.png\n",
            " inflated: BLtraining/813.png\n",
            " inflated: BLtraining/814.png\n",
            " inflated: BLtraining/815.png\n",
            " inflated: BLtraining/816.png\n",
            " inflated: BLtraining/817.png\n",
            " inflated: BLtraining/818.png\n",
            " inflated: BLtraining/819.png\n",
            " inflated: BLtraining/82.png\n",
            " inflated: BLtraining/820.png\n",
            " inflated: BLtraining/821.png\n",
            " inflated: BLtraining/822.png\n",
            " inflated: BLtraining/823.png\n",
            " inflated: BLtraining/824.png\n",
            " inflated: BLtraining/825.png\n",
            " inflated: BLtraining/826.png\n",
            " inflated: BLtraining/827.png\n",
            " inflated: BLtraining/828.png\n",
            " inflated: BLtraining/829.png\n",
            " inflated: BLtraining/83.png\n",
            " inflated: BLtraining/830.png\n",
            " inflated: BLtraining/831.png\n",
            " inflated: BLtraining/832.png\n",
            " inflated: BLtraining/833.png\n",
            " inflated: BLtraining/834.png\n",
            " inflated: BLtraining/835.png\n",
            " inflated: BLtraining/836.png\n",
            " inflated: BLtraining/837.png\n",
            " inflated: BLtraining/838.png\n",
            " inflated: BLtraining/839.png\n",
            " inflated: BLtraining/84.png\n",
            " inflated: BLtraining/840.png\n",
            " inflated: BLtraining/841.png\n",
            " inflated: BLtraining/842.png\n",
            " inflated: BLtraining/843.png\n",
            " inflated: BLtraining/844.png\n",
            " inflated: BLtraining/845.png\n",
            " inflated: BLtraining/846.png\n",
            " inflated: BLtraining/847.png\n",
            " inflated: BLtraining/848.png\n",
            " inflated: BLtraining/849.png\n",
            " inflated: BLtraining/85.png\n",
            " inflated: BLtraining/850.png\n",
            " inflated: BLtraining/851.png\n",
            " inflated: BLtraining/852.png\n",
            " inflated: BLtraining/853.png\n",
            " inflated: BLtraining/854.png\n",
            " inflated: BLtraining/855.png\n",
            " inflated: BLtraining/856.png\n",
            " inflated: BLtraining/857.png\n",
            " inflated: BLtraining/858.png\n",
            " inflated: BLtraining/859.png\n",
            " inflated: BLtraining/86.png\n",
            " inflated: BLtraining/860.png\n",
            " inflated: BLtraining/861.png\n",
            " inflated: BLtraining/862.png\n",
            " inflated: BLtraining/863.png\n",
            " inflated: BLtraining/864.png\n",
            " inflated: BLtraining/865.png\n",
            " inflated: BLtraining/866.png\n",
            " inflated: BLtraining/867.png\n",
            " inflated: BLtraining/868.png\n",
            " inflated: BLtraining/869.png\n",
            " inflated: BLtraining/87.png\n",
            " inflated: BLtraining/870.png\n",
            " inflated: BLtraining/871.png\n",
            " inflated: BLtraining/872.png\n",
            " inflated: BLtraining/873.png\n",
            " inflated: BLtraining/874.png\n",
            " inflated: BLtraining/875.png\n",
            " inflated: BLtraining/876.png\n",
            " inflated: BLtraining/877.png\n",
            " inflated: BLtraining/878.png\n",
            " inflated: BLtraining/879.png\n",
            " inflated: BLtraining/88.png\n",
            " inflated: BLtraining/880.png\n",
            " inflated: BLtraining/881.png\n",
            " inflated: BLtraining/882.png\n",
            " inflated: BLtraining/883.png\n",
            " inflated: BLtraining/884.png\n",
            " inflated: BLtraining/885.png\n",
            " inflated: BLtraining/886.png\n",
            " inflated: BLtraining/887.png\n",
            " inflated: BLtraining/888.png\n",
            " inflated: BLtraining/889.png\n",
            " inflated: BLtraining/89.png\n",
            " inflated: BLtraining/890.png\n",
            " inflated: BLtraining/891.png\n",
            " inflated: BLtraining/892.png\n",
            " inflated: BLtraining/893.png\n",
            " inflated: BLtraining/894.png\n",
            " inflated: BLtraining/895.png\n",
            " inflated: BLtraining/896.png\n",
            " inflated: BLtraining/897.png\n",
            " inflated: BLtraining/898.png\n",
            " inflated: BLtraining/899.png\n",
            " inflated: BLtraining/9.png\n",
            " inflated: BLtraining/90.png\n",
            " inflated: BLtraining/900.png\n",
            " inflated: BLtraining/901.png\n",
            " inflated: BLtraining/902.png\n",
            " inflated: BLtraining/903.png\n",
            " inflated: BLtraining/904.png\n",
            " inflated: BLtraining/905.png\n",
            " inflated: BLtraining/906.png\n",
            " inflated: BLtraining/907.png\n",
            " inflated: BLtraining/908.png\n",
            " inflated: BLtraining/909.png\n",
            " inflated: BLtraining/91.png\n",
            " inflated: BLtraining/910.png\n",
            " inflated: BLtraining/911.png\n",
            " inflated: BLtraining/912.png\n",
            " inflated: BLtraining/913.png\n",
            " inflated: BLtraining/914.png\n",
            " inflated: BLtraining/915.png\n",
            " inflated: BLtraining/916.png\n",
            " inflated: BLtraining/917.png\n",
            " inflated: BLtraining/918.png\n",
            " inflated: BLtraining/919.png\n",
            " inflated: BLtraining/92.png\n",
            " inflated: BLtraining/920.png\n",
            " inflated: BLtraining/921.png\n",
            " inflated: BLtraining/922.png\n",
            " inflated: BLtraining/923.png\n",
            " inflated: BLtraining/924.png\n",
            " inflated: BLtraining/925.png\n",
            " inflated: BLtraining/926.png\n",
            " inflated: BLtraining/927.png\n",
            " inflated: BLtraining/928.png\n",
            " inflated: BLtraining/929.png\n",
            " inflated: BLtraining/93.png\n",
            " inflated: BLtraining/930.png\n",
            " inflated: BLtraining/931.png\n",
            " inflated: BLtraining/932.png\n",
            " inflated: BLtraining/933.png\n",
            " inflated: BLtraining/934.png\n",
            " inflated: BLtraining/935.png\n",
            " inflated: BLtraining/936.png\n",
            " inflated: BLtraining/937.png\n",
            " inflated: BLtraining/938.png\n",
            " inflated: BLtraining/939.png\n",
            " inflated: BLtraining/94.png\n",
            " inflated: BLtraining/940.png\n",
            " inflated: BLtraining/941.png\n",
            " inflated: BLtraining/942.png\n",
            " inflated: BLtraining/943.png\n",
            " inflated: BLtraining/944.png\n",
            " inflated: BLtraining/945.png\n",
            " inflated: BLtraining/946.png\n",
            " inflated: BLtraining/947.png\n",
            " inflated: BLtraining/948.png\n",
            " inflated: BLtraining/949.png\n",
            " inflated: BLtraining/95.png\n",
            " inflated: BLtraining/950.png\n",
            " inflated: BLtraining/951.png\n",
            " inflated: BLtraining/952.png\n",
            " inflated: BLtraining/953.png\n",
            " inflated: BLtraining/954.png\n",
            " inflated: BLtraining/955.png\n",
            " inflated: BLtraining/956.png\n",
            " inflated: BLtraining/957.png\n",
            " inflated: BLtraining/958.png\n",
            " inflated: BLtraining/959.png\n",
            " inflated: BLtraining/96.png\n",
            " inflated: BLtraining/960.png\n",
            " inflated: BLtraining/961.png\n",
            " inflated: BLtraining/962.png\n",
            " inflated: BLtraining/963.png\n",
            " inflated: BLtraining/964.png\n",
            " inflated: BLtraining/965.png\n",
            " inflated: BLtraining/966.png\n",
            " inflated: BLtraining/967.png\n",
            " inflated: BLtraining/968.png\n",
            " inflated: BLtraining/969.png\n",
            " inflated: BLtraining/97.png\n",
            " inflated: BLtraining/970.png\n",
            " inflated: BLtraining/971.png\n",
            " inflated: BLtraining/972.png\n",
            " inflated: BLtraining/973.png\n",
            " inflated: BLtraining/974.png\n",
            " inflated: BLtraining/975.png\n",
            " inflated: BLtraining/976.png\n",
            " inflated: BLtraining/977.png\n",
            " inflated: BLtraining/978.png\n",
            " inflated: BLtraining/979.png\n",
            " inflated: BLtraining/98.png\n",
            " inflated: BLtraining/980.png\n",
            " inflated: BLtraining/981.png\n",
            " inflated: BLtraining/982.png\n",
            " inflated: BLtraining/983.png\n",
            " inflated: BLtraining/984.png\n",
            " inflated: BLtraining/985.png\n",
            " inflated: BLtraining/986.png\n",
            " inflated: BLtraining/987.png\n",
            " inflated: BLtraining/988.png\n",
            " inflated: BLtraining/989.png\n",
            " inflated: BLtraining/99.png\n",
            " inflated: BLtraining/990.png\n",
            " inflated: BLtraining/991.png\n",
            " inflated: BLtraining/992.png\n",
            " inflated: BLtraining/993.png\n",
            " inflated: BLtraining/994.png\n",
            " inflated: BLtraining/995.png\n",
            " inflated: BLtraining/996.png\n",
            " inflated: BLtraining/997.png\n",
            " inflated: BLtraining/998.png\n",
            " inflated: BLtraining/999.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir 'validationImages'"
      ],
      "metadata": {
        "id": "6ieda3sr5CKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/validationImages' && jar xvf '/content/gdrive/MyDrive/BLvalidation.zip' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-apKvduBG6N",
        "outputId": "d26ccd98-700f-4ee1-dfdb-8e2c934a5c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " inflated: BLvalidation/7324.png\n",
            " inflated: BLvalidation/7325.png\n",
            " inflated: BLvalidation/7326.png\n",
            " inflated: BLvalidation/7327.png\n",
            " inflated: BLvalidation/7328.png\n",
            " inflated: BLvalidation/7329.png\n",
            " inflated: BLvalidation/7330.png\n",
            " inflated: BLvalidation/7331.png\n",
            " inflated: BLvalidation/7332.png\n",
            " inflated: BLvalidation/7333.png\n",
            " inflated: BLvalidation/7334.png\n",
            " inflated: BLvalidation/7335.png\n",
            " inflated: BLvalidation/7336.png\n",
            " inflated: BLvalidation/7337.png\n",
            " inflated: BLvalidation/7338.png\n",
            " inflated: BLvalidation/7339.png\n",
            " inflated: BLvalidation/7340.png\n",
            " inflated: BLvalidation/7341.png\n",
            " inflated: BLvalidation/7342.png\n",
            " inflated: BLvalidation/7343.png\n",
            " inflated: BLvalidation/7344.png\n",
            " inflated: BLvalidation/7345.png\n",
            " inflated: BLvalidation/7346.png\n",
            " inflated: BLvalidation/7347.png\n",
            " inflated: BLvalidation/7348.png\n",
            " inflated: BLvalidation/7349.png\n",
            " inflated: BLvalidation/7350.png\n",
            " inflated: BLvalidation/7351.png\n",
            " inflated: BLvalidation/7352.png\n",
            " inflated: BLvalidation/7353.png\n",
            " inflated: BLvalidation/7354.png\n",
            " inflated: BLvalidation/7355.png\n",
            " inflated: BLvalidation/7356.png\n",
            " inflated: BLvalidation/7357.png\n",
            " inflated: BLvalidation/7358.png\n",
            " inflated: BLvalidation/7359.png\n",
            " inflated: BLvalidation/7360.png\n",
            " inflated: BLvalidation/7361.png\n",
            " inflated: BLvalidation/7362.png\n",
            " inflated: BLvalidation/7363.png\n",
            " inflated: BLvalidation/7364.png\n",
            " inflated: BLvalidation/7365.png\n",
            " inflated: BLvalidation/7366.png\n",
            " inflated: BLvalidation/7367.png\n",
            " inflated: BLvalidation/7368.png\n",
            " inflated: BLvalidation/7369.png\n",
            " inflated: BLvalidation/7370.png\n",
            " inflated: BLvalidation/7371.png\n",
            " inflated: BLvalidation/7372.png\n",
            " inflated: BLvalidation/7373.png\n",
            " inflated: BLvalidation/7374.png\n",
            " inflated: BLvalidation/7375.png\n",
            " inflated: BLvalidation/7376.png\n",
            " inflated: BLvalidation/7377.png\n",
            " inflated: BLvalidation/7378.png\n",
            " inflated: BLvalidation/7379.png\n",
            " inflated: BLvalidation/7380.png\n",
            " inflated: BLvalidation/7381.png\n",
            " inflated: BLvalidation/7382.png\n",
            " inflated: BLvalidation/7383.png\n",
            " inflated: BLvalidation/7384.png\n",
            " inflated: BLvalidation/7385.png\n",
            " inflated: BLvalidation/7386.png\n",
            " inflated: BLvalidation/7387.png\n",
            " inflated: BLvalidation/7388.png\n",
            " inflated: BLvalidation/7389.png\n",
            " inflated: BLvalidation/7390.png\n",
            " inflated: BLvalidation/7391.png\n",
            " inflated: BLvalidation/7392.png\n",
            " inflated: BLvalidation/7393.png\n",
            " inflated: BLvalidation/7394.png\n",
            " inflated: BLvalidation/7395.png\n",
            " inflated: BLvalidation/7396.png\n",
            " inflated: BLvalidation/7397.png\n",
            " inflated: BLvalidation/7398.png\n",
            " inflated: BLvalidation/7399.png\n",
            " inflated: BLvalidation/7400.png\n",
            " inflated: BLvalidation/7401.png\n",
            " inflated: BLvalidation/7402.png\n",
            " inflated: BLvalidation/7403.png\n",
            " inflated: BLvalidation/7404.png\n",
            " inflated: BLvalidation/7405.png\n",
            " inflated: BLvalidation/7406.png\n",
            " inflated: BLvalidation/7407.png\n",
            " inflated: BLvalidation/7408.png\n",
            " inflated: BLvalidation/7409.png\n",
            " inflated: BLvalidation/7410.png\n",
            " inflated: BLvalidation/7411.png\n",
            " inflated: BLvalidation/7412.png\n",
            " inflated: BLvalidation/7413.png\n",
            " inflated: BLvalidation/7414.png\n",
            " inflated: BLvalidation/7415.png\n",
            " inflated: BLvalidation/7416.png\n",
            " inflated: BLvalidation/7417.png\n",
            " inflated: BLvalidation/7418.png\n",
            " inflated: BLvalidation/7419.png\n",
            " inflated: BLvalidation/7420.png\n",
            " inflated: BLvalidation/7421.png\n",
            " inflated: BLvalidation/7422.png\n",
            " inflated: BLvalidation/7423.png\n",
            " inflated: BLvalidation/7424.png\n",
            " inflated: BLvalidation/7425.png\n",
            " inflated: BLvalidation/7426.png\n",
            " inflated: BLvalidation/7427.png\n",
            " inflated: BLvalidation/7428.png\n",
            " inflated: BLvalidation/7429.png\n",
            " inflated: BLvalidation/7430.png\n",
            " inflated: BLvalidation/7431.png\n",
            " inflated: BLvalidation/7432.png\n",
            " inflated: BLvalidation/7433.png\n",
            " inflated: BLvalidation/7434.png\n",
            " inflated: BLvalidation/7435.png\n",
            " inflated: BLvalidation/7436.png\n",
            " inflated: BLvalidation/7437.png\n",
            " inflated: BLvalidation/7438.png\n",
            " inflated: BLvalidation/7439.png\n",
            " inflated: BLvalidation/7440.png\n",
            " inflated: BLvalidation/7441.png\n",
            " inflated: BLvalidation/7442.png\n",
            " inflated: BLvalidation/7443.png\n",
            " inflated: BLvalidation/7444.png\n",
            " inflated: BLvalidation/7445.png\n",
            " inflated: BLvalidation/7446.png\n",
            " inflated: BLvalidation/7447.png\n",
            " inflated: BLvalidation/7448.png\n",
            " inflated: BLvalidation/7449.png\n",
            " inflated: BLvalidation/7450.png\n",
            " inflated: BLvalidation/7451.png\n",
            " inflated: BLvalidation/7452.png\n",
            " inflated: BLvalidation/7453.png\n",
            " inflated: BLvalidation/7454.png\n",
            " inflated: BLvalidation/7455.png\n",
            " inflated: BLvalidation/7456.png\n",
            " inflated: BLvalidation/7457.png\n",
            " inflated: BLvalidation/7458.png\n",
            " inflated: BLvalidation/7459.png\n",
            " inflated: BLvalidation/7460.png\n",
            " inflated: BLvalidation/7461.png\n",
            " inflated: BLvalidation/7462.png\n",
            " inflated: BLvalidation/7463.png\n",
            " inflated: BLvalidation/7464.png\n",
            " inflated: BLvalidation/7465.png\n",
            " inflated: BLvalidation/7466.png\n",
            " inflated: BLvalidation/7467.png\n",
            " inflated: BLvalidation/7468.png\n",
            " inflated: BLvalidation/7469.png\n",
            " inflated: BLvalidation/7470.png\n",
            " inflated: BLvalidation/7471.png\n",
            " inflated: BLvalidation/7472.png\n",
            " inflated: BLvalidation/7473.png\n",
            " inflated: BLvalidation/7474.png\n",
            " inflated: BLvalidation/7475.png\n",
            " inflated: BLvalidation/7476.png\n",
            " inflated: BLvalidation/7477.png\n",
            " inflated: BLvalidation/7478.png\n",
            " inflated: BLvalidation/7479.png\n",
            " inflated: BLvalidation/7480.png\n",
            " inflated: BLvalidation/7481.png\n",
            " inflated: BLvalidation/7482.png\n",
            " inflated: BLvalidation/7483.png\n",
            " inflated: BLvalidation/7484.png\n",
            " inflated: BLvalidation/7485.png\n",
            " inflated: BLvalidation/7486.png\n",
            " inflated: BLvalidation/7487.png\n",
            " inflated: BLvalidation/7488.png\n",
            " inflated: BLvalidation/7489.png\n",
            " inflated: BLvalidation/7490.png\n",
            " inflated: BLvalidation/7491.png\n",
            " inflated: BLvalidation/7492.png\n",
            " inflated: BLvalidation/7493.png\n",
            " inflated: BLvalidation/7494.png\n",
            " inflated: BLvalidation/7495.png\n",
            " inflated: BLvalidation/7496.png\n",
            " inflated: BLvalidation/7497.png\n",
            " inflated: BLvalidation/7498.png\n",
            " inflated: BLvalidation/7499.png\n",
            " inflated: BLvalidation/7500.png\n",
            " inflated: BLvalidation/7501.png\n",
            " inflated: BLvalidation/7502.png\n",
            " inflated: BLvalidation/7503.png\n",
            " inflated: BLvalidation/7504.png\n",
            " inflated: BLvalidation/7505.png\n",
            " inflated: BLvalidation/7506.png\n",
            " inflated: BLvalidation/7507.png\n",
            " inflated: BLvalidation/7508.png\n",
            " inflated: BLvalidation/7509.png\n",
            " inflated: BLvalidation/7510.png\n",
            " inflated: BLvalidation/7511.png\n",
            " inflated: BLvalidation/7512.png\n",
            " inflated: BLvalidation/7513.png\n",
            " inflated: BLvalidation/7514.png\n",
            " inflated: BLvalidation/7515.png\n",
            " inflated: BLvalidation/7516.png\n",
            " inflated: BLvalidation/7517.png\n",
            " inflated: BLvalidation/7518.png\n",
            " inflated: BLvalidation/7519.png\n",
            " inflated: BLvalidation/7520.png\n",
            " inflated: BLvalidation/7521.png\n",
            " inflated: BLvalidation/7522.png\n",
            " inflated: BLvalidation/7523.png\n",
            " inflated: BLvalidation/7524.png\n",
            " inflated: BLvalidation/7525.png\n",
            " inflated: BLvalidation/7526.png\n",
            " inflated: BLvalidation/7527.png\n",
            " inflated: BLvalidation/7528.png\n",
            " inflated: BLvalidation/7529.png\n",
            " inflated: BLvalidation/7530.png\n",
            " inflated: BLvalidation/7531.png\n",
            " inflated: BLvalidation/7532.png\n",
            " inflated: BLvalidation/7533.png\n",
            " inflated: BLvalidation/7534.png\n",
            " inflated: BLvalidation/7535.png\n",
            " inflated: BLvalidation/7536.png\n",
            " inflated: BLvalidation/7537.png\n",
            " inflated: BLvalidation/7538.png\n",
            " inflated: BLvalidation/7539.png\n",
            " inflated: BLvalidation/7540.png\n",
            " inflated: BLvalidation/7541.png\n",
            " inflated: BLvalidation/7542.png\n",
            " inflated: BLvalidation/7543.png\n",
            " inflated: BLvalidation/7544.png\n",
            " inflated: BLvalidation/7545.png\n",
            " inflated: BLvalidation/7546.png\n",
            " inflated: BLvalidation/7547.png\n",
            " inflated: BLvalidation/7548.png\n",
            " inflated: BLvalidation/7549.png\n",
            " inflated: BLvalidation/7550.png\n",
            " inflated: BLvalidation/7551.png\n",
            " inflated: BLvalidation/7552.png\n",
            " inflated: BLvalidation/7553.png\n",
            " inflated: BLvalidation/7554.png\n",
            " inflated: BLvalidation/7555.png\n",
            " inflated: BLvalidation/7556.png\n",
            " inflated: BLvalidation/7557.png\n",
            " inflated: BLvalidation/7558.png\n",
            " inflated: BLvalidation/7559.png\n",
            " inflated: BLvalidation/7560.png\n",
            " inflated: BLvalidation/7561.png\n",
            " inflated: BLvalidation/7562.png\n",
            " inflated: BLvalidation/7563.png\n",
            " inflated: BLvalidation/7564.png\n",
            " inflated: BLvalidation/7565.png\n",
            " inflated: BLvalidation/7566.png\n",
            " inflated: BLvalidation/7567.png\n",
            " inflated: BLvalidation/7568.png\n",
            " inflated: BLvalidation/7569.png\n",
            " inflated: BLvalidation/7570.png\n",
            " inflated: BLvalidation/7571.png\n",
            " inflated: BLvalidation/7572.png\n",
            " inflated: BLvalidation/7573.png\n",
            " inflated: BLvalidation/7574.png\n",
            " inflated: BLvalidation/7575.png\n",
            " inflated: BLvalidation/7576.png\n",
            " inflated: BLvalidation/7577.png\n",
            " inflated: BLvalidation/7578.png\n",
            " inflated: BLvalidation/7579.png\n",
            " inflated: BLvalidation/7580.png\n",
            " inflated: BLvalidation/7581.png\n",
            " inflated: BLvalidation/7582.png\n",
            " inflated: BLvalidation/7583.png\n",
            " inflated: BLvalidation/7584.png\n",
            " inflated: BLvalidation/7585.png\n",
            " inflated: BLvalidation/7586.png\n",
            " inflated: BLvalidation/7587.png\n",
            " inflated: BLvalidation/7588.png\n",
            " inflated: BLvalidation/7589.png\n",
            " inflated: BLvalidation/7590.png\n",
            " inflated: BLvalidation/7591.png\n",
            " inflated: BLvalidation/7592.png\n",
            " inflated: BLvalidation/7593.png\n",
            " inflated: BLvalidation/7594.png\n",
            " inflated: BLvalidation/7595.png\n",
            " inflated: BLvalidation/7596.png\n",
            " inflated: BLvalidation/7597.png\n",
            " inflated: BLvalidation/7598.png\n",
            " inflated: BLvalidation/7599.png\n",
            " inflated: BLvalidation/7600.png\n",
            " inflated: BLvalidation/7601.png\n",
            " inflated: BLvalidation/7602.png\n",
            " inflated: BLvalidation/7603.png\n",
            " inflated: BLvalidation/7604.png\n",
            " inflated: BLvalidation/7605.png\n",
            " inflated: BLvalidation/7606.png\n",
            " inflated: BLvalidation/7607.png\n",
            " inflated: BLvalidation/7608.png\n",
            " inflated: BLvalidation/7609.png\n",
            " inflated: BLvalidation/7610.png\n",
            " inflated: BLvalidation/7611.png\n",
            " inflated: BLvalidation/7612.png\n",
            " inflated: BLvalidation/7613.png\n",
            " inflated: BLvalidation/7614.png\n",
            " inflated: BLvalidation/7615.png\n",
            " inflated: BLvalidation/7616.png\n",
            " inflated: BLvalidation/7617.png\n",
            " inflated: BLvalidation/7618.png\n",
            " inflated: BLvalidation/7619.png\n",
            " inflated: BLvalidation/7620.png\n",
            " inflated: BLvalidation/7621.png\n",
            " inflated: BLvalidation/7622.png\n",
            " inflated: BLvalidation/7623.png\n",
            " inflated: BLvalidation/7624.png\n",
            " inflated: BLvalidation/7625.png\n",
            " inflated: BLvalidation/7626.png\n",
            " inflated: BLvalidation/7627.png\n",
            " inflated: BLvalidation/7628.png\n",
            " inflated: BLvalidation/7629.png\n",
            " inflated: BLvalidation/7630.png\n",
            " inflated: BLvalidation/7631.png\n",
            " inflated: BLvalidation/7632.png\n",
            " inflated: BLvalidation/7633.png\n",
            " inflated: BLvalidation/7634.png\n",
            " inflated: BLvalidation/7635.png\n",
            " inflated: BLvalidation/7636.png\n",
            " inflated: BLvalidation/7637.png\n",
            " inflated: BLvalidation/7638.png\n",
            " inflated: BLvalidation/7639.png\n",
            " inflated: BLvalidation/7640.png\n",
            " inflated: BLvalidation/7641.png\n",
            " inflated: BLvalidation/7642.png\n",
            " inflated: BLvalidation/7643.png\n",
            " inflated: BLvalidation/7644.png\n",
            " inflated: BLvalidation/7645.png\n",
            " inflated: BLvalidation/7646.png\n",
            " inflated: BLvalidation/7647.png\n",
            " inflated: BLvalidation/7648.png\n",
            " inflated: BLvalidation/7649.png\n",
            " inflated: BLvalidation/7650.png\n",
            " inflated: BLvalidation/7651.png\n",
            " inflated: BLvalidation/7652.png\n",
            " inflated: BLvalidation/7653.png\n",
            " inflated: BLvalidation/7654.png\n",
            " inflated: BLvalidation/7655.png\n",
            " inflated: BLvalidation/7656.png\n",
            " inflated: BLvalidation/7657.png\n",
            " inflated: BLvalidation/7658.png\n",
            " inflated: BLvalidation/7659.png\n",
            " inflated: BLvalidation/7660.png\n",
            " inflated: BLvalidation/7661.png\n",
            " inflated: BLvalidation/7662.png\n",
            " inflated: BLvalidation/7663.png\n",
            " inflated: BLvalidation/7664.png\n",
            " inflated: BLvalidation/7665.png\n",
            " inflated: BLvalidation/7666.png\n",
            " inflated: BLvalidation/7667.png\n",
            " inflated: BLvalidation/7668.png\n",
            " inflated: BLvalidation/7669.png\n",
            " inflated: BLvalidation/7670.png\n",
            " inflated: BLvalidation/7671.png\n",
            " inflated: BLvalidation/7672.png\n",
            " inflated: BLvalidation/7673.png\n",
            " inflated: BLvalidation/7674.png\n",
            " inflated: BLvalidation/7675.png\n",
            " inflated: BLvalidation/7676.png\n",
            " inflated: BLvalidation/7677.png\n",
            " inflated: BLvalidation/7678.png\n",
            " inflated: BLvalidation/7679.png\n",
            " inflated: BLvalidation/7680.png\n",
            " inflated: BLvalidation/7681.png\n",
            " inflated: BLvalidation/7682.png\n",
            " inflated: BLvalidation/7683.png\n",
            " inflated: BLvalidation/7684.png\n",
            " inflated: BLvalidation/7685.png\n",
            " inflated: BLvalidation/7686.png\n",
            " inflated: BLvalidation/7687.png\n",
            " inflated: BLvalidation/7688.png\n",
            " inflated: BLvalidation/7689.png\n",
            " inflated: BLvalidation/7690.png\n",
            " inflated: BLvalidation/7691.png\n",
            " inflated: BLvalidation/7692.png\n",
            " inflated: BLvalidation/7693.png\n",
            " inflated: BLvalidation/7694.png\n",
            " inflated: BLvalidation/7695.png\n",
            " inflated: BLvalidation/7696.png\n",
            " inflated: BLvalidation/7697.png\n",
            " inflated: BLvalidation/7698.png\n",
            " inflated: BLvalidation/7699.png\n",
            " inflated: BLvalidation/7700.png\n",
            " inflated: BLvalidation/7701.png\n",
            " inflated: BLvalidation/7702.png\n",
            " inflated: BLvalidation/7703.png\n",
            " inflated: BLvalidation/7704.png\n",
            " inflated: BLvalidation/7705.png\n",
            " inflated: BLvalidation/7706.png\n",
            " inflated: BLvalidation/7707.png\n",
            " inflated: BLvalidation/7708.png\n",
            " inflated: BLvalidation/7709.png\n",
            " inflated: BLvalidation/7710.png\n",
            " inflated: BLvalidation/7711.png\n",
            " inflated: BLvalidation/7712.png\n",
            " inflated: BLvalidation/7713.png\n",
            " inflated: BLvalidation/7714.png\n",
            " inflated: BLvalidation/7715.png\n",
            " inflated: BLvalidation/7716.png\n",
            " inflated: BLvalidation/7717.png\n",
            " inflated: BLvalidation/7718.png\n",
            " inflated: BLvalidation/7719.png\n",
            " inflated: BLvalidation/7720.png\n",
            " inflated: BLvalidation/7721.png\n",
            " inflated: BLvalidation/7722.png\n",
            " inflated: BLvalidation/7723.png\n",
            " inflated: BLvalidation/7724.png\n",
            " inflated: BLvalidation/7725.png\n",
            " inflated: BLvalidation/7726.png\n",
            " inflated: BLvalidation/7727.png\n",
            " inflated: BLvalidation/7728.png\n",
            " inflated: BLvalidation/7729.png\n",
            " inflated: BLvalidation/7730.png\n",
            " inflated: BLvalidation/7731.png\n",
            " inflated: BLvalidation/7732.png\n",
            " inflated: BLvalidation/7733.png\n",
            " inflated: BLvalidation/7734.png\n",
            " inflated: BLvalidation/7735.png\n",
            " inflated: BLvalidation/7736.png\n",
            " inflated: BLvalidation/7737.png\n",
            " inflated: BLvalidation/7738.png\n",
            " inflated: BLvalidation/7739.png\n",
            " inflated: BLvalidation/7740.png\n",
            " inflated: BLvalidation/7741.png\n",
            " inflated: BLvalidation/7742.png\n",
            " inflated: BLvalidation/7743.png\n",
            " inflated: BLvalidation/7744.png\n",
            " inflated: BLvalidation/7745.png\n",
            " inflated: BLvalidation/7746.png\n",
            " inflated: BLvalidation/7747.png\n",
            " inflated: BLvalidation/7748.png\n",
            " inflated: BLvalidation/7749.png\n",
            " inflated: BLvalidation/7750.png\n",
            " inflated: BLvalidation/7751.png\n",
            " inflated: BLvalidation/7752.png\n",
            " inflated: BLvalidation/7753.png\n",
            " inflated: BLvalidation/7754.png\n",
            " inflated: BLvalidation/7755.png\n",
            " inflated: BLvalidation/7756.png\n",
            " inflated: BLvalidation/7757.png\n",
            " inflated: BLvalidation/7758.png\n",
            " inflated: BLvalidation/7759.png\n",
            " inflated: BLvalidation/7760.png\n",
            " inflated: BLvalidation/7761.png\n",
            " inflated: BLvalidation/7762.png\n",
            " inflated: BLvalidation/7763.png\n",
            " inflated: BLvalidation/7764.png\n",
            " inflated: BLvalidation/7765.png\n",
            " inflated: BLvalidation/7766.png\n",
            " inflated: BLvalidation/7767.png\n",
            " inflated: BLvalidation/7768.png\n",
            " inflated: BLvalidation/7769.png\n",
            " inflated: BLvalidation/7770.png\n",
            " inflated: BLvalidation/7771.png\n",
            " inflated: BLvalidation/7772.png\n",
            " inflated: BLvalidation/7773.png\n",
            " inflated: BLvalidation/7774.png\n",
            " inflated: BLvalidation/7775.png\n",
            " inflated: BLvalidation/7776.png\n",
            " inflated: BLvalidation/7777.png\n",
            " inflated: BLvalidation/7778.png\n",
            " inflated: BLvalidation/7779.png\n",
            " inflated: BLvalidation/7780.png\n",
            " inflated: BLvalidation/7781.png\n",
            " inflated: BLvalidation/7782.png\n",
            " inflated: BLvalidation/7783.png\n",
            " inflated: BLvalidation/7784.png\n",
            " inflated: BLvalidation/7785.png\n",
            " inflated: BLvalidation/7786.png\n",
            " inflated: BLvalidation/7787.png\n",
            " inflated: BLvalidation/7788.png\n",
            " inflated: BLvalidation/7789.png\n",
            " inflated: BLvalidation/7790.png\n",
            " inflated: BLvalidation/7791.png\n",
            " inflated: BLvalidation/7792.png\n",
            " inflated: BLvalidation/7793.png\n",
            " inflated: BLvalidation/7794.png\n",
            " inflated: BLvalidation/7795.png\n",
            " inflated: BLvalidation/7796.png\n",
            " inflated: BLvalidation/7797.png\n",
            " inflated: BLvalidation/7798.png\n",
            " inflated: BLvalidation/7799.png\n",
            " inflated: BLvalidation/7800.png\n",
            " inflated: BLvalidation/7801.png\n",
            " inflated: BLvalidation/7802.png\n",
            " inflated: BLvalidation/7803.png\n",
            " inflated: BLvalidation/7804.png\n",
            " inflated: BLvalidation/7805.png\n",
            " inflated: BLvalidation/7806.png\n",
            " inflated: BLvalidation/7807.png\n",
            " inflated: BLvalidation/7808.png\n",
            " inflated: BLvalidation/7809.png\n",
            " inflated: BLvalidation/7810.png\n",
            " inflated: BLvalidation/7811.png\n",
            " inflated: BLvalidation/7812.png\n",
            " inflated: BLvalidation/7813.png\n",
            " inflated: BLvalidation/7814.png\n",
            " inflated: BLvalidation/7815.png\n",
            " inflated: BLvalidation/7816.png\n",
            " inflated: BLvalidation/7817.png\n",
            " inflated: BLvalidation/7818.png\n",
            " inflated: BLvalidation/7819.png\n",
            " inflated: BLvalidation/7820.png\n",
            " inflated: BLvalidation/7821.png\n",
            " inflated: BLvalidation/7822.png\n",
            " inflated: BLvalidation/7823.png\n",
            " inflated: BLvalidation/7824.png\n",
            " inflated: BLvalidation/7825.png\n",
            " inflated: BLvalidation/7826.png\n",
            " inflated: BLvalidation/7827.png\n",
            " inflated: BLvalidation/7828.png\n",
            " inflated: BLvalidation/7829.png\n",
            " inflated: BLvalidation/7830.png\n",
            " inflated: BLvalidation/7831.png\n",
            " inflated: BLvalidation/7832.png\n",
            " inflated: BLvalidation/7833.png\n",
            " inflated: BLvalidation/7834.png\n",
            " inflated: BLvalidation/7835.png\n",
            " inflated: BLvalidation/7836.png\n",
            " inflated: BLvalidation/7837.png\n",
            " inflated: BLvalidation/7838.png\n",
            " inflated: BLvalidation/7839.png\n",
            " inflated: BLvalidation/7840.png\n",
            " inflated: BLvalidation/7841.png\n",
            " inflated: BLvalidation/7842.png\n",
            " inflated: BLvalidation/7843.png\n",
            " inflated: BLvalidation/7844.png\n",
            " inflated: BLvalidation/7845.png\n",
            " inflated: BLvalidation/7846.png\n",
            " inflated: BLvalidation/7847.png\n",
            " inflated: BLvalidation/7848.png\n",
            " inflated: BLvalidation/7849.png\n",
            " inflated: BLvalidation/7850.png\n",
            " inflated: BLvalidation/7851.png\n",
            " inflated: BLvalidation/7852.png\n",
            " inflated: BLvalidation/7853.png\n",
            " inflated: BLvalidation/7854.png\n",
            " inflated: BLvalidation/7855.png\n",
            " inflated: BLvalidation/7856.png\n",
            " inflated: BLvalidation/7857.png\n",
            " inflated: BLvalidation/7858.png\n",
            " inflated: BLvalidation/7859.png\n",
            " inflated: BLvalidation/7860.png\n",
            " inflated: BLvalidation/7861.png\n",
            " inflated: BLvalidation/7862.png\n",
            " inflated: BLvalidation/7863.png\n",
            " inflated: BLvalidation/7864.png\n",
            " inflated: BLvalidation/7865.png\n",
            " inflated: BLvalidation/7866.png\n",
            " inflated: BLvalidation/7867.png\n",
            " inflated: BLvalidation/7868.png\n",
            " inflated: BLvalidation/7869.png\n",
            " inflated: BLvalidation/7870.png\n",
            " inflated: BLvalidation/7871.png\n",
            " inflated: BLvalidation/7872.png\n",
            " inflated: BLvalidation/7873.png\n",
            " inflated: BLvalidation/7874.png\n",
            " inflated: BLvalidation/7875.png\n",
            " inflated: BLvalidation/7876.png\n",
            " inflated: BLvalidation/7877.png\n",
            " inflated: BLvalidation/7878.png\n",
            " inflated: BLvalidation/7879.png\n",
            " inflated: BLvalidation/7880.png\n",
            " inflated: BLvalidation/7881.png\n",
            " inflated: BLvalidation/7882.png\n",
            " inflated: BLvalidation/7883.png\n",
            " inflated: BLvalidation/7884.png\n",
            " inflated: BLvalidation/7885.png\n",
            " inflated: BLvalidation/7886.png\n",
            " inflated: BLvalidation/7887.png\n",
            " inflated: BLvalidation/7888.png\n",
            " inflated: BLvalidation/7889.png\n",
            " inflated: BLvalidation/7890.png\n",
            " inflated: BLvalidation/7891.png\n",
            " inflated: BLvalidation/7892.png\n",
            " inflated: BLvalidation/7893.png\n",
            " inflated: BLvalidation/7894.png\n",
            " inflated: BLvalidation/7895.png\n",
            " inflated: BLvalidation/7896.png\n",
            " inflated: BLvalidation/7897.png\n",
            " inflated: BLvalidation/7898.png\n",
            " inflated: BLvalidation/7899.png\n",
            " inflated: BLvalidation/7900.png\n",
            " inflated: BLvalidation/7901.png\n",
            " inflated: BLvalidation/7902.png\n",
            " inflated: BLvalidation/7903.png\n",
            " inflated: BLvalidation/7904.png\n",
            " inflated: BLvalidation/7905.png\n",
            " inflated: BLvalidation/7906.png\n",
            " inflated: BLvalidation/7907.png\n",
            " inflated: BLvalidation/7908.png\n",
            " inflated: BLvalidation/7909.png\n",
            " inflated: BLvalidation/7910.png\n",
            " inflated: BLvalidation/7911.png\n",
            " inflated: BLvalidation/7912.png\n",
            " inflated: BLvalidation/7913.png\n",
            " inflated: BLvalidation/7914.png\n",
            " inflated: BLvalidation/7915.png\n",
            " inflated: BLvalidation/7916.png\n",
            " inflated: BLvalidation/7917.png\n",
            " inflated: BLvalidation/7918.png\n",
            " inflated: BLvalidation/7919.png\n",
            " inflated: BLvalidation/7920.png\n",
            " inflated: BLvalidation/7921.png\n",
            " inflated: BLvalidation/7922.png\n",
            " inflated: BLvalidation/7923.png\n",
            " inflated: BLvalidation/7924.png\n",
            " inflated: BLvalidation/7925.png\n",
            " inflated: BLvalidation/7926.png\n",
            " inflated: BLvalidation/7927.png\n",
            " inflated: BLvalidation/7928.png\n",
            " inflated: BLvalidation/7929.png\n",
            " inflated: BLvalidation/7930.png\n",
            " inflated: BLvalidation/7931.png\n",
            " inflated: BLvalidation/7932.png\n",
            " inflated: BLvalidation/7933.png\n",
            " inflated: BLvalidation/7934.png\n",
            " inflated: BLvalidation/7935.png\n",
            " inflated: BLvalidation/7936.png\n",
            " inflated: BLvalidation/7937.png\n",
            " inflated: BLvalidation/7938.png\n",
            " inflated: BLvalidation/7939.png\n",
            " inflated: BLvalidation/7940.png\n",
            " inflated: BLvalidation/7941.png\n",
            " inflated: BLvalidation/7942.png\n",
            " inflated: BLvalidation/7943.png\n",
            " inflated: BLvalidation/7944.png\n",
            " inflated: BLvalidation/7945.png\n",
            " inflated: BLvalidation/7946.png\n",
            " inflated: BLvalidation/7947.png\n",
            " inflated: BLvalidation/7948.png\n",
            " inflated: BLvalidation/7949.png\n",
            " inflated: BLvalidation/7950.png\n",
            " inflated: BLvalidation/7951.png\n",
            " inflated: BLvalidation/7952.png\n",
            " inflated: BLvalidation/7953.png\n",
            " inflated: BLvalidation/7954.png\n",
            " inflated: BLvalidation/7955.png\n",
            " inflated: BLvalidation/7956.png\n",
            " inflated: BLvalidation/7957.png\n",
            " inflated: BLvalidation/7958.png\n",
            " inflated: BLvalidation/7959.png\n",
            " inflated: BLvalidation/7960.png\n",
            " inflated: BLvalidation/7961.png\n",
            " inflated: BLvalidation/7962.png\n",
            " inflated: BLvalidation/7963.png\n",
            " inflated: BLvalidation/7964.png\n",
            " inflated: BLvalidation/7965.png\n",
            " inflated: BLvalidation/7966.png\n",
            " inflated: BLvalidation/7967.png\n",
            " inflated: BLvalidation/7968.png\n",
            " inflated: BLvalidation/7969.png\n",
            " inflated: BLvalidation/7970.png\n",
            " inflated: BLvalidation/7971.png\n",
            " inflated: BLvalidation/7972.png\n",
            " inflated: BLvalidation/7973.png\n",
            " inflated: BLvalidation/7974.png\n",
            " inflated: BLvalidation/7975.png\n",
            " inflated: BLvalidation/7976.png\n",
            " inflated: BLvalidation/7977.png\n",
            " inflated: BLvalidation/7978.png\n",
            " inflated: BLvalidation/7979.png\n",
            " inflated: BLvalidation/7980.png\n",
            " inflated: BLvalidation/7981.png\n",
            " inflated: BLvalidation/7982.png\n",
            " inflated: BLvalidation/7983.png\n",
            " inflated: BLvalidation/7984.png\n",
            " inflated: BLvalidation/7985.png\n",
            " inflated: BLvalidation/7986.png\n",
            " inflated: BLvalidation/7987.png\n",
            " inflated: BLvalidation/7988.png\n",
            " inflated: BLvalidation/7989.png\n",
            " inflated: BLvalidation/7990.png\n",
            " inflated: BLvalidation/7991.png\n",
            " inflated: BLvalidation/7992.png\n",
            " inflated: BLvalidation/7993.png\n",
            " inflated: BLvalidation/7994.png\n",
            " inflated: BLvalidation/7995.png\n",
            " inflated: BLvalidation/7996.png\n",
            " inflated: BLvalidation/7997.png\n",
            " inflated: BLvalidation/7998.png\n",
            " inflated: BLvalidation/7999.png\n",
            " inflated: BLvalidation/8000.png\n",
            " inflated: BLvalidation/8001.png\n",
            " inflated: BLvalidation/8002.png\n",
            " inflated: BLvalidation/8003.png\n",
            " inflated: BLvalidation/8004.png\n",
            " inflated: BLvalidation/8005.png\n",
            " inflated: BLvalidation/8006.png\n",
            " inflated: BLvalidation/8007.png\n",
            " inflated: BLvalidation/8008.png\n",
            " inflated: BLvalidation/8009.png\n",
            " inflated: BLvalidation/8010.png\n",
            " inflated: BLvalidation/8011.png\n",
            " inflated: BLvalidation/8012.png\n",
            " inflated: BLvalidation/8013.png\n",
            " inflated: BLvalidation/8014.png\n",
            " inflated: BLvalidation/8015.png\n",
            " inflated: BLvalidation/8016.png\n",
            " inflated: BLvalidation/8017.png\n",
            " inflated: BLvalidation/8018.png\n",
            " inflated: BLvalidation/8019.png\n",
            " inflated: BLvalidation/8020.png\n",
            " inflated: BLvalidation/8021.png\n",
            " inflated: BLvalidation/8022.png\n",
            " inflated: BLvalidation/8023.png\n",
            " inflated: BLvalidation/8024.png\n",
            " inflated: BLvalidation/8025.png\n",
            " inflated: BLvalidation/8026.png\n",
            " inflated: BLvalidation/8027.png\n",
            " inflated: BLvalidation/8028.png\n",
            " inflated: BLvalidation/8029.png\n",
            " inflated: BLvalidation/8030.png\n",
            " inflated: BLvalidation/8031.png\n",
            " inflated: BLvalidation/8032.png\n",
            " inflated: BLvalidation/8033.png\n",
            " inflated: BLvalidation/8034.png\n",
            " inflated: BLvalidation/8035.png\n",
            " inflated: BLvalidation/8036.png\n",
            " inflated: BLvalidation/8037.png\n",
            " inflated: BLvalidation/8038.png\n",
            " inflated: BLvalidation/8039.png\n",
            " inflated: BLvalidation/8040.png\n",
            " inflated: BLvalidation/8041.png\n",
            " inflated: BLvalidation/8042.png\n",
            " inflated: BLvalidation/8043.png\n",
            " inflated: BLvalidation/8044.png\n",
            " inflated: BLvalidation/8045.png\n",
            " inflated: BLvalidation/8046.png\n",
            " inflated: BLvalidation/8047.png\n",
            " inflated: BLvalidation/8048.png\n",
            " inflated: BLvalidation/8049.png\n",
            " inflated: BLvalidation/8050.png\n",
            " inflated: BLvalidation/8051.png\n",
            " inflated: BLvalidation/8052.png\n",
            " inflated: BLvalidation/8053.png\n",
            " inflated: BLvalidation/8054.png\n",
            " inflated: BLvalidation/8055.png\n",
            " inflated: BLvalidation/8056.png\n",
            " inflated: BLvalidation/8057.png\n",
            " inflated: BLvalidation/8058.png\n",
            " inflated: BLvalidation/8059.png\n",
            " inflated: BLvalidation/8060.png\n",
            " inflated: BLvalidation/8061.png\n",
            " inflated: BLvalidation/8062.png\n",
            " inflated: BLvalidation/8063.png\n",
            " inflated: BLvalidation/8064.png\n",
            " inflated: BLvalidation/8065.png\n",
            " inflated: BLvalidation/8066.png\n",
            " inflated: BLvalidation/8067.png\n",
            " inflated: BLvalidation/8068.png\n",
            " inflated: BLvalidation/8069.png\n",
            " inflated: BLvalidation/8070.png\n",
            " inflated: BLvalidation/8071.png\n",
            " inflated: BLvalidation/8072.png\n",
            " inflated: BLvalidation/8073.png\n",
            " inflated: BLvalidation/8074.png\n",
            " inflated: BLvalidation/8075.png\n",
            " inflated: BLvalidation/8076.png\n",
            " inflated: BLvalidation/8077.png\n",
            " inflated: BLvalidation/8078.png\n",
            " inflated: BLvalidation/8079.png\n",
            " inflated: BLvalidation/8080.png\n",
            " inflated: BLvalidation/8081.png\n",
            " inflated: BLvalidation/8082.png\n",
            " inflated: BLvalidation/8083.png\n",
            " inflated: BLvalidation/8084.png\n",
            " inflated: BLvalidation/8085.png\n",
            " inflated: BLvalidation/8086.png\n",
            " inflated: BLvalidation/8087.png\n",
            " inflated: BLvalidation/8088.png\n",
            " inflated: BLvalidation/8089.png\n",
            " inflated: BLvalidation/8090.png\n",
            " inflated: BLvalidation/8091.png\n",
            " inflated: BLvalidation/8092.png\n",
            " inflated: BLvalidation/8093.png\n",
            " inflated: BLvalidation/8094.png\n",
            " inflated: BLvalidation/8095.png\n",
            " inflated: BLvalidation/8096.png\n",
            " inflated: BLvalidation/8097.png\n",
            " inflated: BLvalidation/8098.png\n",
            " inflated: BLvalidation/8099.png\n",
            " inflated: BLvalidation/8100.png\n",
            " inflated: BLvalidation/8101.png\n",
            " inflated: BLvalidation/8102.png\n",
            " inflated: BLvalidation/8103.png\n",
            " inflated: BLvalidation/8104.png\n",
            " inflated: BLvalidation/8105.png\n",
            " inflated: BLvalidation/8106.png\n",
            " inflated: BLvalidation/8107.png\n",
            " inflated: BLvalidation/8108.png\n",
            " inflated: BLvalidation/8109.png\n",
            " inflated: BLvalidation/8110.png\n",
            " inflated: BLvalidation/8111.png\n",
            " inflated: BLvalidation/8112.png\n",
            " inflated: BLvalidation/8113.png\n",
            " inflated: BLvalidation/8114.png\n",
            " inflated: BLvalidation/8115.png\n",
            " inflated: BLvalidation/8116.png\n",
            " inflated: BLvalidation/8117.png\n",
            " inflated: BLvalidation/8118.png\n",
            " inflated: BLvalidation/8119.png\n",
            " inflated: BLvalidation/8120.png\n",
            " inflated: BLvalidation/8121.png\n",
            " inflated: BLvalidation/8122.png\n",
            " inflated: BLvalidation/8123.png\n",
            " inflated: BLvalidation/8124.png\n",
            " inflated: BLvalidation/8125.png\n",
            " inflated: BLvalidation/8126.png\n",
            " inflated: BLvalidation/8127.png\n",
            " inflated: BLvalidation/8128.png\n",
            " inflated: BLvalidation/8129.png\n",
            " inflated: BLvalidation/8130.png\n",
            " inflated: BLvalidation/8131.png\n",
            " inflated: BLvalidation/8132.png\n",
            " inflated: BLvalidation/8133.png\n",
            " inflated: BLvalidation/8134.png\n",
            " inflated: BLvalidation/8135.png\n",
            " inflated: BLvalidation/8136.png\n",
            " inflated: BLvalidation/8137.png\n",
            " inflated: BLvalidation/8138.png\n",
            " inflated: BLvalidation/8139.png\n",
            " inflated: BLvalidation/8140.png\n",
            " inflated: BLvalidation/8141.png\n",
            " inflated: BLvalidation/8142.png\n",
            " inflated: BLvalidation/8143.png\n",
            " inflated: BLvalidation/8144.png\n",
            " inflated: BLvalidation/8145.png\n",
            " inflated: BLvalidation/8146.png\n",
            " inflated: BLvalidation/8147.png\n",
            " inflated: BLvalidation/8148.png\n",
            " inflated: BLvalidation/8149.png\n",
            " inflated: BLvalidation/8150.png\n",
            " inflated: BLvalidation/8151.png\n",
            " inflated: BLvalidation/8152.png\n",
            " inflated: BLvalidation/8153.png\n",
            " inflated: BLvalidation/8154.png\n",
            " inflated: BLvalidation/8155.png\n",
            " inflated: BLvalidation/8156.png\n",
            " inflated: BLvalidation/8157.png\n",
            " inflated: BLvalidation/8158.png\n",
            " inflated: BLvalidation/8159.png\n",
            " inflated: BLvalidation/8160.png\n",
            " inflated: BLvalidation/8161.png\n",
            " inflated: BLvalidation/8162.png\n",
            " inflated: BLvalidation/8163.png\n",
            " inflated: BLvalidation/8164.png\n",
            " inflated: BLvalidation/8165.png\n",
            " inflated: BLvalidation/8166.png\n",
            " inflated: BLvalidation/8167.png\n",
            " inflated: BLvalidation/8168.png\n",
            " inflated: BLvalidation/8169.png\n",
            " inflated: BLvalidation/8170.png\n",
            " inflated: BLvalidation/8171.png\n",
            " inflated: BLvalidation/8172.png\n",
            " inflated: BLvalidation/8173.png\n",
            " inflated: BLvalidation/8174.png\n",
            " inflated: BLvalidation/8175.png\n",
            " inflated: BLvalidation/8176.png\n",
            " inflated: BLvalidation/8177.png\n",
            " inflated: BLvalidation/8178.png\n",
            " inflated: BLvalidation/8179.png\n",
            " inflated: BLvalidation/8180.png\n",
            " inflated: BLvalidation/8181.png\n",
            " inflated: BLvalidation/8182.png\n",
            " inflated: BLvalidation/8183.png\n",
            " inflated: BLvalidation/8184.png\n",
            " inflated: BLvalidation/8185.png\n",
            " inflated: BLvalidation/8186.png\n",
            " inflated: BLvalidation/8187.png\n",
            " inflated: BLvalidation/8188.png\n",
            " inflated: BLvalidation/8189.png\n",
            " inflated: BLvalidation/8190.png\n",
            " inflated: BLvalidation/8191.png\n",
            " inflated: BLvalidation/8192.png\n",
            " inflated: BLvalidation/8193.png\n",
            " inflated: BLvalidation/8194.png\n",
            " inflated: BLvalidation/8195.png\n",
            " inflated: BLvalidation/8196.png\n",
            " inflated: BLvalidation/8197.png\n",
            " inflated: BLvalidation/8198.png\n",
            " inflated: BLvalidation/8199.png\n",
            " inflated: BLvalidation/8200.png\n",
            " inflated: BLvalidation/8201.png\n",
            " inflated: BLvalidation/8202.png\n",
            " inflated: BLvalidation/8203.png\n",
            " inflated: BLvalidation/8204.png\n",
            " inflated: BLvalidation/8205.png\n",
            " inflated: BLvalidation/8206.png\n",
            " inflated: BLvalidation/8207.png\n",
            " inflated: BLvalidation/8208.png\n",
            " inflated: BLvalidation/8209.png\n",
            " inflated: BLvalidation/8210.png\n",
            " inflated: BLvalidation/8211.png\n",
            " inflated: BLvalidation/8212.png\n",
            " inflated: BLvalidation/8213.png\n",
            " inflated: BLvalidation/8214.png\n",
            " inflated: BLvalidation/8215.png\n",
            " inflated: BLvalidation/8216.png\n",
            " inflated: BLvalidation/8217.png\n",
            " inflated: BLvalidation/8218.png\n",
            " inflated: BLvalidation/8219.png\n",
            " inflated: BLvalidation/8220.png\n",
            " inflated: BLvalidation/8221.png\n",
            " inflated: BLvalidation/8222.png\n",
            " inflated: BLvalidation/8223.png\n",
            " inflated: BLvalidation/8224.png\n",
            " inflated: BLvalidation/8225.png\n",
            " inflated: BLvalidation/8226.png\n",
            " inflated: BLvalidation/8227.png\n",
            " inflated: BLvalidation/8228.png\n",
            " inflated: BLvalidation/8229.png\n",
            " inflated: BLvalidation/8230.png\n",
            " inflated: BLvalidation/8231.png\n",
            " inflated: BLvalidation/8232.png\n",
            " inflated: BLvalidation/8233.png\n",
            " inflated: BLvalidation/8234.png\n",
            " inflated: BLvalidation/8235.png\n",
            " inflated: BLvalidation/8236.png\n",
            " inflated: BLvalidation/8237.png\n",
            " inflated: BLvalidation/8238.png\n",
            " inflated: BLvalidation/8239.png\n",
            " inflated: BLvalidation/8240.png\n",
            " inflated: BLvalidation/8241.png\n",
            " inflated: BLvalidation/8242.png\n",
            " inflated: BLvalidation/8243.png\n",
            " inflated: BLvalidation/8244.png\n",
            " inflated: BLvalidation/8245.png\n",
            " inflated: BLvalidation/8246.png\n",
            " inflated: BLvalidation/8247.png\n",
            " inflated: BLvalidation/8248.png\n",
            " inflated: BLvalidation/8249.png\n",
            " inflated: BLvalidation/8250.png\n",
            " inflated: BLvalidation/8251.png\n",
            " inflated: BLvalidation/8252.png\n",
            " inflated: BLvalidation/8253.png\n",
            " inflated: BLvalidation/8254.png\n",
            " inflated: BLvalidation/8255.png\n",
            " inflated: BLvalidation/8256.png\n",
            " inflated: BLvalidation/8257.png\n",
            " inflated: BLvalidation/8258.png\n",
            " inflated: BLvalidation/8259.png\n",
            " inflated: BLvalidation/8260.png\n",
            " inflated: BLvalidation/8261.png\n",
            " inflated: BLvalidation/8262.png\n",
            " inflated: BLvalidation/8263.png\n",
            " inflated: BLvalidation/8264.png\n",
            " inflated: BLvalidation/8265.png\n",
            " inflated: BLvalidation/8266.png\n",
            " inflated: BLvalidation/8267.png\n",
            " inflated: BLvalidation/8268.png\n",
            " inflated: BLvalidation/8269.png\n",
            " inflated: BLvalidation/8270.png\n",
            " inflated: BLvalidation/8271.png\n",
            " inflated: BLvalidation/8272.png\n",
            " inflated: BLvalidation/8273.png\n",
            " inflated: BLvalidation/8274.png\n",
            " inflated: BLvalidation/8275.png\n",
            " inflated: BLvalidation/8276.png\n",
            " inflated: BLvalidation/8277.png\n",
            " inflated: BLvalidation/8278.png\n",
            " inflated: BLvalidation/8279.png\n",
            " inflated: BLvalidation/8280.png\n",
            " inflated: BLvalidation/8281.png\n",
            " inflated: BLvalidation/8282.png\n",
            " inflated: BLvalidation/8283.png\n",
            " inflated: BLvalidation/8284.png\n",
            " inflated: BLvalidation/8285.png\n",
            " inflated: BLvalidation/8286.png\n",
            " inflated: BLvalidation/8287.png\n",
            " inflated: BLvalidation/8288.png\n",
            " inflated: BLvalidation/8289.png\n",
            " inflated: BLvalidation/8290.png\n",
            " inflated: BLvalidation/8291.png\n",
            " inflated: BLvalidation/8292.png\n",
            " inflated: BLvalidation/8293.png\n",
            " inflated: BLvalidation/8294.png\n",
            " inflated: BLvalidation/8295.png\n",
            " inflated: BLvalidation/8296.png\n",
            " inflated: BLvalidation/8297.png\n",
            " inflated: BLvalidation/8298.png\n",
            " inflated: BLvalidation/8299.png\n",
            " inflated: BLvalidation/8300.png\n",
            " inflated: BLvalidation/8301.png\n",
            " inflated: BLvalidation/8302.png\n",
            " inflated: BLvalidation/8303.png\n",
            " inflated: BLvalidation/8304.png\n",
            " inflated: BLvalidation/8305.png\n",
            " inflated: BLvalidation/8306.png\n",
            " inflated: BLvalidation/8307.png\n",
            " inflated: BLvalidation/8308.png\n",
            " inflated: BLvalidation/8309.png\n",
            " inflated: BLvalidation/8310.png\n",
            " inflated: BLvalidation/8311.png\n",
            " inflated: BLvalidation/8312.png\n",
            " inflated: BLvalidation/8313.png\n",
            " inflated: BLvalidation/8314.png\n",
            " inflated: BLvalidation/8315.png\n",
            " inflated: BLvalidation/8316.png\n",
            " inflated: BLvalidation/8317.png\n",
            " inflated: BLvalidation/8318.png\n",
            " inflated: BLvalidation/8319.png\n",
            " inflated: BLvalidation/8320.png\n",
            " inflated: BLvalidation/8321.png\n",
            " inflated: BLvalidation/8322.png\n",
            " inflated: BLvalidation/8323.png\n",
            " inflated: BLvalidation/8324.png\n",
            " inflated: BLvalidation/8325.png\n",
            " inflated: BLvalidation/8326.png\n",
            " inflated: BLvalidation/8327.png\n",
            " inflated: BLvalidation/8328.png\n",
            " inflated: BLvalidation/8329.png\n",
            " inflated: BLvalidation/8330.png\n",
            " inflated: BLvalidation/8331.png\n",
            " inflated: BLvalidation/8332.png\n",
            " inflated: BLvalidation/8333.png\n",
            " inflated: BLvalidation/8334.png\n",
            " inflated: BLvalidation/8335.png\n",
            " inflated: BLvalidation/8336.png\n",
            " inflated: BLvalidation/8337.png\n",
            " inflated: BLvalidation/8338.png\n",
            " inflated: BLvalidation/8339.png\n",
            " inflated: BLvalidation/8340.png\n",
            " inflated: BLvalidation/8341.png\n",
            " inflated: BLvalidation/8342.png\n",
            " inflated: BLvalidation/8343.png\n",
            " inflated: BLvalidation/8344.png\n",
            " inflated: BLvalidation/8345.png\n",
            " inflated: BLvalidation/8346.png\n",
            " inflated: BLvalidation/8347.png\n",
            " inflated: BLvalidation/8348.png\n",
            " inflated: BLvalidation/8349.png\n",
            " inflated: BLvalidation/8350.png\n",
            " inflated: BLvalidation/8351.png\n",
            " inflated: BLvalidation/8352.png\n",
            " inflated: BLvalidation/8353.png\n",
            " inflated: BLvalidation/8354.png\n",
            " inflated: BLvalidation/8355.png\n",
            " inflated: BLvalidation/8356.png\n",
            " inflated: BLvalidation/8357.png\n",
            " inflated: BLvalidation/8358.png\n",
            " inflated: BLvalidation/8359.png\n",
            " inflated: BLvalidation/8360.png\n",
            " inflated: BLvalidation/8361.png\n",
            " inflated: BLvalidation/8362.png\n",
            " inflated: BLvalidation/8363.png\n",
            " inflated: BLvalidation/8364.png\n",
            " inflated: BLvalidation/8365.png\n",
            " inflated: BLvalidation/8366.png\n",
            " inflated: BLvalidation/8367.png\n",
            " inflated: BLvalidation/8368.png\n",
            " inflated: BLvalidation/8369.png\n",
            " inflated: BLvalidation/8370.png\n",
            " inflated: BLvalidation/8371.png\n",
            " inflated: BLvalidation/8372.png\n",
            " inflated: BLvalidation/8373.png\n",
            " inflated: BLvalidation/8374.png\n",
            " inflated: BLvalidation/8375.png\n",
            " inflated: BLvalidation/8376.png\n",
            " inflated: BLvalidation/8377.png\n",
            " inflated: BLvalidation/8378.png\n",
            " inflated: BLvalidation/8379.png\n",
            " inflated: BLvalidation/8380.png\n",
            " inflated: BLvalidation/8381.png\n",
            " inflated: BLvalidation/8382.png\n",
            " inflated: BLvalidation/8383.png\n",
            " inflated: BLvalidation/8384.png\n",
            " inflated: BLvalidation/8385.png\n",
            " inflated: BLvalidation/8386.png\n",
            " inflated: BLvalidation/8387.png\n",
            " inflated: BLvalidation/8388.png\n",
            " inflated: BLvalidation/8389.png\n",
            " inflated: BLvalidation/8390.png\n",
            " inflated: BLvalidation/8391.png\n",
            " inflated: BLvalidation/8392.png\n",
            " inflated: BLvalidation/8393.png\n",
            " inflated: BLvalidation/8394.png\n",
            " inflated: BLvalidation/8395.png\n",
            " inflated: BLvalidation/8396.png\n",
            " inflated: BLvalidation/8397.png\n",
            " inflated: BLvalidation/8398.png\n",
            " inflated: BLvalidation/8399.png\n",
            " inflated: BLvalidation/8400.png\n",
            " inflated: BLvalidation/8401.png\n",
            " inflated: BLvalidation/8402.png\n",
            " inflated: BLvalidation/8403.png\n",
            " inflated: BLvalidation/8404.png\n",
            " inflated: BLvalidation/8405.png\n",
            " inflated: BLvalidation/8406.png\n",
            " inflated: BLvalidation/8407.png\n",
            " inflated: BLvalidation/8408.png\n",
            " inflated: BLvalidation/8409.png\n",
            " inflated: BLvalidation/8410.png\n",
            " inflated: BLvalidation/8411.png\n",
            " inflated: BLvalidation/8412.png\n",
            " inflated: BLvalidation/8413.png\n",
            " inflated: BLvalidation/8414.png\n",
            " inflated: BLvalidation/8415.png\n",
            " inflated: BLvalidation/8416.png\n",
            " inflated: BLvalidation/8417.png\n",
            " inflated: BLvalidation/8418.png\n",
            " inflated: BLvalidation/8419.png\n",
            " inflated: BLvalidation/8420.png\n",
            " inflated: BLvalidation/8421.png\n",
            " inflated: BLvalidation/8422.png\n",
            " inflated: BLvalidation/8423.png\n",
            " inflated: BLvalidation/8424.png\n",
            " inflated: BLvalidation/8425.png\n",
            " inflated: BLvalidation/8426.png\n",
            " inflated: BLvalidation/8427.png\n",
            " inflated: BLvalidation/8428.png\n",
            " inflated: BLvalidation/8429.png\n",
            " inflated: BLvalidation/8430.png\n",
            " inflated: BLvalidation/8431.png\n",
            " inflated: BLvalidation/8432.png\n",
            " inflated: BLvalidation/8433.png\n",
            " inflated: BLvalidation/8434.png\n",
            " inflated: BLvalidation/8435.png\n",
            " inflated: BLvalidation/8436.png\n",
            " inflated: BLvalidation/8437.png\n",
            " inflated: BLvalidation/8438.png\n",
            " inflated: BLvalidation/8439.png\n",
            " inflated: BLvalidation/8440.png\n",
            " inflated: BLvalidation/8441.png\n",
            " inflated: BLvalidation/8442.png\n",
            " inflated: BLvalidation/8443.png\n",
            " inflated: BLvalidation/8444.png\n",
            " inflated: BLvalidation/8445.png\n",
            " inflated: BLvalidation/8446.png\n",
            " inflated: BLvalidation/8447.png\n",
            " inflated: BLvalidation/8448.png\n",
            " inflated: BLvalidation/8449.png\n",
            " inflated: BLvalidation/8450.png\n",
            " inflated: BLvalidation/8451.png\n",
            " inflated: BLvalidation/8452.png\n",
            " inflated: BLvalidation/8453.png\n",
            " inflated: BLvalidation/8454.png\n",
            " inflated: BLvalidation/8455.png\n",
            " inflated: BLvalidation/8456.png\n",
            " inflated: BLvalidation/8457.png\n",
            " inflated: BLvalidation/8458.png\n",
            " inflated: BLvalidation/8459.png\n",
            " inflated: BLvalidation/8460.png\n",
            " inflated: BLvalidation/8461.png\n",
            " inflated: BLvalidation/8462.png\n",
            " inflated: BLvalidation/8463.png\n",
            " inflated: BLvalidation/8464.png\n",
            " inflated: BLvalidation/8465.png\n",
            " inflated: BLvalidation/8466.png\n",
            " inflated: BLvalidation/8467.png\n",
            " inflated: BLvalidation/8468.png\n",
            " inflated: BLvalidation/8469.png\n",
            " inflated: BLvalidation/8470.png\n",
            " inflated: BLvalidation/8471.png\n",
            " inflated: BLvalidation/8472.png\n",
            " inflated: BLvalidation/8473.png\n",
            " inflated: BLvalidation/8474.png\n",
            " inflated: BLvalidation/8475.png\n",
            " inflated: BLvalidation/8476.png\n",
            " inflated: BLvalidation/8477.png\n",
            " inflated: BLvalidation/8478.png\n",
            " inflated: BLvalidation/8479.png\n",
            " inflated: BLvalidation/8480.png\n",
            " inflated: BLvalidation/8481.png\n",
            " inflated: BLvalidation/8482.png\n",
            " inflated: BLvalidation/8483.png\n",
            " inflated: BLvalidation/8484.png\n",
            " inflated: BLvalidation/8485.png\n",
            " inflated: BLvalidation/8486.png\n",
            " inflated: BLvalidation/8487.png\n",
            " inflated: BLvalidation/8488.png\n",
            " inflated: BLvalidation/8489.png\n",
            " inflated: BLvalidation/8490.png\n",
            " inflated: BLvalidation/8491.png\n",
            " inflated: BLvalidation/8492.png\n",
            " inflated: BLvalidation/8493.png\n",
            " inflated: BLvalidation/8494.png\n",
            " inflated: BLvalidation/8495.png\n",
            " inflated: BLvalidation/8496.png\n",
            " inflated: BLvalidation/8497.png\n",
            " inflated: BLvalidation/8498.png\n",
            " inflated: BLvalidation/8499.png\n",
            " inflated: BLvalidation/8500.png\n",
            " inflated: BLvalidation/8501.png\n",
            " inflated: BLvalidation/8502.png\n",
            " inflated: BLvalidation/8503.png\n",
            " inflated: BLvalidation/8504.png\n",
            " inflated: BLvalidation/8505.png\n",
            " inflated: BLvalidation/8506.png\n",
            " inflated: BLvalidation/8507.png\n",
            " inflated: BLvalidation/8508.png\n",
            " inflated: BLvalidation/8509.png\n",
            " inflated: BLvalidation/8510.png\n",
            " inflated: BLvalidation/8511.png\n",
            " inflated: BLvalidation/8512.png\n",
            " inflated: BLvalidation/8513.png\n",
            " inflated: BLvalidation/8514.png\n",
            " inflated: BLvalidation/8515.png\n",
            " inflated: BLvalidation/8516.png\n",
            " inflated: BLvalidation/8517.png\n",
            " inflated: BLvalidation/8518.png\n",
            " inflated: BLvalidation/8519.png\n",
            " inflated: BLvalidation/8520.png\n",
            " inflated: BLvalidation/8521.png\n",
            " inflated: BLvalidation/8522.png\n",
            " inflated: BLvalidation/8523.png\n",
            " inflated: BLvalidation/8524.png\n",
            " inflated: BLvalidation/8525.png\n",
            " inflated: BLvalidation/8526.png\n",
            " inflated: BLvalidation/8527.png\n",
            " inflated: BLvalidation/8528.png\n",
            " inflated: BLvalidation/8529.png\n",
            " inflated: BLvalidation/8530.png\n",
            " inflated: BLvalidation/8531.png\n",
            " inflated: BLvalidation/8532.png\n",
            " inflated: BLvalidation/8533.png\n",
            " inflated: BLvalidation/8534.png\n",
            " inflated: BLvalidation/8535.png\n",
            " inflated: BLvalidation/8536.png\n",
            " inflated: BLvalidation/8537.png\n",
            " inflated: BLvalidation/8538.png\n",
            " inflated: BLvalidation/8539.png\n",
            " inflated: BLvalidation/8540.png\n",
            " inflated: BLvalidation/8541.png\n",
            " inflated: BLvalidation/8542.png\n",
            " inflated: BLvalidation/8543.png\n",
            " inflated: BLvalidation/8544.png\n",
            " inflated: BLvalidation/8545.png\n",
            " inflated: BLvalidation/8546.png\n",
            " inflated: BLvalidation/8547.png\n",
            " inflated: BLvalidation/8548.png\n",
            " inflated: BLvalidation/8549.png\n",
            " inflated: BLvalidation/8550.png\n",
            " inflated: BLvalidation/8551.png\n",
            " inflated: BLvalidation/8552.png\n",
            " inflated: BLvalidation/8553.png\n",
            " inflated: BLvalidation/8554.png\n",
            " inflated: BLvalidation/8555.png\n",
            " inflated: BLvalidation/8556.png\n",
            " inflated: BLvalidation/8557.png\n",
            " inflated: BLvalidation/8558.png\n",
            " inflated: BLvalidation/8559.png\n",
            " inflated: BLvalidation/8560.png\n",
            " inflated: BLvalidation/8561.png\n",
            " inflated: BLvalidation/8562.png\n",
            " inflated: BLvalidation/8563.png\n",
            " inflated: BLvalidation/8564.png\n",
            " inflated: BLvalidation/8565.png\n",
            " inflated: BLvalidation/8566.png\n",
            " inflated: BLvalidation/8567.png\n",
            " inflated: BLvalidation/8568.png\n",
            " inflated: BLvalidation/8569.png\n",
            " inflated: BLvalidation/8570.png\n",
            " inflated: BLvalidation/8571.png\n",
            " inflated: BLvalidation/8572.png\n",
            " inflated: BLvalidation/8573.png\n",
            " inflated: BLvalidation/8574.png\n",
            " inflated: BLvalidation/8575.png\n",
            " inflated: BLvalidation/8576.png\n",
            " inflated: BLvalidation/8577.png\n",
            " inflated: BLvalidation/8578.png\n",
            " inflated: BLvalidation/8579.png\n",
            " inflated: BLvalidation/8580.png\n",
            " inflated: BLvalidation/8581.png\n",
            " inflated: BLvalidation/8582.png\n",
            " inflated: BLvalidation/8583.png\n",
            " inflated: BLvalidation/8584.png\n",
            " inflated: BLvalidation/8585.png\n",
            " inflated: BLvalidation/8586.png\n",
            " inflated: BLvalidation/8587.png\n",
            " inflated: BLvalidation/8588.png\n",
            " inflated: BLvalidation/8589.png\n",
            " inflated: BLvalidation/8590.png\n",
            " inflated: BLvalidation/8591.png\n",
            " inflated: BLvalidation/8592.png\n",
            " inflated: BLvalidation/8593.png\n",
            " inflated: BLvalidation/8594.png\n",
            " inflated: BLvalidation/8595.png\n",
            " inflated: BLvalidation/8596.png\n",
            " inflated: BLvalidation/8597.png\n",
            " inflated: BLvalidation/8598.png\n",
            " inflated: BLvalidation/8599.png\n",
            " inflated: BLvalidation/8600.png\n",
            " inflated: BLvalidation/8601.png\n",
            " inflated: BLvalidation/8602.png\n",
            " inflated: BLvalidation/8603.png\n",
            " inflated: BLvalidation/8604.png\n",
            " inflated: BLvalidation/8605.png\n",
            " inflated: BLvalidation/8606.png\n",
            " inflated: BLvalidation/8607.png\n",
            " inflated: BLvalidation/8608.png\n",
            " inflated: BLvalidation/8609.png\n",
            " inflated: BLvalidation/8610.png\n",
            " inflated: BLvalidation/8611.png\n",
            " inflated: BLvalidation/8612.png\n",
            " inflated: BLvalidation/8613.png\n",
            " inflated: BLvalidation/8614.png\n",
            " inflated: BLvalidation/8615.png\n",
            " inflated: BLvalidation/8616.png\n",
            " inflated: BLvalidation/8617.png\n",
            " inflated: BLvalidation/8618.png\n",
            " inflated: BLvalidation/8619.png\n",
            " inflated: BLvalidation/8620.png\n",
            " inflated: BLvalidation/8621.png\n",
            " inflated: BLvalidation/8622.png\n",
            " inflated: BLvalidation/8623.png\n",
            " inflated: BLvalidation/8624.png\n",
            " inflated: BLvalidation/8625.png\n",
            " inflated: BLvalidation/8626.png\n",
            " inflated: BLvalidation/8627.png\n",
            " inflated: BLvalidation/8628.png\n",
            " inflated: BLvalidation/8629.png\n",
            " inflated: BLvalidation/8630.png\n",
            " inflated: BLvalidation/8631.png\n",
            " inflated: BLvalidation/8632.png\n",
            " inflated: BLvalidation/8633.png\n",
            " inflated: BLvalidation/8634.png\n",
            " inflated: BLvalidation/8635.png\n",
            " inflated: BLvalidation/8636.png\n",
            " inflated: BLvalidation/8637.png\n",
            " inflated: BLvalidation/8638.png\n",
            " inflated: BLvalidation/8639.png\n",
            " inflated: BLvalidation/8640.png\n",
            " inflated: BLvalidation/8641.png\n",
            " inflated: BLvalidation/8642.png\n",
            " inflated: BLvalidation/8643.png\n",
            " inflated: BLvalidation/8644.png\n",
            " inflated: BLvalidation/8645.png\n",
            " inflated: BLvalidation/8646.png\n",
            " inflated: BLvalidation/8647.png\n",
            " inflated: BLvalidation/8648.png\n",
            " inflated: BLvalidation/8649.png\n",
            " inflated: BLvalidation/8650.png\n",
            " inflated: BLvalidation/8651.png\n",
            " inflated: BLvalidation/8652.png\n",
            " inflated: BLvalidation/8653.png\n",
            " inflated: BLvalidation/8654.png\n",
            " inflated: BLvalidation/8655.png\n",
            " inflated: BLvalidation/8656.png\n",
            " inflated: BLvalidation/8657.png\n",
            " inflated: BLvalidation/8658.png\n",
            " inflated: BLvalidation/8659.png\n",
            " inflated: BLvalidation/8660.png\n",
            " inflated: BLvalidation/8661.png\n",
            " inflated: BLvalidation/8662.png\n",
            " inflated: BLvalidation/8663.png\n",
            " inflated: BLvalidation/8664.png\n",
            " inflated: BLvalidation/8665.png\n",
            " inflated: BLvalidation/8666.png\n",
            " inflated: BLvalidation/8667.png\n",
            " inflated: BLvalidation/8668.png\n",
            " inflated: BLvalidation/8669.png\n",
            " inflated: BLvalidation/8670.png\n",
            " inflated: BLvalidation/8671.png\n",
            " inflated: BLvalidation/8672.png\n",
            " inflated: BLvalidation/8673.png\n",
            " inflated: BLvalidation/8674.png\n",
            " inflated: BLvalidation/8675.png\n",
            " inflated: BLvalidation/8676.png\n",
            " inflated: BLvalidation/8677.png\n",
            " inflated: BLvalidation/8678.png\n",
            " inflated: BLvalidation/8679.png\n",
            " inflated: BLvalidation/8680.png\n",
            " inflated: BLvalidation/8681.png\n",
            " inflated: BLvalidation/8682.png\n",
            " inflated: BLvalidation/8683.png\n",
            " inflated: BLvalidation/8684.png\n",
            " inflated: BLvalidation/8685.png\n",
            " inflated: BLvalidation/8686.png\n",
            " inflated: BLvalidation/8687.png\n",
            " inflated: BLvalidation/8688.png\n",
            " inflated: BLvalidation/8689.png\n",
            " inflated: BLvalidation/8690.png\n",
            " inflated: BLvalidation/8691.png\n",
            " inflated: BLvalidation/8692.png\n",
            " inflated: BLvalidation/8693.png\n",
            " inflated: BLvalidation/8694.png\n",
            " inflated: BLvalidation/8695.png\n",
            " inflated: BLvalidation/8696.png\n",
            " inflated: BLvalidation/8697.png\n",
            " inflated: BLvalidation/8698.png\n",
            " inflated: BLvalidation/8699.png\n",
            " inflated: BLvalidation/8700.png\n",
            " inflated: BLvalidation/8701.png\n",
            " inflated: BLvalidation/8702.png\n",
            " inflated: BLvalidation/8703.png\n",
            " inflated: BLvalidation/8704.png\n",
            " inflated: BLvalidation/8705.png\n",
            " inflated: BLvalidation/8706.png\n",
            " inflated: BLvalidation/8707.png\n",
            " inflated: BLvalidation/8708.png\n",
            " inflated: BLvalidation/8709.png\n",
            " inflated: BLvalidation/8710.png\n",
            " inflated: BLvalidation/8711.png\n",
            " inflated: BLvalidation/8712.png\n",
            " inflated: BLvalidation/8713.png\n",
            " inflated: BLvalidation/8714.png\n",
            " inflated: BLvalidation/8715.png\n",
            " inflated: BLvalidation/8716.png\n",
            " inflated: BLvalidation/8717.png\n",
            " inflated: BLvalidation/8718.png\n",
            " inflated: BLvalidation/8719.png\n",
            " inflated: BLvalidation/8720.png\n",
            " inflated: BLvalidation/8721.png\n",
            " inflated: BLvalidation/8722.png\n",
            " inflated: BLvalidation/8723.png\n",
            " inflated: BLvalidation/8724.png\n",
            " inflated: BLvalidation/8725.png\n",
            " inflated: BLvalidation/8726.png\n",
            " inflated: BLvalidation/8727.png\n",
            " inflated: BLvalidation/8728.png\n",
            " inflated: BLvalidation/8729.png\n",
            " inflated: BLvalidation/8730.png\n",
            " inflated: BLvalidation/8731.png\n",
            " inflated: BLvalidation/8732.png\n",
            " inflated: BLvalidation/8733.png\n",
            " inflated: BLvalidation/8734.png\n",
            " inflated: BLvalidation/8735.png\n",
            " inflated: BLvalidation/8736.png\n",
            " inflated: BLvalidation/8737.png\n",
            " inflated: BLvalidation/8738.png\n",
            " inflated: BLvalidation/8739.png\n",
            " inflated: BLvalidation/8740.png\n",
            " inflated: BLvalidation/8741.png\n",
            " inflated: BLvalidation/8742.png\n",
            " inflated: BLvalidation/8743.png\n",
            " inflated: BLvalidation/8744.png\n",
            " inflated: BLvalidation/8745.png\n",
            " inflated: BLvalidation/8746.png\n",
            " inflated: BLvalidation/8747.png\n",
            " inflated: BLvalidation/8748.png\n",
            " inflated: BLvalidation/8749.png\n",
            " inflated: BLvalidation/8750.png\n",
            " inflated: BLvalidation/8751.png\n",
            " inflated: BLvalidation/8752.png\n",
            " inflated: BLvalidation/8753.png\n",
            " inflated: BLvalidation/8754.png\n",
            " inflated: BLvalidation/8755.png\n",
            " inflated: BLvalidation/8756.png\n",
            " inflated: BLvalidation/8757.png\n",
            " inflated: BLvalidation/8758.png\n",
            " inflated: BLvalidation/8759.png\n",
            " inflated: BLvalidation/8760.png\n",
            " inflated: BLvalidation/8761.png\n",
            " inflated: BLvalidation/8762.png\n",
            " inflated: BLvalidation/8763.png\n",
            " inflated: BLvalidation/8764.png\n",
            " inflated: BLvalidation/8765.png\n",
            " inflated: BLvalidation/8766.png\n",
            " inflated: BLvalidation/8767.png\n",
            " inflated: BLvalidation/8768.png\n",
            " inflated: BLvalidation/8769.png\n",
            " inflated: BLvalidation/8770.png\n",
            " inflated: BLvalidation/8771.png\n",
            " inflated: BLvalidation/8772.png\n",
            " inflated: BLvalidation/8773.png\n",
            " inflated: BLvalidation/8774.png\n",
            " inflated: BLvalidation/8775.png\n",
            " inflated: BLvalidation/8776.png\n",
            " inflated: BLvalidation/8777.png\n",
            " inflated: BLvalidation/8778.png\n",
            " inflated: BLvalidation/8779.png\n",
            " inflated: BLvalidation/8780.png\n",
            " inflated: BLvalidation/8781.png\n",
            " inflated: BLvalidation/8782.png\n",
            " inflated: BLvalidation/8783.png\n",
            " inflated: BLvalidation/8784.png\n",
            " inflated: BLvalidation/8785.png\n",
            " inflated: BLvalidation/8786.png\n",
            " inflated: BLvalidation/8787.png\n",
            " inflated: BLvalidation/8788.png\n",
            " inflated: BLvalidation/8789.png\n",
            " inflated: BLvalidation/8790.png\n",
            " inflated: BLvalidation/8791.png\n",
            " inflated: BLvalidation/8792.png\n",
            " inflated: BLvalidation/8793.png\n",
            " inflated: BLvalidation/8794.png\n",
            " inflated: BLvalidation/8795.png\n",
            " inflated: BLvalidation/8796.png\n",
            " inflated: BLvalidation/8797.png\n",
            " inflated: BLvalidation/8798.png\n",
            " inflated: BLvalidation/8799.png\n",
            " inflated: BLvalidation/8800.png\n",
            " inflated: BLvalidation/8801.png\n",
            " inflated: BLvalidation/8802.png\n",
            " inflated: BLvalidation/8803.png\n",
            " inflated: BLvalidation/8804.png\n",
            " inflated: BLvalidation/8805.png\n",
            " inflated: BLvalidation/8806.png\n",
            " inflated: BLvalidation/8807.png\n",
            " inflated: BLvalidation/8808.png\n",
            " inflated: BLvalidation/8809.png\n",
            " inflated: BLvalidation/8810.png\n",
            " inflated: BLvalidation/8811.png\n",
            " inflated: BLvalidation/8812.png\n",
            " inflated: BLvalidation/8813.png\n",
            " inflated: BLvalidation/8814.png\n",
            " inflated: BLvalidation/8815.png\n",
            " inflated: BLvalidation/8816.png\n",
            " inflated: BLvalidation/8817.png\n",
            " inflated: BLvalidation/8818.png\n",
            " inflated: BLvalidation/8819.png\n",
            " inflated: BLvalidation/8820.png\n",
            " inflated: BLvalidation/8821.png\n",
            " inflated: BLvalidation/8822.png\n",
            " inflated: BLvalidation/8823.png\n",
            " inflated: BLvalidation/8824.png\n",
            " inflated: BLvalidation/8825.png\n",
            " inflated: BLvalidation/8826.png\n",
            " inflated: BLvalidation/8827.png\n",
            " inflated: BLvalidation/8828.png\n",
            " inflated: BLvalidation/8829.png\n",
            " inflated: BLvalidation/8830.png\n",
            " inflated: BLvalidation/8831.png\n",
            " inflated: BLvalidation/8832.png\n",
            " inflated: BLvalidation/8833.png\n",
            " inflated: BLvalidation/8834.png\n",
            " inflated: BLvalidation/8835.png\n",
            " inflated: BLvalidation/8836.png\n",
            " inflated: BLvalidation/8837.png\n",
            " inflated: BLvalidation/8838.png\n",
            " inflated: BLvalidation/8839.png\n",
            " inflated: BLvalidation/8840.png\n",
            " inflated: BLvalidation/8841.png\n",
            " inflated: BLvalidation/8842.png\n",
            " inflated: BLvalidation/8843.png\n",
            " inflated: BLvalidation/8844.png\n",
            " inflated: BLvalidation/8845.png\n",
            " inflated: BLvalidation/8846.png\n",
            " inflated: BLvalidation/8847.png\n",
            " inflated: BLvalidation/8848.png\n",
            " inflated: BLvalidation/8849.png\n",
            " inflated: BLvalidation/8850.png\n",
            " inflated: BLvalidation/8851.png\n",
            " inflated: BLvalidation/8852.png\n",
            " inflated: BLvalidation/8853.png\n",
            " inflated: BLvalidation/8854.png\n",
            " inflated: BLvalidation/8855.png\n",
            " inflated: BLvalidation/8856.png\n",
            " inflated: BLvalidation/8857.png\n",
            " inflated: BLvalidation/8858.png\n",
            " inflated: BLvalidation/8859.png\n",
            " inflated: BLvalidation/8860.png\n",
            " inflated: BLvalidation/8861.png\n",
            " inflated: BLvalidation/8862.png\n",
            " inflated: BLvalidation/8863.png\n",
            " inflated: BLvalidation/8864.png\n",
            " inflated: BLvalidation/8865.png\n",
            " inflated: BLvalidation/8866.png\n",
            " inflated: BLvalidation/8867.png\n",
            " inflated: BLvalidation/8868.png\n",
            " inflated: BLvalidation/8869.png\n",
            " inflated: BLvalidation/8870.png\n",
            " inflated: BLvalidation/8871.png\n",
            " inflated: BLvalidation/8872.png\n",
            " inflated: BLvalidation/8873.png\n",
            " inflated: BLvalidation/8874.png\n",
            " inflated: BLvalidation/8875.png\n",
            " inflated: BLvalidation/8876.png\n",
            " inflated: BLvalidation/8877.png\n",
            " inflated: BLvalidation/8878.png\n",
            " inflated: BLvalidation/8879.png\n",
            " inflated: BLvalidation/8880.png\n",
            " inflated: BLvalidation/8881.png\n",
            " inflated: BLvalidation/8882.png\n",
            " inflated: BLvalidation/8883.png\n",
            " inflated: BLvalidation/8884.png\n",
            " inflated: BLvalidation/8885.png\n",
            " inflated: BLvalidation/8886.png\n",
            " inflated: BLvalidation/8887.png\n",
            " inflated: BLvalidation/8888.png\n",
            " inflated: BLvalidation/8889.png\n",
            " inflated: BLvalidation/8890.png\n",
            " inflated: BLvalidation/8891.png\n",
            " inflated: BLvalidation/8892.png\n",
            " inflated: BLvalidation/8893.png\n",
            " inflated: BLvalidation/8894.png\n",
            " inflated: BLvalidation/8895.png\n",
            " inflated: BLvalidation/8896.png\n",
            " inflated: BLvalidation/8897.png\n",
            " inflated: BLvalidation/8898.png\n",
            " inflated: BLvalidation/8899.png\n",
            " inflated: BLvalidation/8900.png\n",
            " inflated: BLvalidation/8901.png\n",
            " inflated: BLvalidation/8902.png\n",
            " inflated: BLvalidation/8903.png\n",
            " inflated: BLvalidation/8904.png\n",
            " inflated: BLvalidation/8905.png\n",
            " inflated: BLvalidation/8906.png\n",
            " inflated: BLvalidation/8907.png\n",
            " inflated: BLvalidation/8908.png\n",
            " inflated: BLvalidation/8909.png\n",
            " inflated: BLvalidation/8910.png\n",
            " inflated: BLvalidation/8911.png\n",
            " inflated: BLvalidation/8912.png\n",
            " inflated: BLvalidation/8913.png\n",
            " inflated: BLvalidation/8914.png\n",
            " inflated: BLvalidation/8915.png\n",
            " inflated: BLvalidation/8916.png\n",
            " inflated: BLvalidation/8917.png\n",
            " inflated: BLvalidation/8918.png\n",
            " inflated: BLvalidation/8919.png\n",
            " inflated: BLvalidation/8920.png\n",
            " inflated: BLvalidation/8921.png\n",
            " inflated: BLvalidation/8922.png\n",
            " inflated: BLvalidation/8923.png\n",
            " inflated: BLvalidation/8924.png\n",
            " inflated: BLvalidation/8925.png\n",
            " inflated: BLvalidation/8926.png\n",
            " inflated: BLvalidation/8927.png\n",
            " inflated: BLvalidation/8928.png\n",
            " inflated: BLvalidation/8929.png\n",
            " inflated: BLvalidation/8930.png\n",
            " inflated: BLvalidation/8931.png\n",
            " inflated: BLvalidation/8932.png\n",
            " inflated: BLvalidation/8933.png\n",
            " inflated: BLvalidation/8934.png\n",
            " inflated: BLvalidation/8935.png\n",
            " inflated: BLvalidation/8936.png\n",
            " inflated: BLvalidation/8937.png\n",
            " inflated: BLvalidation/8938.png\n",
            " inflated: BLvalidation/8939.png\n",
            " inflated: BLvalidation/8940.png\n",
            " inflated: BLvalidation/8941.png\n",
            " inflated: BLvalidation/8942.png\n",
            " inflated: BLvalidation/8943.png\n",
            " inflated: BLvalidation/8944.png\n",
            " inflated: BLvalidation/8945.png\n",
            " inflated: BLvalidation/8946.png\n",
            " inflated: BLvalidation/8947.png\n",
            " inflated: BLvalidation/8948.png\n",
            " inflated: BLvalidation/8949.png\n",
            " inflated: BLvalidation/8950.png\n",
            " inflated: BLvalidation/8951.png\n",
            " inflated: BLvalidation/8952.png\n",
            " inflated: BLvalidation/8953.png\n",
            " inflated: BLvalidation/8954.png\n",
            " inflated: BLvalidation/8955.png\n",
            " inflated: BLvalidation/8956.png\n",
            " inflated: BLvalidation/8957.png\n",
            " inflated: BLvalidation/8958.png\n",
            " inflated: BLvalidation/8959.png\n",
            " inflated: BLvalidation/8960.png\n",
            " inflated: BLvalidation/8961.png\n",
            " inflated: BLvalidation/8962.png\n",
            " inflated: BLvalidation/8963.png\n",
            " inflated: BLvalidation/8964.png\n",
            " inflated: BLvalidation/8965.png\n",
            " inflated: BLvalidation/8966.png\n",
            " inflated: BLvalidation/8967.png\n",
            " inflated: BLvalidation/8968.png\n",
            " inflated: BLvalidation/8969.png\n",
            " inflated: BLvalidation/8970.png\n",
            " inflated: BLvalidation/8971.png\n",
            " inflated: BLvalidation/8972.png\n",
            " inflated: BLvalidation/8973.png\n",
            " inflated: BLvalidation/8974.png\n",
            " inflated: BLvalidation/8975.png\n",
            " inflated: BLvalidation/8976.png\n",
            " inflated: BLvalidation/8977.png\n",
            " inflated: BLvalidation/8978.png\n",
            " inflated: BLvalidation/8979.png\n",
            " inflated: BLvalidation/8980.png\n",
            " inflated: BLvalidation/8981.png\n",
            " inflated: BLvalidation/8982.png\n",
            " inflated: BLvalidation/8983.png\n",
            " inflated: BLvalidation/8984.png\n",
            " inflated: BLvalidation/8985.png\n",
            " inflated: BLvalidation/8986.png\n",
            " inflated: BLvalidation/8987.png\n",
            " inflated: BLvalidation/8988.png\n",
            " inflated: BLvalidation/8989.png\n",
            " inflated: BLvalidation/8990.png\n",
            " inflated: BLvalidation/8991.png\n",
            " inflated: BLvalidation/8992.png\n",
            " inflated: BLvalidation/8993.png\n",
            " inflated: BLvalidation/8994.png\n",
            " inflated: BLvalidation/8995.png\n",
            " inflated: BLvalidation/8996.png\n",
            " inflated: BLvalidation/8997.png\n",
            " inflated: BLvalidation/8998.png\n",
            " inflated: BLvalidation/8999.png\n",
            " inflated: BLvalidation/9000.png\n",
            " inflated: BLvalidation/9001.png\n",
            " inflated: BLvalidation/9002.png\n",
            " inflated: BLvalidation/9003.png\n",
            " inflated: BLvalidation/9004.png\n",
            " inflated: BLvalidation/9005.png\n",
            " inflated: BLvalidation/9006.png\n",
            " inflated: BLvalidation/9007.png\n",
            " inflated: BLvalidation/9008.png\n",
            " inflated: BLvalidation/9009.png\n",
            " inflated: BLvalidation/9010.png\n",
            " inflated: BLvalidation/9011.png\n",
            " inflated: BLvalidation/9012.png\n",
            " inflated: BLvalidation/9013.png\n",
            " inflated: BLvalidation/9014.png\n",
            " inflated: BLvalidation/9015.png\n",
            " inflated: BLvalidation/9016.png\n",
            " inflated: BLvalidation/9017.png\n",
            " inflated: BLvalidation/9018.png\n",
            " inflated: BLvalidation/9019.png\n",
            " inflated: BLvalidation/9020.png\n",
            " inflated: BLvalidation/9021.png\n",
            " inflated: BLvalidation/9022.png\n",
            " inflated: BLvalidation/9023.png\n",
            " inflated: BLvalidation/9024.png\n",
            " inflated: BLvalidation/9025.png\n",
            " inflated: BLvalidation/9026.png\n",
            " inflated: BLvalidation/9027.png\n",
            " inflated: BLvalidation/9028.png\n",
            " inflated: BLvalidation/9029.png\n",
            " inflated: BLvalidation/9030.png\n",
            " inflated: BLvalidation/9031.png\n",
            " inflated: BLvalidation/9032.png\n",
            " inflated: BLvalidation/9033.png\n",
            " inflated: BLvalidation/9034.png\n",
            " inflated: BLvalidation/9035.png\n",
            " inflated: BLvalidation/9036.png\n",
            " inflated: BLvalidation/9037.png\n",
            " inflated: BLvalidation/9038.png\n",
            " inflated: BLvalidation/9039.png\n",
            " inflated: BLvalidation/9040.png\n",
            " inflated: BLvalidation/9041.png\n",
            " inflated: BLvalidation/9042.png\n",
            " inflated: BLvalidation/9043.png\n",
            " inflated: BLvalidation/9044.png\n",
            " inflated: BLvalidation/9045.png\n",
            " inflated: BLvalidation/9046.png\n",
            " inflated: BLvalidation/9047.png\n",
            " inflated: BLvalidation/9048.png\n",
            " inflated: BLvalidation/9049.png\n",
            " inflated: BLvalidation/9050.png\n",
            " inflated: BLvalidation/9051.png\n",
            " inflated: BLvalidation/9052.png\n",
            " inflated: BLvalidation/9053.png\n",
            " inflated: BLvalidation/9054.png\n",
            " inflated: BLvalidation/9055.png\n",
            " inflated: BLvalidation/9056.png\n",
            " inflated: BLvalidation/9057.png\n",
            " inflated: BLvalidation/9058.png\n",
            " inflated: BLvalidation/9059.png\n",
            " inflated: BLvalidation/9060.png\n",
            " inflated: BLvalidation/9061.png\n",
            " inflated: BLvalidation/9062.png\n",
            " inflated: BLvalidation/9063.png\n",
            " inflated: BLvalidation/9064.png\n",
            " inflated: BLvalidation/9065.png\n",
            " inflated: BLvalidation/9066.png\n",
            " inflated: BLvalidation/9067.png\n",
            " inflated: BLvalidation/9068.png\n",
            " inflated: BLvalidation/9069.png\n",
            " inflated: BLvalidation/9070.png\n",
            " inflated: BLvalidation/9071.png\n",
            " inflated: BLvalidation/9072.png\n",
            " inflated: BLvalidation/9073.png\n",
            " inflated: BLvalidation/9074.png\n",
            " inflated: BLvalidation/9075.png\n",
            " inflated: BLvalidation/9076.png\n",
            " inflated: BLvalidation/9077.png\n",
            " inflated: BLvalidation/9078.png\n",
            " inflated: BLvalidation/9079.png\n",
            " inflated: BLvalidation/9080.png\n",
            " inflated: BLvalidation/9081.png\n",
            " inflated: BLvalidation/9082.png\n",
            " inflated: BLvalidation/9083.png\n",
            " inflated: BLvalidation/9084.png\n",
            " inflated: BLvalidation/9085.png\n",
            " inflated: BLvalidation/9086.png\n",
            " inflated: BLvalidation/9087.png\n",
            " inflated: BLvalidation/9088.png\n",
            " inflated: BLvalidation/9089.png\n",
            " inflated: BLvalidation/9090.png\n",
            " inflated: BLvalidation/9091.png\n",
            " inflated: BLvalidation/9092.png\n",
            " inflated: BLvalidation/9093.png\n",
            " inflated: BLvalidation/9094.png\n",
            " inflated: BLvalidation/9095.png\n",
            " inflated: BLvalidation/9096.png\n",
            " inflated: BLvalidation/9097.png\n",
            " inflated: BLvalidation/9098.png\n",
            " inflated: BLvalidation/9099.png\n",
            " inflated: BLvalidation/9100.png\n",
            " inflated: BLvalidation/9101.png\n",
            " inflated: BLvalidation/9102.png\n",
            " inflated: BLvalidation/9103.png\n",
            " inflated: BLvalidation/9104.png\n",
            " inflated: BLvalidation/9105.png\n",
            " inflated: BLvalidation/9106.png\n",
            " inflated: BLvalidation/9107.png\n",
            " inflated: BLvalidation/9108.png\n",
            " inflated: BLvalidation/9109.png\n",
            " inflated: BLvalidation/9110.png\n",
            " inflated: BLvalidation/9111.png\n",
            " inflated: BLvalidation/9112.png\n",
            " inflated: BLvalidation/9113.png\n",
            " inflated: BLvalidation/9114.png\n",
            " inflated: BLvalidation/9115.png\n",
            " inflated: BLvalidation/9116.png\n",
            " inflated: BLvalidation/9117.png\n",
            " inflated: BLvalidation/9118.png\n",
            " inflated: BLvalidation/9119.png\n",
            " inflated: BLvalidation/9120.png\n",
            " inflated: BLvalidation/9121.png\n",
            " inflated: BLvalidation/9122.png\n",
            " inflated: BLvalidation/9123.png\n",
            " inflated: BLvalidation/9124.png\n",
            " inflated: BLvalidation/9125.png\n",
            " inflated: BLvalidation/9126.png\n",
            " inflated: BLvalidation/9127.png\n",
            " inflated: BLvalidation/9128.png\n",
            " inflated: BLvalidation/9129.png\n",
            " inflated: BLvalidation/9130.png\n",
            " inflated: BLvalidation/9131.png\n",
            " inflated: BLvalidation/9132.png\n",
            " inflated: BLvalidation/9133.png\n",
            " inflated: BLvalidation/9134.png\n",
            " inflated: BLvalidation/9135.png\n",
            " inflated: BLvalidation/9136.png\n",
            " inflated: BLvalidation/9137.png\n",
            " inflated: BLvalidation/9138.png\n",
            " inflated: BLvalidation/9139.png\n",
            " inflated: BLvalidation/9140.png\n",
            " inflated: BLvalidation/9141.png\n",
            " inflated: BLvalidation/9142.png\n",
            " inflated: BLvalidation/9143.png\n",
            " inflated: BLvalidation/9144.png\n",
            " inflated: BLvalidation/9145.png\n",
            " inflated: BLvalidation/9146.png\n",
            " inflated: BLvalidation/9147.png\n",
            " inflated: BLvalidation/9148.png\n",
            " inflated: BLvalidation/9149.png\n",
            " inflated: BLvalidation/9150.png\n",
            " inflated: BLvalidation/9151.png\n",
            " inflated: BLvalidation/9152.png\n",
            " inflated: BLvalidation/9153.png\n",
            " inflated: BLvalidation/9154.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.applications.xception\n",
        "import tensorflow.keras.preprocessing.image"
      ],
      "metadata": {
        "id": "P9fqg__cB9J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir 'preprocessedTraining'\n",
        "!mkdir 'preprocessedValidation'"
      ],
      "metadata": {
        "id": "ykTvZgFfCOz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "ds_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_ds = ds_gen.flow_from_directory(\n",
        "  \"/content/trainingImages\", \n",
        "  shuffle=False,\n",
        "  target_size=(299, 299),\n",
        "  batch_size=32\n",
        ")\n",
        "x,y=train_ds.next()\n",
        "\n",
        "val_ds = ds_gen.flow_from_directory(\n",
        "  \"/content/validationImages\",\n",
        "  shuffle=False,\n",
        "  target_size=(299, 299),\n",
        "  batch_size=32\n",
        ")\n",
        "x1,y1=val_ds.next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90aCG1oaB_4U",
        "outputId": "7ceffba8-cc5c-42f5-f42a-feac537e7480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7323 images belonging to 1 classes.\n",
            "Found 1831 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "  \n",
        "# Opening JSON file\n",
        "f = open('/content/gdrive/MyDrive/captions.json')\n",
        "  \n",
        "# returns JSON object as \n",
        "# a dictionary\n",
        "data = json.load(f)"
      ],
      "metadata": {
        "id": "jr2r5UM0DlY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(data, test_size = 0.2, shuffle=False )"
      ],
      "metadata": {
        "id": "TwjKHImMDo1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainJson = open('captions_train.json', 'w')\n",
        "trainJson.write(str(train))\n",
        "trainJson.close()"
      ],
      "metadata": {
        "id": "DKNlEmIgDtDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valJson = open('captions_validation.json', 'w')\n",
        "valJson.write(str(val))\n",
        "valJson.close()"
      ],
      "metadata": {
        "id": "oU53EkfwDwTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot()\n",
        "pyplot.imshow(train_ds[0][0][0], cmap=pyplot.get_cmap('gray'))\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "yfDHto_mDz4-",
        "outputId": "5d411db1-403d-40fb-d472-b969dc7643cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/gdrive/MyDrive/CaTr/catr/' && python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkjkteQEFB5M",
        "outputId": "666f2827-8fe1-499f-bbb5-615a719e56ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Device: cuda\n",
            "Number of params: 83959866\n",
            "Train: 7322\n",
            "Valid: 1831\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Start Training..\n",
            "Epoch: 0\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/content/gdrive/MyDrive/CaTr/catr/models/position_encoding.py:38: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n",
            "100% 228/228 [06:41<00:00,  1.76s/it]\n",
            "Training Loss: 0.9563886625089668\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 1.272826776930115e-05\n",
            "\n",
            "Epoch: 1\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 7.403870738112585e-06\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 2.8026725486001692e-06\n",
            "\n",
            "Epoch: 2\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:45<00:00,  1.78s/it]\n",
            "Training Loss: 2.2314492233570556e-06\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 1.1251598874062846e-06\n",
            "\n",
            "Epoch: 3\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 1.0266185471476875e-06\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.08it/s]\n",
            "Validation Loss: 6.211285994658252e-07\n",
            "\n",
            "Epoch: 4\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 5.692233688535995e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 3.5855790097935697e-07\n",
            "\n",
            "Epoch: 5\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 3.774382576151319e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 3.1458486513076486e-07\n",
            "\n",
            "Epoch: 6\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 3.001873222043933e-07\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 5.727940751594831e-08\n",
            "\n",
            "Epoch: 7\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 9.915421534906113e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:54<00:00,  1.06it/s]\n",
            "Validation Loss: 4.006339780999199e-08\n",
            "\n",
            "Epoch: 8\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 5.412540773469824e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.08it/s]\n",
            "Validation Loss: 2.980231163767375e-08\n",
            "\n",
            "Epoch: 9\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:44<00:00,  1.77s/it]\n",
            "Training Loss: 3.875248899943703e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.08it/s]\n",
            "Validation Loss: 2.3283058913809077e-08\n",
            "\n",
            "Epoch: 10\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 2.962717594064208e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:54<00:00,  1.07it/s]\n",
            "Validation Loss: 1.8626449593445363e-08\n",
            "\n",
            "Epoch: 11\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 2.341619502587876e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.07it/s]\n",
            "Validation Loss: 1.3503315691663383e-08\n",
            "\n",
            "Epoch: 12\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 1.8712227751699242e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:54<00:00,  1.07it/s]\n",
            "Validation Loss: 1.210719256650938e-08\n",
            "\n",
            "Epoch: 13\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.76s/it]\n",
            "Training Loss: 1.5136670299242426e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:54<00:00,  1.07it/s]\n",
            "Validation Loss: 9.313224857976365e-09\n",
            "\n",
            "Epoch: 14\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.76s/it]\n",
            "Training Loss: 1.2668717548698126e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.08it/s]\n",
            "Validation Loss: 8.381902283360887e-09\n",
            "\n",
            "Epoch: 15\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 1.1044519353656587e-08\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.08it/s]\n",
            "Validation Loss: 7.730435265098722e-09\n",
            "\n",
            "Epoch: 16\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.77s/it]\n",
            "Training Loss: 9.810542935533723e-09\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 3.725290076417309e-09\n",
            "\n",
            "Epoch: 17\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 8.13081799160131e-09\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 3.725290076417309e-09\n",
            "\n",
            "Epoch: 18\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 6.462836982927861e-09\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:55<00:00,  1.05it/s]\n",
            "Validation Loss: 3.725290076417309e-09\n",
            "\n",
            "Epoch: 19\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:42<00:00,  1.76s/it]\n",
            "Training Loss: 5.1545687503892815e-09\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.08it/s]\n",
            "Validation Loss: 2.7939675018018306e-09\n",
            "\n",
            "Epoch: 20\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 4.627891533930239e-09\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 2.7939675018018306e-09\n",
            "\n",
            "Epoch: 21\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 228/228 [06:43<00:00,  1.77s/it]\n",
            "Training Loss: 4.564960890777551e-09\n",
            "  0% 0/58 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100% 58/58 [00:53<00:00,  1.09it/s]\n",
            "Validation Loss: 2.7939675018018306e-09\n",
            "\n",
            "Epoch: 22\n",
            "  0% 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 55% 125/228 [03:44<02:57,  1.73s/it]"
          ]
        }
      ]
    }
  ]
}